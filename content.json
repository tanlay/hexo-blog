[{"title":"Docker入门","date":"2019-08-13T11:49:12.000Z","path":"post/6782be63.html","text":"Docker是Docker项目开发的一种容器格式。docker命令可以运行、停止、启动、检查容器。 Docker Hub Registry提供了个人与组织保存和开发Docker容器镜像的地方 Docker镜像和容器容器化的目的是将应用程序运行所需要的所有组件集合在一个单一而独立的单元中。对于Docker来说，这个单元被称为镜像。 镜像：是一个静态单元，它是容器运行的应用程序以及应用程序执行所需要的库、配置文件、可执行程序或者其他组件。 容器：指的是一个已运行的Docker镜像的实例。 Docker命令查找Docker组件信息的命令 docker version：查看docker版本 docker info：查看docker系统信息 docker help：查看与docker命令一起使用的命令或选项 docker history：查看镜像历史 docker inspect：查看镜像或者容器信息 docker port：列出容器的端口映射 操作正在运行的容器的命令 docker ps：列出正在运行的容器 docker attach：将另一个命令附加到正在运行的容器上 docker exec：在正在运行的容器中执行命令 docker inspect：审查容器的元数据 docker cp：从容器中复制文件到宿主机 docker diff：检查容器从启动后其文件系统所做的改变 操作镜像的命令 docker images：查看系统上的镜像 docker run：运行镜像 docker pull：从registry上拉取镜像 docker push：将镜像传到registry中 docker save：将镜像保存为tarball docker load：将tarball加载到本地镜像 docker export：从容器中将文件系统导出成本地文件系统的tarball文件 操作Docker Registry的命令 docker search：在registry中搜索镜像 docker login：登陆到Docker Hub Registry（可以通过自己的账号推送拉取镜像） docker logout：从Docker Hub Registry中登出 修改现存的镜像的命令 docker tag：未镜像添加一个名字 docker rename：修改镜像名字 修改容器的状态的命令 docker stop：停止正在运行的容器 docker start：启动已经停止的容器 docker restart：重启启动容器 docker pause：暂停正在运行的容器 docker unpause：重新启动已经暂停的容器 docker kill：向容器发送kill信号或其他信号 查看Docker的活动的命令 docker events：查看Docker服务器的事件 docker top：查看容器的进程 docker logs：查看容器产生的日志消息 docker stats：查看容器的CPU和内存使用统计 docker wait：查看容器直到它停止 创建镜像和容器的命令 docker build：从头构建镜像 docker commit：从容器创建镜像 docker create：从镜像创建容器但是不运行它 docker import：将文件系统导入镜像中 部署搭建Docker运行环境在Centos7系统中安装docker123456[mint@ali-mint ~]$ sudo yum -y install epel-release[mint@ali-mint ~]$ sudo yum -y install docker[mint@ali-mint ~]$ systemctl restart docker[mint@ali-mint ~]$ systemctl enabled docker[mint@ali-mint ~]$ systemctl status docker[mint@ali-mint ~]$ docker version 在ubuntu系统安装docker12345[mint@ali-mint ~]$ sudo apt -y update[mint@ali-mint ~]$ sudo apt -y install docker.io[mint@ali-mint ~]$ sudo service docker.io restart[mint@ali-mint ~]$ sduo service docker.io status[mint@ali-mint ~]$ sudo dpkg-qurey -L docker.io | less 搭建Docker Registry如果没有网络的环境下怎么使用docker拉取镜像呢，这就需要提前构建docker私有registry。并且还可以减少pull、push的时间。基于Centos7系统可以使用yum安装docker-registry包来部署docker registry。注意需要开放防火墙访问权限或者直接关闭防火墙。 安装docker-registry使用yum安装12345[root@docker-registry ~]# yum -y install docker-registry[root@docker-registry ~]# systemctl restart docker-distribution[root@docker-registry ~]# systemctl enable docker-distribution[root@docker-registry ~]# netstat -tnlp|grep registrytcp6 0 0 :::5000 :::* LISTEN 2703/registry 使用docker容器部署1[root@docker-registry ~]# docker run -d 5000:5000 registry 获取镜像1[root@docker-registry yum.repos.d]# docker run --name myhello hello-world 允许访问registryDocker客户端要求从registry那里获得证书，或者将registry标记为不安全。可以通过编辑/etc/sysconfig/docker文件将registry标记为不安全，如下： 12345[root@docker-registry ~]# cat !$cat /etc/sysconfig/dockerADD_REGISTRY='--add-registry localhost:5000'INSECURE_REGISTRY='--insecure-registry loclahost:5000'[root@docker-registry ~]# systemctl restart docker 为镜像打个标签使用docker tag命令为镜像指定一个名字，之后可以使用这个名字把镜像推送到本地的docker registry中 1[root@docker-registry ~]# docker tag hello-world localhost:5000/hello-world-me 推送镜像将hello-world-me镜像推送到docker-registry中。 1[root@docker-registry ~]# docker push localhost:5000/hello-world-me 拉取镜像为了确保从本地registry中拉取镜像，需要删除本地镜像，然后尝试从本地registry中取回该镜像 1234[root@docker-registry ~]# docker rmi myhello[root@docker-registry ~]# docker rmi hello-world localhost:5000/hello-world[root@docker-registry ~]# docker pull localhost:5000/hello-world-me[root@docker-registry ~]# docker images 配置私有Docker Registry仓库 –access-logfile：对docker-registry服务的访问记录会记录到所设置的任何文件 –max-requests 100：设置registry守护进程能够接收的请求上限为100 –graceful-timeout 3600：工作进程发起重启信号后，在给3600s来完成正在处理的请求。如果这段时间不能处理完，则会被杀死 -t 3600：工作进程超过3600s(1小时)没有活动，他会被杀死并重启。 -k gevent：将工作进程类型设置为gevent（基于Greenlets的一种异步工作进程） -b 0.0.0.0:5000：将工作进程绑定到系统所在IP地址（0.0.0.0）的5000端口上，此时外部docker客户端可以使用tcp5000端口连接到docker registry -w 4：设置工作进程为4 docker_registry.wsgi:application：进程随Docker registry wsgi应用程序一起运行 运行容器镜像12345678910111213141516[mint@ali-mint ~]$ docker run centos cat /etc/os-releaseNAME=\"CentOS Linux\"VERSION=\"7 (Core)\"ID=\"centos\"ID_LIKE=\"rhel fedora\"VERSION_ID=\"7\"PRETTY_NAME=\"CentOS Linux 7 (Core)\"ANSI_COLOR=\"0;31\"CPE_NAME=\"cpe:/o:centos:centos:7\"HOME_URL=\"https://www.centos.org/\"BUG_REPORT_URL=\"https://bugs.centos.org/\"CENTOS_MANTISBT_PROJECT=\"CentOS-7\"CENTOS_MANTISBT_PROJECT_VERSION=\"7\"REDHAT_SUPPORT_PRODUCT=\"centos\"REDHAT_SUPPORT_PRODUCT_VERSION=\"7\" 执行以上docker run centos cat /etc/os-release命令则docker引擎会进行以下操作 寻找镜像: 到centos:latest的镜像，本地仓库没有则会到Docker.io的registry查找，并下载centos:lateset 执行命令: cat命令会显示出/etc/os-release文件的内容 以上命令执行只是打印/etc/os-release文件的内容，打印完就执行完了。可以使用docker images查看本地系统的镜像，docker ps查看正在运行的容器，docker ps -a查看所有容器，如果需要重新启动该容器，则需要使用docker start命令启动容器 123456789101112131415161718192021222324[mint@ali-mint ~]$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEfedora latest ef49352c9c21 11 days ago 246MBubuntu latest 3556258649b2 2 weeks ago 64.2MBcentos latest 9f38484d220f 5 months ago 202MB[mint@ali-mint ~]$ docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES12572b653b36 centos \"cat /etc/os-release\" 16 minutes ago Exited (0) 16 minutes ago upbeat_noyce[mint@ali-mint ~]$ docker start -i 12572b653b36NAME=\"CentOS Linux\"VERSION=\"7 (Core)\"ID=\"centos\"ID_LIKE=\"rhel fedora\"VERSION_ID=\"7\"PRETTY_NAME=\"CentOS Linux 7 (Core)\"ANSI_COLOR=\"0;31\"CPE_NAME=\"cpe:/o:centos:centos:7\"HOME_URL=\"https://www.centos.org/\"BUG_REPORT_URL=\"https://bugs.centos.org/\"CENTOS_MANTISBT_PROJECT=\"CentOS-7\"CENTOS_MANTISBT_PROJECT_VERSION=\"7\"REDHAT_SUPPORT_PRODUCT=\"centos\"REDHAT_SUPPORT_PRODUCT_VERSION=\"7\" 此时使用docker start -i 12572b653b36，-i 选项把容器的输出定向到本地shell中 以交互式运行容器镜像常见的例子，打开一个shell在容器内部直接进行操作。可以方便查看容器内部情况并修改内容。以下我通过执行/bin/bash命令打开一个容器的shell进行交互 123456[mint@ali-mint ~]$ docker run -it centos /bin/bash[root@10962ad1fb5c /]#[root@10962ad1fb5c /]# ps -e PID TTY TIME CMD 1 pts/0 00:00:00 bash 14 pts/0 00:00:00 ps 此时已经来到容器内部了，可以通过主机名来看，如果主机名没有变化，可以通过执行ps -e命令来查看正在运行的命令来判断。 也可以在容器中执行命令，使用yum命令添加更多程序到容器中。可以使用exit退出容器shell，还可以通过docker commit命令制作新的镜像，需要使用docker ps -a查询到该容器的容器ID,本地系统就有一个名为testrun的镜像了并可以为接下来的docker run做准备 1234567[root@10962ad1fb5c /]# yum -y install httpd vsftpd httpd-manual net-tools iproute[root@10962ad1fb5c /] exit[mint@ali-mint ~]$ docker commit 10962ad1fb5c testrunsha256:b38aa80475139935155a341257cb03f4b7cf6279f2a93b509d6a8daab60b8578z[mint@ali-mint ~]$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEtestrun latest b38aa8047513 About a minute ago 356MB 在容器内运行管理命令想在运行容器之后结束后，容器自动销毁，可以添加–rm选项。这样就不会有太多无用容器占用磁盘空间。执行ip和route命令依赖于之前安装的net-tools和iproute命令 123456789101112131415[mint@ali-mint ~]$ docker run -it --rm testrun /usr/sbin/ip addr show eth0266: eth0@if267: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:12:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.18.0.2/16 brd 172.18.255.255 scope global eth0 valid_lft forever preferred_lft forever[mint@ali-mint ~]$ docker run -it --rm testrun /usr/sbin/route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 172.18.0.1 0.0.0.0 UG 0 0 0 eth0172.18.0.0 0.0.0.0 255.255.0.0 U 0 0 0 eth0[mint@ali-mint ~]$ ip addr show docker03: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:29:b8:4b:2f brd ff:ff:ff:ff:ff:ff inet 172.18.0.1/16 brd 172.18.255.255 scope global docker0 valid_lft forever preferred_lft forever 前两个docker命令查询到容器内的网络情况，接下来的IP命令显示了宿主机的docker0网络接口，它的一个IP地址172.18.0.1/16。默认情况下，宿主机会在容器启动时通过DHCP给容器分配地址。testrun运行的第一个ip地址为172.18.0.2/16。如果再次运行容器将会生成新的地址。因为通过run命令每次会生成新的容器。 通过route可以看到容器的默认网关是172.18.0.1，刚好是宿主机docker0网络接口的IP地址。通过宿主机的docker0接口进行路由能够让容器访问本地宿主机之外的网络资源 运行容器化服务使用容器运行服务由以下优势： 配置：能够提前配置好所需的全部可执行程序，库，配置文件等无需担心宿主机是否提供这些组件，还方便将容器迁移至另一台服务器 隔离：每个容器都有自己的文件系统和网络接口，所以能够运行多个相同的服务容器 使用docker简单构件apache web服务器，apache会默认监听80和443端口。首先创建宿主机目录，添加index.html文件 123[mint@ali-mint ~]$ mkdir /var/www/html/[mint@ali-mint ~]$ cat /var/www/html/index.html The Apache Web Server is Running! 使用之前构建的testrun镜像，执行以下命令前确保宿主机的80和443没有被占用 12[mint@ali-mint ~]$ docker run -d -p 80:80 -p 443:443 --name=MyWebServer -v /var/www/:/var/www/ testrun /usr/sbin/httpd -DFOREGROUNDda04638d9afc285111bd0eb51c4e73b0651c3e73ab14af997fb9f31e46cd6fe0 选线 描述 -d 让容器化命令在后台运行容器 -p 80:80 -p 443:443 映射端口，将容器端口映射到宿主机的端口上，冒号左边是宿主机端口，右边是容器端口。这里是将容器的80和443端口分别映射到宿主机的80和443端口上 –name=MyWebServer 指定容器名，之后可以通过容器名来操作容器，而不用通过难记的容器ID操作 -v /var/www:/var/www 挂载卷，将宿主机（冒号左边）的目录挂载到容器（冒号右边）的目录 testrun 镜像名称 /usr/sbin/httpd -DFOREGROUND 使用-DFOREGROUND选项来运行httpd守护进程 此时使用docker ps可以看到该容器，看到容器被分配了容器ID，使用的镜像testrun，运行的命令是httpd，容器是在11分钟之前创建的，宿主机上所有IPv4的网络接口将会对80和443端口的请求转发到容器内对应的端口上。 123[mint@ali-mint ~]$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESda04638d9afc testrun \"/usr/sbin/httpd -DF…\" 11 minutes ago Up 11 minutes 0.0.0.0:80-&gt;80/tcp, 0.0.0.0:443-&gt;443/tcp MyWebServer 也可以使用docker exec进入容器，按exit退出容器。 因为容器的80端口已经映射到宿主机的80上，所以通过访问宿主机的80端口即可访问到文件/var/www/html/index.html的内容。因为安装过httpd-manual包。所以还可以通过浏览器访问宿主机地址的80端口下的/manual页面可以访问到httpd的manual页 12345[mint@ali-mint ~]$ docker exec -it MyWebServer /bin/bash [root@da04638d9afc /]# exitexit[mint@ali-mint ~]$ curl localhostThe Apache Web Server is Running! 在容器中运行服务时进行资源限制默认情况下，容器运行时，容器访问内存、CPU方面是没有限制的，可以使用–memory、–momory-swap、–cpu-shares和–cpuset-cpus选项来限制可以使用的内存和CPU。 1[mint@ali-mint ~]$ docker run -d -p 80:80 -p 443:443 --name=MyWebServer -v /var/www/:/var/www/ --memory=10m --memory-swap=-1 --cpu-shares=256 testrun /usr/sbin/httpd -DFOREGROUND ec5e1a8281f0f8406187431f1eb3a5b46e864ab85adf2aadc8c5eddc1698a8fb –memory=10m：容器可以使用10m的内存 –memory-swap=-1：容器可以无限制使用交换空间，如果不设置默认为memory的2倍（20m） –cpu-shares=256： 在1024范围内设置CPU配额。设置256只占1024的25% –cpuset-cpus=0,1：使用CPU核0或1 –cpuset-cpus=3：使用第四个CPU核 –cpuset-cpus=1-3：使用CPU核1，2或3 运行特权容器大多数情况下，运行docker容器时，会限制访问宿主机或其他容器的访问以及其他容器访问我正在运行的容器。然而有些特殊情况下，想要让容器拥有更大的宿主机系统访问权限。这种容器就成为特权容器 选线 描述 –ipc IPC：开放访宿主机的进程间通信设施。默认情况下，每个容器都有私有的IPC功能设施 –net-host 网络接口：向容器开放宿主机的网路接口。容器默认都有自己的网络接口 –pid=host 进程表：允许容器访问进程表。容器默认有自己的进程表 -e HOST=/host 宿主机文件系统：如果设置了，HOST环境变量会告诉容器将宿主机的root文件系统挂载到容器的某个目录上，推荐挂载在/host下 –privileged 这一选项会关闭容器运行命令的安全隔离。因此，以root运行的进程拥有宿主机上以root运行任何进程是同样的权限 查找、拉取、保存和装载容器镜像搜索镜像使用docker search命令搜索镜像 12345[mint@ali-mint ~]$ docker search centos[mint@ali-mint ~]$ docker search ubuntu[mint@ali-mint ~]$ docker search nginx[mint@ali-mint ~]$ docker search mysql[mint@ali-mint ~]$ docker search jenkins 也可以细化搜索 -s：查找star数至少是多少的 –no-trunc：告诉docker search不要截取描述字段 automated=true：只显示定期自动重新构建的镜像 123[mint@ali-mint ~]$ docker search -s 100 centos[mint@ali-mint ~]$ docker search --no-trunc=true mysql[mint@ali-mint ~]$ docker search --automated=true centos 在Docker Hub上检索镜像通过web浏览器访问Docker Hub Registry，可以找到镜像的很多信息。如果需要查找多个镜像的文档，可以访问Docker Library，找到相应镜像并查看其文档 支持的镜像版本 用来运行镜像的基本docke run命令 配合docker run使用环境变量，这些变量可以更改镜像设置 这个容器镜像在github页面的位置 用于构建该镜像的Dockerfile文件 从Docker Registry上拉取镜像通过docker pull命令可以从docker registry上拉取镜像，可以从Docker Hub Registry上拉取，也可以从自建的docker registry上拉取。 123456[mint@ali-mint ~]$ docker pull centos[mint@ali-mint ~]$ docker pull mysql[mint@ali-mint ~]$ docker pull nginx[mint@ali-mint ~]$ docker pull 172.16.100.10:5000/centos[mint@ali-mint ~]$ docker pull 172.16.100.10:5000/mysql[mint@ali-mint ~]$ docker pull 172.16.100.10:5000/nginx 保存和装载镜像拉取镜像并不是将镜像放入Docker的唯一方式，还可以把镜像保存为tarball，然后copy到其他系统中，并装载它。 以下使用docker save命令将centos进行保存为一个tarball。tarball文件都包含了要构成保存镜像所需要的层，再将tar拷贝到另一个运行Docker服务的系统后，可使用docker load命令装载它并查看结果 1234[mint@ali-mint ~]$ docker save -o centos7.tar centos[mint@ali-mint ~]$ scp centos7.tar 172.18.9.50:/tmp[test@test ~]$ docker load -i /tmp/centos7.tar[test@test ~]$ docker images|grep centos 为镜像做标签检视容器每个镜像所附带的信息包含了默认配置、创建者信息以及何时以何种方式创建的细节。在容器运行后，容器会包含额外的信息，如容器的网络配置、容器是否正在运行以及挂载卷的信息。 在容器或镜像上运行docker inspect命令可以查看与之关联的底层数据。在用镜像或容器调试问题时，很有帮助。例如查看容器IP地址可以了解客户端程序（Web浏览器）去哪里寻找容器中运行的服务。docker inspect采用json格式显示，方便阅读。 用docker inspect检视基础镜像通过检视镜像可以大致了解到镜像的创建时间、构建镜像使用的Docker版本，对外开放的端口等信息。以下例子检视了最新的centos镜像。倘若centos:latest尚未拉取到我的本地系统，该命令会先拉取对应镜像并检视它。 123456789101112131415161718192021222324252627[mint@ali-mint ~]$ docker inspect centos[ &#123; \"Architecture\": \"amd64\", \"Author\": \"\", \"Comment\": \"\", \"Config\": &#123; \"AttachStdin\": false, \"AttachStdout\": false, \"AttachStderr\": false, \"Cmd\": [ \"/bin/sh\", \"-c\", \"#(nop) \", \"CMD [\\\"/bin/bash\\\"]\" ], \"Env\": [ \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" ], ... \"Created\": \"2019-03-14T21:19:53.361167852Z\", \"DockerVersion\": \"18.06.1-ce\", \"Id\": \"sha256:9f38484d220fa527b1fb19747638497179500a1bed8bf0498eb788229229e6e1\", \"Os\": \"linux\", ... &#125;] 从这些输出可以看出很多信息。该容器体系结构是amd64的，兼容64PC机。该镜像创建时没有定义Comment和Author。Config部分设置了容器运行的环境。 如果运行时没有指定其他命令，默认会运行/bin/bash命令。由于与标准输入、标准输出和标准错误的关联被设置为false。因此在运行该容器时要指定一些选项（docker run -it centos）。Env设置了PATH变量，定义了运行命令是用于查找命令的目录。最后一部分显示了和容器创建相关的基本信息。如创建时间，创建容器的docker版本，完整的容器ID以及是何种操作系统。 查看镜像历史可以在基础镜像是上构建生成新镜像。每次在镜像上运行新命令。就会长生一个新的容器层。如果这些层与镜像保存在一起就可以使用docker history命令查看这些信息。 要查看镜像历史，只要该镜像上执行docker history命令即可 12345[mint@ali-mint ~]$ docker history centosIMAGE CREATED CREATED BY SIZE COMMENT9f38484d220f 5 months ago /bin/sh -c #(nop) CMD [\"/bin/bash\"] 0B &lt;missing&gt; 5 months ago /bin/sh -c #(nop) LABEL org.label-schema.sc… 0B &lt;missing&gt; 5 months ago /bin/sh -c #(nop) ADD file:074f2c974463ab38c… 202MB 可以看到，镜像是5个月前构建的，并修改了3次，还可以看到生成镜像的shell命令。之后容器如果使用了IMAGE列的任何镜像层，就不必在拉去那个层，而只要使用系统中已经存在的这个层就可以了。 检视正在运行的容器一旦容器运行起来，不但可以获得原始镜像的信息还可以获得docker run命令所设置的许多数据，以及它在运行时添加到容器的配置设置。只要docker ps -a能列出来的容器，都可以用docker inspect来查看 启动要检视的容器以下例子使用centos镜像通过python命令和SimpleHTTPServer组件运行一个简单的Web服务器。Web服务器以守护进程（-d）的方式在后台运行，并且容器的8080端口开放给宿主机，容器名字为centos_web，通过设置–restart=”on-failure:5”当容器发生故障时，docker会至多尝试5次来重启容器。默认不会自动重启，初始镜像是centos，用python2运行SimpleHTTPServer模块来让8080端口提供服务。可以通过在宿主机上执行命令curl localhost:8080 容器是否在运行，可以发现在容器中和在宿主机上执行该命令输出结果都一致。 12345678[root@ali-mint ~]# echo \"Start Python Web Server on Centos: Successful\" &gt; /var/www/html/index.html[root@ali-mint ~]# docker run -d -p 8080:8080 --name=\"centos_web\" --restart=\"on-failure:5\" -w /var/www/html/ -v /var/www/html/:/var/www/html/ centos python -m SimpleHTTPServer 80807544f6d77f308b1ddc4948ba7cb9da19f18df8143b05946ca1972c09b2c5b4dd[root@ali-mint ~]# docker exec -it 7544f6d77f30 /bin/bash[root@7544f6d77f30 html]# curl localhost:8080Start Python Web Server on Centos: Successful[root@ali-mint ~]# curl localhost:8080Start Python Web Server on Centos: Successful 检视整个容器配置使用docker inspect命令可以直接输出该容器的全部信息，当然也可以通过使用管道、重定向将内容送到more、less或文件上以便阅读。 1234567891011121314151617[root@ali-mint mint]# docker inspect centos_web ... \"Args\": [ \"-m\", \"SimpleHTTPServer\", \"8080\" ], \"Config\": &#123; \"AttachStdin\": false, \"AttachStdout\": false, \"AttachStderr\": false, \"Cmd\": [ \"python\", \"-m\", \"SimpleHTTPServer\", \"8080\" ], 属性Arg中保存了容器启动是传给python命令的3个参数。Config部分显示标准错误、标准输入和标准输出并关联到启动容器的终端会话上。如果要运行/bin/bash，以便通过终端控制台直接与容器交互，这些设置应该设置为true，而不是false。Config部分的Cmd属性存放了命令（Python）及传给该命令的所有参数（-m、SimpleHTTPServer和8080） 12345678910111213 \"Hostname\": \"7544f6d77f30\", \"CpuShares\": 0, \"CpusetCpus\": \"\",... \"ExposedPorts\": &#123; \"8080/tcp\": &#123;&#125; &#125;, \"Tty\": false, \"OpenStdin\": false, \"StdinOnce\": false, \"Env\": [ \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" ], 如果系统中存在多个容器，也许想要为每个容器分配CPU配额，以确保重要的容器获得更高比例的CPU时间，此处，CpusShares并未获取到CPU的优先级。如果设定了CpusetCpus，容器只会在选中的CPU上运行。这两个值都可以通过docker run命令的-c和–cpuset-cpus=””选项设置. Env部分包含了PATH的设置，PATH定义了在容器中执行命令时用来查找命令的目录。ExposedPorts显示容器TCP8080端口开放到宿主机的相同端口上。由于命令行中没有设置主机名，容器的前12个字符被用作主机名。可以使用docker run的-h选项为容器分配主机名 123456 \"Image\": \"centos\",... \"User\": \"\",... \"WorkingDir\": \"/var/www/html\", ], Images显示使用的镜像名称（centos），User没有设置，如设置则容器内的命令会使用指定的用户运行。例如，docker run命令设置-u aapache选项，Web服务器会以apache用户运行，而不是root用户。WorkingDir设置工作目录（命令执行的目录）设置为/var/www/html。 123456789101112131415161718\"HostConfig\": &#123; ... \"PortBindings\": &#123; \"8080/tcp\": [ &#123; \"HostIp\": \"\", \"HostPort\": \"8080\" &#125; ] &#125;, \"Privileged\": false, \"PublishAllPorts\": false, \"ReadonlyRootfs\": false, \"RestartPolicy\": &#123; \"Name\": \"on-failure\", \"MaximumRetryCount\": 5 &#125;, ... PortBindings设置了TCP8080端口对宿主机上所有IP地址的8080端口开放。Privileged: false表示容器除了额外指定的方式（如明确的从宿主机挂载卷）之外，没有权限访问其他容器或者宿主机。当PublishAllPorts设置为false时，容器中只有那些明确指定的端口（此处的8080）才能被宿主机相同的端口访问到。ReaadonlyRootfs设置为false。则root文件系统可以被写入。RestartPolicy默认属性如果发生故障不重启，本例会重启5次 1234567\"Id\": \"7544f6d77f308b1ddc4948ba7cb9da19f18df8143b05946ca1972c09b2c5b4dd\",\"Image\": \"sha256:9f38484d220fa527b1fb19747638497179500a1bed8bf0498eb788229229e6e1\",\"Name\": \"/centos_web\",\"MountLabel\": \"\",\"HostnamePath\": \"/var/lib/docker/containers/7544f6d77f308b1ddc4948ba7cb9da19f18df8143b05946ca1972c09b2c5b4dd/hostname\", \"HostsPath\": \"/var/lib/docker/containers/7544f6d77f308b1ddc4948ba7cb9da19f18df8143b05946ca1972c09b2c5b4dd/hosts\",\"LogPath\": \"/var/lib/docker/containers/7544f6d77f308b1ddc4948ba7cb9da19f18df8143b05946ca1972c09b2c5b4dd/7544f6d77f308b1ddc4948ba7cb9da19f18df8143b05946ca1972c09b2c5b4dd-json.log\", HostnamePath设置了容器/etc/hostname文件的位置。HostPath设置了容器/etc/hosts文件的位置，该文件将容器的主机名和IP地址关联到一起，同时还设置了localhost的IP地址以及IPV6地址。LogPath设定了与该容器关联的日志文件位置，文件名是容器ID-json.log。可以使用docker logs centos_web查看容器日志。MountLabel设置了selinux的上下文。Name属性的内容是斜杠加上容器名(/centos_web) 12345678910111213141516171819\"NetworkSettings\": &#123; \"Bridge\": \"\", \"Gateway\": \"172.18.0.1\", \"GlobalIPv6Address\": \"\", \"GlobalIPv6PrefixLen\": 0, \"IPAddress\": \"172.18.0.2\", \"IPPrefixLen\": 16, \"IPv6Gateway\": \"\", \"LinkLocalIPv6Address\": \"\", \"LinkLocalIPv6PrefixLen\": 0, \"MacAddress\": \"02:42:ac:12:00:02\", \"Ports\": &#123; \"8080/tcp\": [ &#123; \"HostIp\": \"0.0.0.0\", \"HostPort\": \"8080\" &#125; ] &#125;, Bridge设定了网络名称（默认docker0），该网络为宿主机上的Docker容器提供了网络接口。宿主机IP地址是172.18.0.2，Docker默认不启用IPV6。MacAddress指定了容器内虚拟网卡的地址。Ports设定显示了TCP8080端口到宿主机上所有IP地址（0.0.0.0）以及TCP8080端口的分配。 1234567891011121314151617181920212223\"State\": &#123; \"Status\": \"running\", \"Running\": true, \"Paused\": false, \"Restarting\": false, \"OOMKilled\": false, \"Dead\": false, \"Pid\": 13298, \"ExitCode\": 0, \"Error\": \"\", \"StartedAt\": \"2019-08-15T10:00:10.428661642Z\", \"FinishedAt\": \"0001-01-01T00:00:00Z\"&#125;, \"Mounts\": [ &#123; \"Type\": \"bind\", \"Source\": \"/var/www/html\", \"Destination\": \"/var/www/html\", \"Mode\": \"\", \"RW\": true, \"Propagation\": \"rprivate\" &#125;], state属性提供了容器当前状态的信息。由于容器正在运行，所以Running为true。Mounts属性可以查看到被挂载的目录（源目录）是宿主机的/var/www/html。挂载到的目录（目的目录）是容器的/var/www/html，RW为true表示可读可写。 检视单个容器的属性可以通过docker inspect命令的–format选项指定希望查询到的具体属性。不但可以获取容器的特定信息，还可以将这些信息传递给其他命令。可以把查询结果传给ping命令。也可以用curl命令来接收查询的内容。 12345678910111213141516[mint@ali-mint ~]$ docker inspect --format=\"&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;\" centos_web172.18.0.2[mint@ali-mint ~]$ ping -c 4 `docker inspect --format=\"&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;\" centos_web`PING 172.18.0.2 (172.18.0.2) 56(84) bytes of data.64 bytes from 172.18.0.2: icmp_seq=1 ttl=64 time=0.078 ms64 bytes from 172.18.0.2: icmp_seq=2 ttl=64 time=0.076 ms64 bytes from 172.18.0.2: icmp_seq=3 ttl=64 time=0.073 ms64 bytes from 172.18.0.2: icmp_seq=4 ttl=64 time=0.077 ms--- 172.18.0.2 ping statistics ---4 packets transmitted, 4 received, 0% packet loss, time 3000msrtt min/avg/max/mdev = 0.073/0.076/0.078/0.002 ms[mint@ali-mint ~]$ curl -L `docker inspect --format=\"&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;\" centos_web`:8080Start Python Web Server on Centos: Successful 检视运行终端会话的容器当启动容器是运行在shell终端会话时，可以通过另外的shell来检视该容器，只要该容器将标准输入STDIN、标准输出STDOUT、标准错误STDERR关联到这个shell。在Docker宿主机上打开两个shell会话，在第一个shell下输入以下命令： 123[mint@ali-mint ~]$ docker run -it --name=bashtest centos /bin/bash[root@62a9c8da90a3 /]# lsanaconda-post.log bin dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var 启动bashtest后，打开一个新的shell并检视第一个shell与容器标准输入、标准输出和标准错误关联配置 12[mint@ali-mint ~]$ docker inspect --format='&#123;&#123;.Config.AttachStdin&#125;&#125; &#123;&#123;.Config.AttachStdout&#125;&#125; &#123;&#123;.Config.AttachStderr&#125;&#125;' bashtest true true true 如果想查看最初启动容器的shell，或者与其交互，可以使用docker attach 命令。在第二个shell中，输入以下命令： 1[mint@ali-mint ~]$ docker attach bashtest 此时可以发现在这两个shell下，不论其中一个输入什么，另一个都会一样的显示。 检视容器的内存和CPU限制如果Docker服务器上使用很多容器，并且多个容器之间存在交互，就存在容器之前争夺资源的问题。通过docker run可以限制某个容器可以使用的内存和交换区数量。还可以为容器设置CPU优先级并限制CPU的使用。 默认运行容器并不会对限制这些资源。添加以下选项重新运行centos_web –cpuset-cpus=0：设置系统的第一个CPU执行来自容器的命令 –cpu-shares=256：设置容器能得到的CPU时钟周期的比例为25% –memory=512M：限制容器能够使用的内存数量为512M –memory-swap=2G：限制容器使用的交换分区大小为2G 1[mint@ali-mint ~]$ docker run -d -p 8080:8080 --name=centos_web --cpuset-cpus=0 --cpu-shares=256 --memory=512M --memory-swap=2G --restart=\"on-failure:5\" -w /var/www/html -v /var/www/html:/var/www/html centos python -m SimpleHTTPServer 8080 可以逐个检视以上配置是否生效。以下输出可以看出容器被设置使用Docker服务器的第一个CPU（0）。容器的CpuShares设置为512，默认1024。内存限制为512M。交换分区2G。 12345678[mint@ali-mint ~]$ docker inspect --format='&#123;&#123;.HostConfig.CpusetCpus&#125;&#125;' centos_web0[mint@ali-mint ~]$ docker inspect --format='&#123;&#123;.HostConfig.CpuShares&#125;&#125;' centos_web 256[mint@ali-mint ~]$ docker inspect --format='&#123;&#123;.HostConfig.Memory&#125;&#125;' centos_web 536870912(base) [mint@ali-mint ~]$ docker inspect --format='&#123;&#123;.HostConfig.MemorySwap&#125;&#125;' centos_web2147483648 寻找探查容器的其他方法使用docker top查看进程一个容器通常只运行一个进程，然而使用docker exec可以在容器中运行其他进程。使用docker top可以查看容器中正在运行的所有进程。 12345[mint@ali-mint ~]$ docker top centos_webUID PID PPID C STIME TTY TIME CMDroot 16548 16532 0 23:04 ? 00:00:00 python -m SimpleHTTPServer 8080root 16659 16532 0 23:05 ? 00:00:00 /bin/bashroot 16698 16659 34 23:05 ? 00:00:02 /usr/bin/python /usr/bin/yum -y install vim 使用docker attach与容器内服务进行交互使用docker attach可以关联到任何正在运行的容器。之前创建的centos_web，连接进去，观察Web服务器对接收的请求的响应。访问宿主机8080端口或者centos_web的8080端口，在访问一个不存在的页面。可看到如下内容： 12345[mint@ali-mint ~]$ docker attach centos_web117.136.72.69 - - [15/Aug/2019 15:10:24] \"GET / HTTP/1.1\" 200 -117.136.72.69 - - [15/Aug/2019 15:10:25] \"GET / HTTP/1.1\" 200 -117.136.72.69 - - [15/Aug/2019 15:10:30] code 404, message File not found117.136.72.69 - - [15/Aug/2019 15:10:30] \"GET /test HTTP/1.1\" 404 - 使用docker exec在正在运行的容器中启动新进程使用docker exec在容器中执行yum 安装net-tools包，并查看容器默认网关172.18.0.1（宿主机docker0网口IP地址）、监听的端口等信息 123456789101112131415[mint@ali-mint ~]$ docker exec -it centos_web yum -y install net-tools Installing : net-tools-2.0-0.24.20131004git.el7.x86 1/1 Verifying : net-tools-2.0-0.24.20131004git.el7.x86_64 1/1 Installed: net-tools.x86_64 0:2.0-0.24.20131004git.el7 Complete![mint@ali-mint ~]$ docker exec -it centos_web route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 172.18.0.1 0.0.0.0 UG 0 0 0 eth0172.18.0.0 0.0.0.0 255.255.0.0 U 0 0 0 eth0[mint@ali-mint ~]$ docker exec -it centos_web netstat -tnlpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:8080 0.0.0.0:* LISTEN 1/python 使用docker logs查看容器进程的输出不但可以使用exec、attach查看实时处理的输出，之后还可以通过docker logs查看进程处理和输出。无论运行中的容器还是已经停止的，只要是未删除的，都可以使用docker logs把容器处理的所有输出打印到屏幕上，然后退出。 12345[mint@ali-mint ~]$ docker logs centos_web117.136.72.69 - - [15/Aug/2019 15:10:24] \"GET / HTTP/1.1\" 200 -117.136.72.69 - - [15/Aug/2019 15:10:25] \"GET / HTTP/1.1\" 200 -117.136.72.69 - - [15/Aug/2019 15:10:30] code 404, message File not found117.136.72.69 - - [15/Aug/2019 15:10:30] \"GET /test HTTP/1.1\" 404 - 输出和docker attach一致，但是docker lgos centos输出完毕后会立即退出，而docker attachb持续等待响应 使用docker diff查看容器的变化docker diff会记录容器运行后容器内文件和目录发生的所有变化。可以查看容器相对与最初运行的镜像有哪些改变。 12345678[mint@ali-mint ~]$ docker diff centos_webA /var/wwwA /var/www/htmlC /rootC /tmpD /root/anaconda-ks.cfgA /tmp/anaconda-ks.cfg... 输出显示新增了/var/www和/var/www/html目录（宿主机挂载上来的），我将/root/下的anaconda-ks.cfg移至/tmp/，导致/root/和/tmp/发生改变。还显示/root/anaconda-ks.cfg被删除，/tmp/anaconda-ks.cfg被增加。所以在提交镜像为永久镜像时，使用docker diff检查一下容器变化是极好的。 使用docker cp从容器复制文件有时需要拷贝容器中的文件，但又不想终止容器运行内正在进行的工作。此时就可以通过docker cp复制容器中的内容到宿主机啦 123[mint@ali-mint ~]$ docker cp centos_web:/var/www/html/index.html /tmp/[mint@ali-mint ~]$ cat /tmp/index.html Start Python Web Server on Centos: Successful 容器的启动、停止和重启停止和启动容器容器运行时，有几种不同的方式将容器暴露给宿主机系统。容器的端口可以暴露在宿主机上，容器内运行的命令可以将标准输入、标准输出和标准错误暴露给宿主机的shell会话。一旦容器停止，它就会释放资源并以某种能够重新启动的状态留存在宿主机系统中。 启动和停止分离式容器之前制作的testrun镜像，由基础镜像并安装httpd组成。通过以下命令。我使用分离选项来启动httpd，并使容器的/var/www/目录挂载到宿主机的/var/www目录，将80端口和443端口暴露给宿主机。 12345678910[mint@ali-mint ~]# docker run -d -p 80:80 -p 443:443 --name=WebServer -v /var/www/:/var/www/ testrun /usr/sbin/httpd -DFOREGROUND9f8c5cd38768d8ff4d233eab9a2e938d2fccfc2294d8cf75b1a118b4c07b4c17[root@ali-mint tmp]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES9f8c5cd38768 testrun \"/usr/sbin/httpd -DF…\" 3 seconds ago Up 1 second 0.0.0.0:80-&gt;80/tcp, 0.0.0.0:443-&gt;443/tcp WebServer [mint@ali-mint ~]# netstat -tnlp|grep -E \":80|:443\"tcp6 0 0 :::80 :::* LISTEN 17692/docker-proxy tcp6 0 0 :::443 :::* LISTEN 17681/docker-proxy [mint@ali-mint ~]# curl http://localhostStart Python Web Server on Centos: Successful docke ps查看到WebServer容器正在运行。运行netstat -tnlp显示docker-proxy进程正在监听80和443端口。用curl访问显示正常的文件内容。当然停止容器只需要使用docker stop 命令 1234567[mint@ali-mint ~]# docker stop WebServer WebServer[mint@ali-mint ~]$ docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES9f8c5cd38768 testrun \"/usr/sbin/httpd -DF…\" 6 minutes ago Exited (0) 32 seconds ago WebServer[mint@ali-mint ~]$ curl http://localhostcurl: (7) Failed to connect to localhost port 80: Connection refused 运行docker stop后，docker ps就查不到了，但仍会出现在docker ps -a中。/usr/sbin/httpd -DFOREGROUND不再运行，而容器内容也保存在本地环境。想要启动这个容器也很简单，使用docker start即可。 12345678910[mint@ali-mint ~]$ docker start WebServerWebServer[root@ali-mint tmp]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES9f8c5cd38768 testrun \"/usr/sbin/httpd -DF…\" 3 seconds ago Up 1 second 0.0.0.0:80-&gt;80/tcp, 0.0.0.0:443-&gt;443/tcp WebServer [mint@ali-mint ~]# netstat -tnlp|grep -E \":80|:443\"tcp6 0 0 :::80 :::* LISTEN 17692/docker-proxy tcp6 0 0 :::443 :::* LISTEN 17681/docker-proxy [mint@ali-mint ~]# curl http://localhostStart Python Web Server on Centos: Successful 启动和停止交互式容器如果容器运行的进程是交互式的，并且标准输入、标准输出和标准错误关联到宿主机的shell会话。在另一个shell上执行docker stop命令时。会话就关闭了，对打开会话的人来看就很不好 12345[mint@ali-mint ~]$ docker run -it --name=bashubuntu ubuntu /bin/bashroot@ec114d94181e:/# pwd/[root@ali-mint ~]$ docker stop bashubuntubashubuntu 此时发现mint用户的shell自动退出了。因为root执行了docker stop。为了使容器以交互式方式工作。添加了以下选项 -a：连接选项。将终端会话连接到容器运行的bash shell的标准输出和标准错误上，这个选项可以看到bash shell的输出 -i：交互选项。将终端会话连接到容器运行bash shell的标准输入上，该选项可以输入命令到shell中。 123[mint@ali-mint ~]$ docker start -ai !$docker start -ai bashubunturoot@ec114d94181e:/#","tags":[{"name":"容器","slug":"容器","permalink":"http://www.dookt.com/tags/容器/"}]},{"title":"Centos安装vmware虚拟机报错","date":"2019-08-04T05:39:11.000Z","path":"post/a583c2ce.html","text":"Centos安装vmware不能正常使用。有可能是因为某些模块没有编译。 Could not open /dev/vmmon安装界面可以打开，启动虚拟机时报错Could not open /dev/vmmon，是因为没有编译vmmon模块 123456cd /tmptar xvf /usr/lib/vmware/modules/source/vmmon.tarcd vmmon-onlymakecp vmmon.ko /lib/modules/2.6.32-504.el6.x86_64/misc/vmmon.komodprobe vmmon 打不开网络配置器vmware-ntcfg点击网络设置没反应，命令使用vmware-ntecfg也没反应。因为没有编译vmnet模块 123456cd /tmptar xvf /usr/lib/vmware/modules/source/vmnet.tarcd vmnet-onlymakecp vmnet.ko /lib/modules/2.6.32-504.el6.x86_64/misc/vmnet.komodprobe vmnet","tags":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://www.dookt.com/tags/虚拟化/"}]},{"title":"k8s平台搭建","date":"2019-08-01T12:04:01.000Z","path":"post/b2e09379.html","text":"Kubernetes集群拥有一个Kubernetes Master。Kubernetes Master提供集群的独特视角，并且拥有一系列组件，比如Kubernetes API Server。API Server提供可以用来和集群交互的REST端点。master节点包括用来创建和复制Pod的Replication Controller。 kubernetes平台环境1234k8s master节点：172.16.100.11k8s node1节点：172.16.100.101k8s node2节点：172.16.100.102docker仓库节点：172.16.100.105 系统初始化123456systemctl stop firewalldsystemctl disable firewalldyum -y install ntpntpdate pool.ntp.orgsystemctl start ntpdsystemctl enable ntpd K8S master安装配置在master节点安装etcd、kubernetes和flanneld1yum -y install kubernetes-master etcd flannel 配置master节点etcd123456789101112# cat /etc/etcd/etcd.confETCD_NAME=etcd1ETCD_DATA_DIR=\"/data/etcd\"ETCD_LISTEN_PEER_URLS=\"http://172.16.100.11:2380\"ETCD_LISTEN_CLIENT_URLS=\"http://172.16.100.11:2379,http://127.0.0.1:2379\"ETCD_MAX_SNAPSHOTS=\"5\"ETCD_INITIAL_ADVERTISE_PEER_URLS=\"http://172.16.100.11:2380\"ETCD_INITIAL_CLUSTER=\"etcd1=http://172.16.100.11:2380,etcd2=http://172.16.100.101:2380,etcd3=http://172.16.100.102:2380\"ETCD_ADVERTISE_CLIENT_URLS=\"http://172.16.100.11:2379\"# 创建etcd数据目录mkdir -p /data/etcd/;chmod 757 -R /data/etcd/ 修改/etc/kubernetes/config配置12345# cat /etc/kubernetes/config KUBE_LOGTOSTDERR=\"--logtostderr=true\"KUBE_LOG_LEVEL=\"--v=0\"KUBE_ALLOW_PRIV=\"--allow-privileged=false\"KUBE_MASTER=\"--master=http://172.16.100.11:8080\" 修改kube-apiserver配置将Kubernetes的apiserver进程的服务地址告诉Kubernetes的controller-manager, scheduler,proxy进程。 12345678# cat /etc/kubernetes/apiserverKUBE_API_ADDRESS=\"--insecure-bind-address=0.0.0.0\"KUBE_API_PORT=\"--port=8080\"KUBELET_PORT=\"--kubelet-port=10250\"KUBE_ETCD_SERVERS=\"--etcd-servers=http://172.16.100.11:2379,http://172.16.100.101:2379,http://172.16.100.102:2379\"KUBE_SERVICE_ADDRESSES=\"--service-cluster-ip-range=10.254.0.0/16\"KUBE_ADMISSION_CONTROL=\"--admission_control=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota\"KUBE_API_ARGS=\"\" 启动master节点上的etcd, apiserver, controller-manager和scheduler12345for I in etcd kube-apiserver kube-controller-manager kube-scheduler; dosystemctl restart $Isystemctl enable $Isystemctl status $Idone K8S node1节点配置在node1节点上安装flannel、docker和Kubernetes1yum install kubernetes-node etcd docker flannel *rhsm* -y 配置node1节点etcd配置信息告诉flannel进程etcd服务的位置以及在etcd上网络配置信息的节点位置。 123456789101112# cat /etc/etcd/etc.confETCD_NAME=etcd2ETCD_DATA_DIR=\"/data/etcd\"ETCD_LISTEN_PEER_URLS=\"http://172.16.100.101:2380\"ETCD_LISTEN_CLIENT_URLS=\"http://172.16.100.101:2379,http://127.0.0.1:2379\"ETCD_MAX_SNAPSHOTS=\"5\"ETCD_INITIAL_ADVERTISE_PEER_URLS=\"http://172.16.100.101:2380\"ETCD_INITIAL_CLUSTER=\"etcd1=http://172.16.100.11:2380,etcd2=http://172.16.100.101:2380,etcd3=http://172.16.100.102:2380\"ETCD_ADVERTISE_CLIENT_URLS=\"http://172.16.100.101:2379\"# 创建etcd数据目录mkdir -p /data/etcd/;chmod 757 -R /data/etcd/ 修改/etc/kubernetes/config配置12345# cat /etc/kubernetes/configKUBE_LOGTOSTDERR=\"--logtostderr=true\"KUBE_LOG_LEVEL=\"--v=0\"KUBE_ALLOW_PRIV=\"--allow-privileged=false\"KUBE_MASTER=\"--master=http://172.16.100.11:8080\" 修改kubelet配置1234567# cat /etc/kubernetes/kubeletKUBELET_ADDRESS=\"--address=0.0.0.0\"KUBELET_PORT=\"--port=10250\"KUBELET_HOSTNAME=\"--hostname-override=172.16.100.101\"KUBELET_API_SERVER=\"--api-servers=http://172.16.100.11:8080\"KUBELET_POD_INFRA_CONTAINER=\"--pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest\"KUBELET_ARGS=\"\" 启动kube-proxy、kubelet、docker并查看其状态1234567for I in kube-proxy kubelet dockerdosystemctl enable $Isystemctl restart $Isystemctl status $Idoneiptables -P FORWARD ACCEPT K8S node1节点配置在node2节点上安装flannel、docker和Kubernetes1yum install kubernetes-node etcd docker flannel *rhsm* -y 配置node1节点etcd配置信息告诉flannel进程etcd服务的位置以及在etcd上网络配置信息的节点位置。 123456789101112# cat /etc/etcd/etc.confETCD_NAME=etcd3ETCD_DATA_DIR=\"/data/etcd\"ETCD_LISTEN_PEER_URLS=\"http://172.16.100.102:2380\"ETCD_LISTEN_CLIENT_URLS=\"http://172.16.100.102:2379,http://127.0.0.1:2379\"ETCD_MAX_SNAPSHOTS=\"5\"ETCD_INITIAL_ADVERTISE_PEER_URLS=\"http://172.16.100.102:2380\"ETCD_INITIAL_CLUSTER=\"etcd1=http://172.16.100.11:2380,etcd2=http://172.16.100.101:2380,etcd3=http://172.16.100.102:2380\"ETCD_ADVERTISE_CLIENT_URLS=\"http://172.16.100.102:2379\"# 创建etcd数据目录mkdir -p /data/etcd/;chmod 757 -R /data/etcd/ 修改/etc/kubernetes/config配置12345# cat /etc/kubernetes/configKUBE_LOGTOSTDERR=\"--logtostderr=true\"KUBE_LOG_LEVEL=\"--v=0\"KUBE_ALLOW_PRIV=\"--allow-privileged=false\"KUBE_MASTER=\"--master=http://172.16.100.11:8080\" 修改kubelet配置1234567# cat /etc/kubernetes/kubeletKUBELET_ADDRESS=\"--address=0.0.0.0\"KUBELET_PORT=\"--port=10250\"KUBELET_HOSTNAME=\"--hostname-override=172.16.100.102\"KUBELET_API_SERVER=\"--api-servers=http://172.16.100.11:8080\"KUBELET_POD_INFRA_CONTAINER=\"--pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest\"KUBELET_ARGS=\"\" 启动kube-proxy、kubelet、docker并查看其状态1234567for I in kube-proxy kubelet dockerdosystemctl enable $Isystemctl restart $Isystemctl status $Idoneiptables -P FORWARD ACCEPT K8S Flanneld网络配置k8s的node节点搭建和配置flannel网络，etcd中/atomic.io/network/config节点会被Node节点上的flannel用来创建Doker IP地址网段。k8s集群所有节点都需要配置flanneld网络，如下，配置完成之后依次重启flanneld。 123# cat /etc/sysconfig/flanneldFLANNEL_ETCD_ENDPOINTS=\"http://172.16.100.11:2379\"FLANNEL_ETCD_PREFIX=\"/atomic.io/network\" 重启flanneld失败，原因是etcd中没有创建flannel网络 创建flanneld网络1etcdctl mk /atomic.io/network/config '&#123;\"Network\":\"172.17.0.0/16\"&#125;' etcd使用在master节点上测试etcd集群是否正常 123456etcdctl member listetcdctl cluster-healthetcdctl get /atomic.io/network/configetcdctl ls /atomic.io/network/subnetsetcdctl rm /atomic.io/network/ --recursiveetcdctl mk /atomic.io/network/config &apos;&#123;&quot;Network&quot;:&quot;172.17.0.0/16&quot;&#125;&apos; K8S Dashborad UIk8s实现的最重要的工作是对Docker容器集群统一的管理和调度，通常使用命令行来操作Kubernetes集群及各个节点，命令行操作非常不方便，如果使用UI界面来可视化操作，会更加方便的管理和维护。 由于官网下载镜像太慢，提前下载好以下两个镜像： pod-infrastructure kubernetes-dashboard-amd64 Docker镜像导入并修改名称1234docker load &lt; pod-infrastructure.tgzdocker tag $(docker images|grep none|awk '&#123;print $3&#125;') registry.access.redhat.com/rhel7/pod-infrastructuredocker load &lt;kubernetes-dashboard-amd64.tgzdocker tag $(docker images|grep none|awk '&#123;print $3&#125;') bestwu/kubernetes-dashboard-amd64:v1.6.3 在master创建dashboard-controller.yaml1234567891011121314151617181920212223242526272829303132333435363738394041apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: kubernetes-dashboard namespace: kube-system labels: k8s-app: kubernetes-dashboard kubernetes.io/cluster-service: \"true\"spec: selector: matchLabels: k8s-app: kubernetes-dashboard template: metadata: labels: k8s-app: kubernetes-dashboard annotations: scheduler.alpha.kubernetes.io/critical-pod: '' scheduler.alpha.kubernetes.io/tolerations: '[&#123;\"key\":\"CriticalAddonsOnly\", \"operator\":\"Exists\"&#125;]' spec: containers: - name: kubernetes-dashboard image: bestwu/kubernetes-dashboard-amd64:v1.6.3 resources: # keep request = limit to keep this container in guaranteed class limits: cpu: 100m memory: 50Mi requests: cpu: 100m memory: 50Mi ports: - containerPort: 9090 args: - --apiserver-host=http://172.16.100.11:8080 livenessProbe: httpGet: path: / port: 9090 initialDelaySeconds: 30 timeoutSeconds: 30 在master上创建dashboard-service.yaml1234567891011121314apiVersion: v1kind: Servicemetadata: name: kubernetes-dashboard namespace: kube-system labels: k8s-app: kubernetes-dashboard kubernetes.io/cluster-service: \"true\"spec: selector: k8s-app: kubernetes-dashboard ports: - port: 80 targetPort: 9090 创建dashborad pods实例12kubectl create -f dashboard-controller.yamlkubectl create -f dashboard-service.yaml 查看pods和service信息因为默认查询到的namespace是default下的，所以需要指定namespace 12345678kubectl get namespacekubectl get deployment --all-namespaceskubectl get svc --all-namespaceskubectl get pods --all-namespaceskubectl get pod -o wide --all-namespaceskubectl describe service/kubernetes-dashboard --namespace=\"kube-system\"kubectl describe pod/kubernetes-dashboard-530803917-816df --namespace=\"kube-system\"kubectl delete pod/kubernetes-dashboard-530803917-816df --namespace=\"kube-system\" --grace-period=0 --force 访问k8s dasborad UI通过浏览器访问：http://172.16.100.11/ui 访问ui有问题提示 注意dashborad-controller.yaml中定义的apiserver-host 是否正确 使用iptables -P FORWARD ACCEPT","tags":[{"name":"容器","slug":"容器","permalink":"http://www.dookt.com/tags/容器/"}]},{"title":"Nginx设置为系统服务","date":"2019-07-31T11:17:37.000Z","path":"post/c6b0c30c.html","text":"通过官网下载NGinx源码安装部署时。每次都是需要手动进入安装目录下管理Nginx。很是麻烦，写个脚本实现Nginx应用的启动、停止、重载。并可以使用service来管理实现开机自启动。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#!/bin/bash# chkconfig: - 85 15# description: Nginx Web Server Dir=/usr/local/nginx/Config=/usr/local/nginx/sbin/nginxPidfile=/usr/local/nginx/logs/nginx.pid. /etc/init.d/functionsstart()&#123; if [ ! -f $Pidfile ];then $Config NUM=$? if [ $NUM -ne 0 ];then action \"NGINX starting...\" /bin/false return $NUM else action \"NGINX starting...\" /bin/true return $NUM fi else echo \"NGINX is running\" return $NUM fi&#125;stop() &#123; if [ -f $Pidfile ];then $Config -s stop NUM=$? if [ $NUM -ne 0 ];then action \"NGINX stopping...\" /bin/false return $NUM else action \"NGINX stopping...\" /bin/true return $NUM fi else echo \"NGINX is not running\" return $NUM fi&#125; status() &#123; if [ `ps -ef | grep nginx | grep -vc grep` -gt 1 ];then echo -e \"\\033[32mNGINX is running\\033[0m\" else echo -e \"\\033[31mNGINX is not running\\033[0m\" fi&#125;case $1 in start) start NUM=$? ;; stop) stop NUM=$? ;; restart) stop sleep 2 start NUM=$? ;; status) status ;; *) echo $\"Usage: $0 &#123;start|stop|restart|status&#125;\" exit 9 ;;esacexit $NUM","tags":[{"name":"Scripts","slug":"Scripts","permalink":"http://www.dookt.com/tags/Scripts/"},{"name":"Nginx","slug":"Nginx","permalink":"http://www.dookt.com/tags/Nginx/"}]},{"title":"Tomcat设置为系统服务","date":"2019-07-31T11:09:33.000Z","path":"post/a2c1797d.html","text":"通过官网下载Tomcat二进制包来安装部署Tomcat。每次都是需要手动进入bin目录下管理Tomcat程序。很是麻烦，写个脚本实现Tomcat应用的启动、停止。并可以使用service来管理。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#!/bin/bash# chkconfig: 2345 99 10# description: Tomcat service manage script. /etc/init.d/functionsexport JAVA_HOME=/usr/java/jdk1.8.0_112/export CATALINA_HOME=/opt/apache-tomcat-9.0.4Usage() &#123; echo $\"Usage: $0 &#123;start|stop|restart|status&#125;\" exit 0&#125;start() &#123; if [ -f $CATALINA_HOME/bin/startup.sh ];then $CATALINA_HOME/bin/startup.sh &amp;&gt; /dev/null NUM=$? if [ $NUM -eq 0 ];then action \"Tomcat started...\" /bin/true return $NUM else action \"Tomcat started...\" /bin/false return $NUM fi fi&#125;stop() &#123; if [ -f $CATALINA_HOME/bin/shutdown.sh ];then $CATALINA_HOME/bin/shutdown.sh &amp;&gt; /dev/null NUM=$? if [ $NUM -eq 0 ];then action \"Tomcat stopped...\" /bin/true return $NUM else action \"Tomcat stopped...\" /bin/false return $NUM fi fi&#125;status() &#123; if [ `ps -ef | grep java | grep -vc grep` -ge 1 ];then echo -e \"\\033[32mTomcat is running\\033[0m\" else echo -e \"\\033[31mTomcat is not running\\033[0m\" fi&#125;case \"$1\" in start) start NUM=$? ;; stop) stop NUM=$? ;; restart) stop sleep 2 start NUM=$? ;; status) status ;; *) Usage ;;esacexit $NUM","tags":[{"name":"Scripts","slug":"Scripts","permalink":"http://www.dookt.com/tags/Scripts/"},{"name":"Tomcat","slug":"Tomcat","permalink":"http://www.dookt.com/tags/Tomcat/"}]},{"title":"Python编写zabbix告警邮件","date":"2019-07-31T11:06:26.000Z","path":"post/7df7e5a.html","text":"使用Python编写一个脚本，实现zabbix邮件告警 123456789101112131415161718192021222324252627#!/usr/bin/python#coding:utf-8import smtplibfrom email.mime.text import MIMETextimport sysmail_host = 'smtp.163.com'mail_user = '1831317'mail_pass = '******'mail_postfix = '163.com'def send_mail(to_list,subject,content): me = \"zabbix监控告警平台\"+\"&lt;\"+mail_user+\"@\"+mail_postfix+\"&gt;\" msg = MIMEText(content, 'plain', 'utf-8') msg['Subject'] = subject msg['From'] = me msg['to'] = to_list try: s = smtplib.SMTP() s.connect(mail_host) s.login(mail_user,mail_pass) s.sendmail(me,to_list,msg.as_string()) s.close() return True except Exception,e: print str(e) return Falseif __name__ == \"__main__\": send_mail(sys.argv[1], sys.argv[2], sys.argv[3])","tags":[{"name":"Zabbix","slug":"Zabbix","permalink":"http://www.dookt.com/tags/Zabbix/"},{"name":"监控","slug":"监控","permalink":"http://www.dookt.com/tags/监控/"}]},{"title":"DockerFile生成镜像","date":"2019-07-31T11:01:46.000Z","path":"post/4120479c.html","text":"使用Dockerfile生成一个可以使用ssh的Centos基础镜像 12345678910111213FROM centos #指定基础镜像MAINTAINER mint#制定维护者RUN yum -y install passwd openssl openssh-server&amp;&amp; echo '123456'|passwd --stdin rootRUN ssh-keygen -q -t rsa -b 2048 -f /etc/ssh/ssh_host_rsa_key -N ''RUN ssh-keygen -q -t ecdsa -f /etc/ssh/ssh_host_ecdsa_key -N ''RUN sed -i '/^session\\s\\+required\\s\\+pam_loginuid.so/s/^/#/' /etc/pam.d/sshdRUN mkdir -p /root/.ssh &amp;&amp; chown root. /root &amp;&amp; chmod 700 /root/.ssh &amp;&amp; cp /etc/skel/.bash* /rootEXPOSE 22#暴露ssh端口CMD ip addr ls eth0|awk '&#123;print $2&#125;'|egrep -o '([0-9]+\\.)&#123;3&#125;[0-9]+';/usr/sbin/sshd -D#设定运行镜时,输出IP,并以daemon的方式启动sshd","tags":[{"name":"Docker","slug":"Docker","permalink":"http://www.dookt.com/tags/Docker/"}]},{"title":"Jenkins发布脚本","date":"2019-07-31T10:56:28.000Z","path":"post/d936a15c.html","text":"使用jenkins来进行业务升级、回滚、备份等功能 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250#!/bin/bash#定义变量#set -xAPPDIR=$2 #应用所在目录，/opt/appAPPNAME=$3 #应用名称，如test-llb-dubbo-21996ENV=$4 #如tdtp,ttspTOMCATWAR=$5 #Tomcat应用webapps下的内容SERVER_PORT=$6 #应用启动的端口，如21996TARDIR=/opt/package #应用tar包存放目录，如/opt/packageBAKDIR=/opt/backup #应用备份目录，如/opt/backup/LOGDIR=/opt/logs #应用日志目录，如/opt/logsBINDIR=$&#123;APPDIR&#125;/$&#123;APPNAME&#125;/bin #脚本所在目录，如/opt/app/test-llb-dubbo-20889/bin/DEPLOY_DIR=$&#123;APPDIR&#125;/$&#123;APPNAME&#125; #应用发布目录，如/opt/app/test-llb-dubbo-20889PARAMNUM=$# #传入的参数个数SCRIPTNAME=$0 #脚本名称#SHELLLOG=\"$&#123;LOGDIR&#125;/$&#123;SCRIPTNAME&#125;.log\" #存放脚本操作日志文件CONFIG_SERVER=172.16.100.11 #jenkins上的nginx服务器地址# 使用帮助function usage() &#123; if [[ $&#123;PARAMNUM&#125; -ne 6 ]];then echo \"Usage: $0 start|stop|restart|publish|rollback APPDIR APPNAME ENV TOMCATWAR SERVER_PORT\" exit 11 fi&#125;usage#start functionfunction start() &#123; PIDS=`ps -ef | grep java | grep \"$&#123;DEPLOY_DIR&#125;\" |awk '&#123;print $2&#125;'` #判断应用是否启动 if [[ -n \"$&#123;PIDS&#125;\" ]];then echo \"ERROR: The $&#123;APPNAME&#125; already started!\" echo \"PID: $PIDS\" return 1 fi chown -R app. /opt #判断端口是否被占用 if [[ -n $&#123;SERVER_PORT&#125; ]];then SERVER_PORT_COUNT=`netstat -tln | grep $&#123;SERVER_PORT&#125; | wc -l` if [[ $&#123;SERVER_PORT_COUNT&#125; -gt 0 ]]; then echo \"ERROR: The $&#123;APPNAME&#125; port $&#123;SERVER_PORT&#125; already used!\" return 2 fi fi #执行启动脚本 echo -e \"Starting the $&#123;APPNAME&#125; ...\\c\" sleep 2 #判断是不是dubbo应用 result=$(echo $&#123;APPNAME&#125;| grep -vE \"tomcat|bom\") if [[ \"$&#123;result&#125;\" != \"\" ]];then source /etc/profile &amp;&amp; cd $&#123;BINDIR&#125; &amp;&amp; /bin/bash $&#123;BINDIR&#125;/start.sh else source /etc/profile &amp;&amp; cd $&#123;BINDIR&#125; &amp;&amp; nohup /bin/bash $&#123;BINDIR&#125;/startup.sh &gt;/dev/null 2&gt;&amp;1 &amp; fi # 判断应用是否启动成功 COUNT=0 # 计算java 进程个数 flag=0 # 计算启动时间秒数 while [[ $&#123;COUNT&#125; -lt 1 ]]; do echo -e \".\\c\" # 等同于 echo -n \".\" sleep 1 if [[ -n \"$&#123;SERVER_PORT&#125;\" ]]; then COUNT=`netstat -ant | grep $&#123;SERVER_PORT&#125; | wc -l` else COUNT=`ps -f | grep java | grep \"$&#123;DEPLOY_DIR&#125;\" | awk '&#123;print $2&#125;' | wc -l` fi if [[ $&#123;COUNT&#125; -gt 0 ]]; then break fi # 判断启动30s后，端口或进程不存在，表示启动失败 flag=$[$&#123;flag&#125;+1] if [[ $&#123;flag&#125; -gt 30 ]] &amp;&amp; [[ $&#123;COUNT&#125; -eq 0 ]]; then echo \"应用启动失败\" exit 33 fi done #输出启动成功信息 echo \"OK!\" PIDS=`ps -f | grep java | grep \"$&#123;DEPLOY_DIR&#125;\" | awk '&#123;print $2&#125;'` echo \"Start $&#123;APPNAME&#125; Success, PID: $PIDS\"&#125;# stop functionfunction stop() &#123; PIDS=`ps -ef | grep java | grep \"$&#123;DEPLOY_DIR&#125;\" |awk '&#123;print $2&#125;'` #判断应用是否已经停止 if [[ -z \"$PIDS\" ]]; then echo \"ERROR: The $&#123;APPNAME&#125; does not started!\" return 4 fi #停止应用进程 echo -e \"Stopping the $&#123;APPNAME&#125; ...\\c\" for PID in $&#123;PIDS&#125; ; do kill $&#123;PID&#125; &gt; /dev/null 2&gt;&amp;1 done #判断应用是否停止成功，等待时间15s COUNT=0 while [[ $&#123;COUNT&#125; -lt 15 ]]; do echo -e \".\\c\" sleep 1 COUNT=$[$&#123;COUNT&#125;+1] done # 停止进程超过15s，直接kill -9 PIDS_EXIST=`ps -ef | grep java | grep \"$&#123;DEPLOY_DIR&#125;\" |awk '&#123;print $2&#125;'` echo $&#123;PIDS_EXIST&#125; if [[ -n \"$&#123;PIDS_EXIST&#125;\" ]]; then for PID in $&#123;PIDS_EXIST&#125; ; do kill -9 $&#123;PID&#125; &gt; /dev/null 2&gt;&amp;1 done fi # 输出停止成功信息 echo \"OK!\" echo \"Stop $&#123;APPNAME&#125; Success, PID: $PIDS\"&#125;# backup functionfunction backup() &#123; cd $&#123;APPDIR&#125; #判断应用目录是否存在 if [[ ! -d $&#123;APPNAME&#125; ]];then echo \"ERROR: $&#123;DEPLOY_DIR&#125; is not existed.\" return 5 fi mv $&#123;APPNAME&#125; $&#123;BAKDIR&#125;/$&#123;APPNAME&#125;_`date +%F_%T` #判断是否备份成功 if [[ $? -eq 0 ]];then echo \"Backup $&#123;APPNAME&#125; sucess!\" else echo \"Backup $&#123;APPNAME&#125; failed!\" exit 6 fi cd $&#123;BAKDIR&#125; find . -mtime +30 -name \"*$&#123;APPNAME&#125;*\" -exec rm -rf &#123;&#125; \\;&#125;#deploy functionfunction deploy() &#123; #解压需要更新的应用包到应用目录 #判断是否是dubbo应用 result=$(echo $&#123;APPNAME&#125;| grep -vE \"tomcat|bom\") if [[ \"$&#123;result&#125;\" != \"\" ]];then mkdir -p \"$&#123;APPDIR&#125;/$&#123;APPNAME&#125;\" cd $&#123;APPDIR&#125;/$&#123;APPNAME&#125; #下载应用包,解压文件夹 wget http://$&#123;CONFIG_SERVER&#125;/$&#123;ENV&#125;/$&#123;APPNAME&#125;.tar -O $&#123;TARDIR&#125;/$&#123;APPNAME&#125;.tar tar -xf $&#123;TARDIR&#125;/$&#123;APPNAME&#125;.tar -C $&#123;APPDIR&#125; sleep 3 if [[ ! -d $&#123;LOGDIR&#125; ]];then mkdir -p $&#123;LOGDIR&#125; fi #判断应用目录日志文件是否是软连接 if [[ ! -L $&#123;APPNAME&#125;/log ]];then #判断应用目录日志文件夹是否是文件夹 if [[ -d $&#123;APPNAME&#125;/logs ]]; then mv $&#123;APPNAME&#125;/logs/* $&#123;LOGDIR&#125; rmdir $&#123;APPNAME&#125;/logs fi ln -s $&#123;LOGDIR&#125; $&#123;APPDIR&#125;/$&#123;APPNAME&#125;/logs else echo \"日志文件已经是软链接\" fi else #如果是tomcat应用 #获取到tomcat包保存在包目录 wget http://$&#123;CONFIG_SERVER&#125;/tomcat-8.5.29.tar.gz -O $&#123;TARDIR&#125;/tomcat-8.5.29.tar.gz #判断是否存在tomcat应用目录 if [[ ! -d $&#123;APPDIR&#125;/$&#123;APPNAME&#125; ]];then #解压文件夹 cd $&#123;APPDIR&#125; &amp;&amp; tar xf $&#123;TARDIR&#125;/tomcat-8.5.29.tar.gz -C . &amp;&amp; rm -rf ./tomcat-8.5.29/webapps &amp;&amp; mv tomcat-8.5.29 $&#123;APPNAME&#125; wget http://$&#123;CONFIG_SERVER&#125;/$&#123;ENV&#125;/$&#123;APPNAME&#125;.tar -O $&#123;TARDIR&#125;/$&#123;APPNAME&#125;.tar cd $&#123;TARDIR&#125; &amp;&amp; tar xf $&#123;APPNAME&#125;.tar &amp;&amp; mv $&#123;APPNAME&#125;/webapps $&#123;APPDIR&#125;/$&#123;APPNAME&#125; &amp;&amp; rm -rf $&#123;APPNAME&#125; sleep 3 if [[ ! -d $&#123;LOGDIR&#125; ]];then mkdir -p $&#123;LOGDIR&#125; fi #判断应用目录日志文件是否是软连接 if [[ ! -L $&#123;APPNAME&#125;/log ]];then #判断应用目录日志文件夹是否是文件夹 if [[ -d $&#123;APPNAME&#125;/logs ]]; then mv $&#123;APPNAME&#125;/logs/* $&#123;LOGDIR&#125; rmdir $&#123;APPNAME&#125;/logs fi ln -s $&#123;LOGDIR&#125; $&#123;APPDIR&#125;/$&#123;APPNAME&#125;/logs else echo \"日志文件已经是软链接\" fi fi fi&#125;#rollback functionfunction rollback() &#123; cd $&#123;APPDIR&#125; result=$(echo $&#123;APPNAME&#125; | grep -vE \"tomcat|bom\") if [[ \"$&#123;result&#125;\" = \"\" ]];then [[ -d $&#123;APPNAME&#125; ]] &amp;&amp; rm -rf $&#123;APPNAME&#125; mv $&#123;BAKDIR&#125;/`ls -rht $&#123;BAKDIR&#125;|grep $&#123;APPNAME&#125;|tail -1` $&#123;APPNAME&#125; else [[ -d $&#123;APPNAME&#125; ]] &amp;&amp; rm -rf $&#123;APPNAME&#125;/webapps/ mv $&#123;BAKDIR&#125;/`ls -rht $&#123;BAKDIR&#125;|grep webapps|tail -1` $&#123;APPNAME&#125;/ fi #输出应用回滚成功信息 echo \"Rollback $&#123;APPNAME&#125; sucess!\"&#125;case $1 in start) start ;; stop) stop ;; restart) stop start ;; publish) stop backup deploy start ;; rollback) stop rollback start ;; *) usage ;;esac","tags":[{"name":"Scripts","slug":"Scripts","permalink":"http://www.dookt.com/tags/Scripts/"},{"name":"Jenkins","slug":"Jenkins","permalink":"http://www.dookt.com/tags/Jenkins/"}]},{"title":"k8s-一个简单的例子","date":"2019-07-31T02:14:21.000Z","path":"post/d6261197.html","text":"使用k8s部署一个Java WEB应用。该应用运行在Tomcat里的Web App。需要启动两个容器：WEB容器和MySQL容器，并且Web App需要访问MySQL容器。 环境准备使用vmware+centos7.2。安装系统完成之后，首先关闭防火墙，selinux，安装和下载k8s相关镜像，使用kubeadm快速安装一个k8s集群 宿主机IP：172.16.100.11 123456[root@spareribs ~]# systemctl stop firewalld[root@spareribs ~]# systemctl disable firewalld[root@spareribs ~]# sed '/SELINUX/s/enforcing/disabled/g' /etc/selinux/config[root@spareribs ~]# init 6 [root@spareribs ~]# yum -y install etcd kubernetes #会自动安装docker[root@spareribs ~]# systemctl restart etcd docker kube-apiserver kube-controller-manager kube-scheduler kubelet kube-proxy #需要按顺序启动 查看服务端口12ps -ef | grep -E \"kube|etcd|docker\"netstat -tnlp | grep -E \"kube|etcd|docker\" 启动MySQL服务定义MySQL RC文件参数解释 kind：资源对象类型，ReplicationController表示是一个RC spec：RC的相关属性定义 spec.selector：表示是RC的Pod标签（Label）选择器，即监控和管理拥有这些标签的Pod实例，确保当前集群上始终有且仅有replicas个Pod实例在运行 spec.replicas：表示Pod实例运行的数量 spec.template：当Pod数量小于replicas时，RC会根据spec.template定义的Pod模板来生成新的Pod实例 spec.template.matadata.labels：指定该Pod的标签，必须匹配之前的spec.selector，否则RC每次创建的Pod都无法被selector识别，到时候会成为一个死循环 12345678910111213141516171819202122# cat mysql-rc.yamlapiVersion: v1kind: ReplicationControllermetadata: name: mysqlspec: replicas: 1 selector: app: mysql template: metadata: labels: app: mysql spec: containers: - name: mysql image: mysql ports: - containerPort: 3306 env: - name: MYSQL_ROOT_PASSWORD value: '123456' 文件详解 kind：副本控制器RC metadata.name：RC的名称，全局唯一 spec.selector.app：符合目标的Pod拥有此标签 spec.replicas：Pod副本期待数目 spec.template：根据此模板创建Pod的实例 spec.template.matadata.labels：Pod实例拥有的标签，对应RC的selector spec.template.spec.containers：Pod实例内容器定义部分 spec.template.spec.containers.name：容器名字 spec.template.spec.containers.images：对应的docker镜像 spec.template.spec.containers.ports.containersPort：容器对应的端口号 spec.template.spec.containers.ports.env：注入到容器内的环境变量 发布MySQL RC文件到集群中12[root@k8s ~]# kubectl create -f mysql-rc.yaml replicationcontroller \"mysql\" created 查询mysql RC信息及mysql Pod信息1234567[root@k8s ~]# kubectl get rcNAME DESIRED CURRENT READY AGEmysql 1 1 1 1h[root@k8s ~]# kubectl get podsNAME READY STATUS RESTARTS AGEmysql-kl3bx 1/1 Running 0 1h 启动Pod失败解决方案发现Pod一直处于ContainCreating状态，可以使用kubectl describe pod mysql查看报错信息 image pull failed for registry.access.redhat.com/rhel7/pod-infrastructure:latest, this may be because there are no credentials on this request. details: (open /etc/docker/certs.d/registry.access.redhat.com/redhat-ca.crt: no such file or directory) yum install rhsm -y #测试不生效 使用如下方式解决 12[root@k8s ~]# wget http://mirror.centos.org/centos/7/os/x86_64/Packages/python-rhsm-certificates-1.19.10-1.el7_4.x86_64.rpm[root@k8s ~]# rpm2cpio python-rhsm-certificates-1.19.10-1.el7_4.x86_64.rpm | cpio -iv --to-stdout ./etc/rhsm/ca/redhat-uep.pem | tee /etc/rhsm/ca/redhat-uep.pem Failed to create pod infra container: ImagePullBackOff; Skipping pod “redis-master-jj6jw_default(fec25a87-cdbe-11e7-ba32-525400cae48b)”: Back-off pulling image “registry.access.redhat.com/rhel7/pod-infrastructure:lates” 1[root@k8s ~]# docker pull registry.access.redhat.com/rhel7/pod-infrastructure:latest 如果启动失败，需要先删除在创建 1234[root@k8s ~]# kubectl delete -f mysql-rc.yaml[root@k8s ~]# kubectl create -f mysql-rc.yaml[root@k8s ~]# kubectl get rc [root@k8s ~]# kubectl get pods 查看正在运行的容器此时会发现MySQL Pod对应的容器还多创建了一个来自谷歌的pause容器，这个就是Pod的根容器。 123[root@k8s ~]# docker ps | grep mysql3488f858c29a mysql \"docker-entrypoint...\" About an hour ago Up About an hour k8s_mysql.f6601b53_mysql-kl3bx_default_c3374963-b0c6-11e9-aca2-000c294094ee_89d776eeb5ac50286749 registry.access.redhat.com/rhel7/pod-infrastructure:latest \"/usr/bin/pod\" About an hour ago Up About an hour k8s_POD.1d520ba5_mysql-kl3bx_default_c3374963-b0c6-11e9-aca2-000c294094ee_85e02244 定义一个Service文件参数解释 metadata：是Service的服务名 spec.ports.port：定义了Service的虚拟端口 spec.selector：确定了那些Pod副本 12345678910# cat mysql-svc.yamlapiVersion: v1kind: Servicemetadata: name: mysqlspec: ports: - port: 3306 selector: app: mysql 文件详解 kind：标明k8s Services matadata.name：Service的全局唯一名称 spec.ports.port：Service提供服务的端口号 spec.selector：Service对应的Pod拥有这里定义的标签 发布MySQL SVC文件到集群中12[root@k8s ~]# kubectl create -f mysql-svc.yamlservice \"mysql\" created 查询svc文件信息1234[root@k8s ~]# kubectl get svcNAME CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes 10.254.0.1 &lt;none&gt; 443/TCP 2hmysql 10.254.202.48 &lt;none&gt; 3306/TCP 1h 启动Tomcat应用定义Tomcat RC文件12345678910111213141516171819202122# cat myweb-rc.yaml apiVersion: v1kind: ReplicationControllermetadata: name: mywebspec: replicas: 2 selector: app: myweb template: metadata: labels: app: myweb spec: containers: - name: myweb image: kubeguide/tomcat-app:v1 ports: - containerPort: 8080 env: - name: MYSQL_SERVICE_HOST value: 10.254.202.48 发布Tomcat RC文件到集群中12[root@k8s ~]# kubectl create -f myweb-rc.yamlreplicationcontroller \"myweb\" created 查询Tomcat RC信息及Pod信息12345678910[root@k8s k8s]# kubectl get rc NAME DESIRED CURRENT READY AGEmysql 1 1 1 1hmyweb 2 2 2 1h[root@k8s k8s]# kubectl get podNAME READY STATUS RESTARTS AGEmysql-kl3bx 1/1 Running 0 1hmyweb-djvx5 1/1 Running 0 1hmyweb-jcmz8 1/1 Running 0 1h 定义一个Service文件123456789101112# cat myweb-svc.yaml apiVersion: v1kind: Servicemetadata: name: mywebspec: type: NodePort ports: - port: 8080 nodePort: 30001 selector: app: myweb 发布Tomcat SVC文件到集群中12[root@k8s ~]# kubectl create -f myweb-svc.yamlservice \"myweb\" created 查看Tomcat SVC信息123456[root@k8s k8s]# kubectl get svcNAME CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes 10.254.0.1 &lt;none&gt; 443/TCP 2hmysql 10.254.202.48 &lt;none&gt; 3306/TCP 1hmyweb 10.254.128.72 &lt;nodes&gt; 8080:30001/TCP 1h[root@k8s k8s]# 访问测试 使用curl 10.254.128.72 8080可以正常访问tomat 使用curl 172.16.100.11 30001却访问不了 12#使用该命令即可解决问题[root@k8s k8s]# iptables -P FORWARD ACCEPT","tags":[{"name":"容器","slug":"容器","permalink":"http://www.dookt.com/tags/容器/"}]},{"title":"Mysql设置权限","date":"2019-07-26T14:25:22.000Z","path":"post/41380.html","text":"MySQL是由列级别权限存在的。实现了限制用户对表上特定列的访问权限。一般都是实现对表级别不具备访问权限，但是对某些列有访问权限。当然也存在其他情形。 使用物理工具备份可能需要的权限 物理备份工具：innobackupex，MySQL Enterprise Backup等等 权限lock tables 作用：备份时锁表，产生一致性备份 权限process 作用：show processlist,show engine innodb status,查看线程，查看引擎状态 权限reload 作用：flush table/host/logs/tables/status/threads/refresh/reload，所有的flush操作。用于锁表，切割日志，更新权限 权限：replication client 作用：show master/slave status;查看事务日志执行状态与位置 show binary logs；查看当前保存的事务日志列表与文件大小 权限：super 作用：super权限很多很多，但是没有CURD（增删改查权限），这里点到为止说一下和备份相关的起停复制线程，切换主库位置，更改复制过滤条件，清理二进制日志，赋予账户视图与存储过程的DEFINER权限，创建链接服务器（类似于MSSQL的订阅服务器），关闭线程，不受最大连接线程数限制的VIP连接通道，阻断刷新线程的命令，不受离线模式影响， 12grant lock tables,reload,process,replication client,super,select,event,trigger,show view on *.* to bak@'192.168.%';flush privileges; 使用逻辑备份工具可能需要的权限 逻辑备份工具：mysqldump,mysqlpump,mydumper等等 权限SELECT 作用：查询表中数据 权限SHOW VIEW 作用：查看创建视图的语句 权限TRIGGER 作用：备份触发器 权限EVENT 作用：备份事件（定时任务） 权限lock tables 作用：备份时锁表，产生一致性备份 权限reload 作用：show processlist,show engine innodb status,查看线程，查看引擎状态 权限replication client 作用：show master/slave status;查看事务日志执行状态与位置 show binary logs；查看当前保存的事务日志列表与文件大小 权限：super 作用：关闭线程，不受最大连接线程数限制的VIP连接通道，阻断刷新线程的命令，不受离线模式影响 12grant lock tables,reload,process,replication client,super,select,event,trigger,show view on *.* to bak@'192.168.%';flush privileges; 备注： super权限可以防止因为线程满，备份任务无法连接数据库而导致的备份翻车。且阻断刷新线程也是很重要 innobackupex主要以物理文件和备份缓存文件的方式进行，所以不需要show权限与select权限逻辑备份的基本原理就是数据全部读取，必须select与show权限，查看表定义的权限由select权限提供 login-path的以port+host的方式保存时，会在用户目录下生成.login.cnf文件，拷贝到网络互通的其他主机上，仍然可以登陆，方便的同时也留下祸根","tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.dookt.com/tags/数据库/"}]},{"title":"Docker实战","date":"2019-07-26T14:17:23.000Z","path":"post/11988.html","text":"Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的linux机器上，也可以实现虚拟化。Docker虚拟化有三个概念需要理解，分别镜像、容器、仓库。 镜像：Docker的镜像其实就是模板，跟我们常见的ISO镜像类似，是一个样板。Docker镜像作为docker中最基本的概念，一个完整的Docker镜像可以支撑一个Docker容器的运行，在Docker容器运行过程中主要提供文件系统数据支撑。有以下几个特性： - 镜像分层，每个镜像都由一个或多个镜像层组成； - 可通过在某个镜像加上一定的镜像层得到新镜像（此过程可通过编写dockerfile或基于容器Commit实现） - 每个镜像层拥有唯一镜像ID - 镜像在存储和使用时共享相同的镜像层（根据ID），所以在pull镜像时，已有的镜像层会自动跳过下载； - 每个镜像层都是只读，即使启动成容器，也无法对其真正的修改，修改只会作用于最上层的容器层；容器：使用镜像常见的应用或者系统，我们称之为一个容器。（通俗来说，镜像运行起来叫容器）仓库：仓库是存放镜像的地方，分为公开仓库（Public）和私有仓库（Private）两种形式。 注：以下环境全部基于Centos7.* 安装docker引擎123456systemctl enable docekrsed -i s/SELINUX/enforcing/disabled/g /etc/selinux/confsetenforce 0systemctl disable firewald systemctl stop firewalldreboot docker常用命令123456789101112131415161718192021docker version #查看版本docker search centos#搜索可用docker镜像docker images 查看当前docker所有镜像docker pull centos #下载镜像cat centos.tar | docker import - centos6_newname #Docker导入镜像docker export 容器_id &gt; cenos6.tar #Docker导出镜像docker run centos echo \"hello word\"#在docker容器中运行hello world!docker run centos yum install ntpdate#在容器中安装ntpdate的程序docker ps -l 命令获得最后一个容器的id，docker ps -a查看所有的容器。运行docker commit 提交刚修改的容器，例如：docker commit 2313132 centos:v1docker run -i -t -d centos /bin/bash 在容器里启动一个/bin/bash shell环境，可以登录进入操作，其中-t tty，表示打开一个终端的意思，-i interactive，表示可以交互输入,-d表示在后台启动，以daemon方式启动。 docker run -d centos:v1 /bin/bash Docker stop id 关闭容器Docker start id 启动某个容器docker rm id 删除容器，docker rmi images删除镜像docker run -d -p 80:80 -p 8022:22 centos:v2，解析：-p指定容器启动后docker上运行的端口映射及容器里运行的端口，80:80，第一个80表示docker系统上的80，第二个80表示docker虚拟机里面的端口。用户默认访问本机80端口，自动映射到容器里面的80端口。docker exec -it id /bin/bash 进入容器终端docker exec id ifconfig查看容器的IP地址；Docker inspect id |grep -i ipaddr查看容器IP地址；Docker exec df -h查看容器的磁盘分区信息 docker和docker-ce修改国内镜像源 docker配置国内镜像源 1234cat /etc/docker/daemon.json &#123; \"registry-mirrors\": \\[\"https://registry.docker-cn.com\"\\] &#125; docker-ce配置国内镜像源编辑docker-ce启动脚本/usr/lib/systemd/system/docker.service，在ExecStart=/usr/bin/dockerd后添加docker仓库源 12ExecStart=/usr/bin/dockerd --registry-mirror=https://jxus37ad.mirror.aliyuncs.comsystemctl restart docker docker网络模式基于docker run 创建Docker容器时，可以使用–net选项制定容器的网络模式，Docker默认四种网络模式：host、container、none、bridge（–net=host, –net=container , –net=none –net=bridge） host模式：Docker容器运行时，会默认分配独立的network Namespace，用于隔离子系统，基于host模式时，容器将不会获得独立的Network Namespace。将与宿主机共用一个Netework Namespace，不会配置IP地址，而是使用宿主机的IP地址 container模式：新创建的容器和已经存在的容器共享一个Network Namespace，而不是和宿主机共享，依赖与第一个存在的容器 none模式：容器拥有自己的Network Namespace，但是不对Docker 容器进行任何网路配置，也就是说该Docker容器没有网卡、IP、路由等信息，需要手工为Docker容器添加网卡、配置IP等，典型Pipework工具为Docker容器指定IP等信息； bridge模式：Bridge模式是Docker默认的网络模式，该模式会为每一个容器分配Network Namespace、设置IP、路由等配置，默认会将Docker容器连接到一个虚拟网桥交换机Docker0上。 首先宿主机上创建一对虚拟网卡veth pair设备，veth设备总是成对出现的，组成了一个数据的通道，数据从一个设备进入，就会从另一个设备出来，veth设备常用来连接两个网络设备。 Docker将veth pair设备的一端放在新创建的容器中，并命名为eth0，然后将另一端放在宿主机中，以vethxxx这样类似的名字命名，并将这个网络设备加入到docker0网桥中，可以通过brctl show命令查看。 从docker0子网中分配一个IP给容器使用，并设置docker0的IP地址为容器的默认网关。 此时容器IP与宿主机能够通信，宿主机也可以访问容器中的IP地址，在Bridge模式下，连在同一网桥上的容器之间可以相互通信，同时容器也可以访问外网，但是其他物理机不能访问docker容器IP，需要通过NAT将容器IP的port映射为宿主机的IP和port。 docker配置bridge网络Centos7下docker使用桥接模式非常简单，当然我们借助 大牛 写的pipework工具实现 安装pipework工具 12git clone https://github.com/jpetazzo/pipework /usr/local/pipeworkcp ~/pipework/pipework /usr/local/bin/ 启动一个docker容器 注意一定要加上–net=none（分配网络空间但不配置IP地址） docker run -itd –net=none nginx #启动一个Nginx容器 使用pipework配置桥接网络 docker ps -a #查看刚刚启动的Nginx的容器ID # “677dd7beac02”为Nginx的容器ID，以此为IP地址、掩码、网关。注意网关一定是docker宿主机的IP地址 pipework br0 677dd7beac02 192.168.2.103/24@192.168.2.253 Dockerfile实战由于Docker官网公共仓库镜像大多不完整，无法真正满足企业的生产环境系统，此时需要我们自行定制镜像或者重新打包镜像。Docker镜像制作是管理员的必备工作之一，Docker镜像制作的方法主要有两种，制作方法如下：Docker commit|export将新容器提交至Images列表；编写Dockerfile，bulid新的镜像至镜像列表； 本例，基础镜像采用 docker.io/lemonbar/centos6-ssh 运行一个基础镜像来启动一个容器，修改相应配置，并使用docker commit提交 12345678910111213141516171819202122232425docker run -itd docker.io/lemonbar/centos6-ssh #启动镜像docker exec -it 44b3fb717f9f /bin/bash #进去刚启动的容器中rm /etc/yum.repos.d/*.repo;wget -c http://mirrors.aliyun.com/repo/Centos-6.repo # 在容器中中执行，更换阿里云镜像源docker commit 44b3fb717f9f centos-test:v1 #在宿主机上提交``` - 根据需求编写Dockerfile文件```shell###生成nginx镜像#设置基本镜像FROM centos-test:v1#作者信息MAINTAINER MINT#设置工作目录WORKDIR /rootRUN cp /etc/skel/.bash* /rootRUN echo '123456'|passwd --stdin rootRUN rpm --rebuilddb &amp;&amp; yum -y install tar vim wget gcc gcc-c++ make pcre pcre-devel zlib zlib-devel gzip* bzip* net-tools ntpdateRUN wget -c http://nginx.org/download/nginx-1.12.2.tar.gz;tar -xf nginx-1.12.2.tar.gz;cd nginx-1.12.2;./configure --prefix=/usr/local/nginx &amp;&amp; make &amp;&amp; make install#暴露端口EXPOSE 22 80#设置运行镜像时的默认命令CMD /usr/local/nginx/sbin/nginx; /usr/sbin/sshd -D 123456789101112131415###生成redis镜像#设置基本镜像FROM centos-test:v2#作者信息MAINTAINER MINT#设置工作目录WORKDIR /rootRUN cp /etc/skel/.bash* /rootRUN echo '123456'|passwd --stdin rootRUN rpm --rebuilddb &amp;&amp; yum -y install wget tar gcc gcc-c++ makeRUN tar -xf redis-4.0.10.tar.gz;cd redis-4.0.10;make PREFIX=/usr/local/redis install#暴露端口EXPOSE 22 6379#设置运行镜像时的默认命令CMD /usr/local/redis/bin/redis-server; /usr/sbin/sshd -D 使用docker build 生成新镜像 12docker build -t centos-nginx . docker build -t centos-redis -f /root/Docker-redis #指定redis的dockerfile","tags":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://www.dookt.com/tags/虚拟化/"}]},{"title":"Mycat+MySQL读写分离","date":"2019-07-26T14:03:59.000Z","path":"post/35152.html","text":"随着互联网时代的发展，传统的数据库技术日趋成熟、计算机网络技术的飞速发展和应用范围的扩充，数据库应用已经普遍建立于计算机网络之上。此时集中式数据库系统表现出它的不足： 集中式处理，势必造成性能瓶颈； 应用程序集中在一台计算机上运行，一旦该计算机发生故障，则整个系统受到影响，可靠性不高； 集中式处理引起系统的规模和配置都不够灵活，系统的可扩充性差。 在这种形势下，集中式数据库将向分布式数据库发展。 MyCAT发展历程 MyCAT的诞生，要从其前身Amoeba和Cobar说起，Amoeba（变形虫）项目，该开源框架于2008年开始发布一款 Amoeba for Mysql软件。这个软件致力于MySQL的分布式数据库前端代理层，它主要在应用层访问MySQL的时候充当SQL路由功能，专注于分布式数据库代理层（Database Proxy）开发。 座落与 Client、DB Server(s)之间，对客户端透明。具有负载均衡、高可用性、SQL过滤、读写分离、可路由相关的到目标数据库、可并发请求多台数据库合并结果。 通过Amoeba你能够完成多数据源的高可用、负载均衡、数据切片的功能，目前Amoeba已在很多企业的生产线上面使用。 阿里巴巴于2012年6月19日，正式对外开源的数据库中间件Cobar，前身是早已经开源的Amoeba，不过其作者陈思儒离职去盛大之后，阿里巴巴内部考虑到Amoeba的稳定性、性能和功能支持，以及其他因素，重新设立了一个项目组并且更换名称为Cobar。[Cobar](https://github.com/alibaba/cobar&quot; \\t “_blank) 是由 Alibaba 开源的 MySQL 分布式处理中间件，它可以在分布式的环境下看上去像传统数据库一样提供海量数据服务。 Cobar自诞生之日起， 就受到广大程序员的追捧，但是自2013年后，几乎没有后续更新。在此情况下，MyCAT应运而生，它基于阿里开源的Cobar产品而研发，Cobar的稳定性、可靠性、优秀的架构和性能，以及众多成熟的使用案例使得MyCAT一开始就拥有一个很好的起点，站在巨人的肩膀上，MyCAT能看到更远。目前MyCAT的最新发布版本为1.6版本。 从定义和分类来看，MyCAT是一个开源的分布式数据库系统，是一个实现了MySQL协议的Server，前端用户可以把它看做是一个数据库代理中间件，基于MySQL客户端工具和命令行访问，其后端可以用MySQL原生（Native）协议与多个MySQL服务器通信，也可以用JDBC协议与大多数主流数据库服务器通信，其核心功能是分库分表，即将一个大表水平分割为N个小表，存储在后端MySQL服务器里或者其他数据库里。 Mycat发展到目前版本，已经不在是一个单纯的MySQL代理，它的后端可以支持MySQL、SQL Server、Oracle、DB2、PostgreSQL等主流数据库，也支持MongoDB这种新型NOSQL方式的存储，未来还会支持更多类型的存储。 最终用户看来，无论是那种存储方式，在Mycat里，都是一个传统的数据库表，支持标准的SQL语句进行数据的操作，对前端业务系统来说，可以大幅度降低开发难度，提升开发速度，在测试阶段，可以将一表定义为任何一种Mycat支持的存储方式，比如MySQL的MyASM表、内存表、或者MongoDB、LeveIDB以及号称是世界上最快的内存数据库MemSQL上。 DBA眼中的MyCATMycat就是MySQL Server，而Mycat后面连接的MySQL Server，就好象是MySQL的存储引擎,如InnoDB，MyISAM等，因此，Mycat本身并不存储数据，数据是在后端的MySQL上存储的，因此数据可靠性以及事务等都是MySQL保证的，简单的说，Mycat就是MySQL最佳伴侣，它在一定程度上让MySQL拥有了能跟Oracle PK的能力。 软件工程师眼中的MyCATMycat就是一个近似等于MySQL的数据库服务器，你可以用连接MySQL的方式去连接Mycat（除了端口不同，默认的Mycat端口是8066而非MySQL的3306，因此需要在连接字符串上增加端口信息），大多数情况下，可以用你熟悉的对象映射框架使用Mycat，但建议对于分片表，尽量使用基础的SQL语句，因为这样能达到最佳性能，特别是几千万甚至几百亿条记录的情况下。 架构师眼中的MyCATMycat是一个强大的数据库中间件，不仅仅可以用作读写分离、以及分表分库、容灾备份，而且可以用于多租户应用开发、云平台基础设施、让你的架构具备很强的适应性和灵活性，借助于即将发布的Mycat智能优化模块，系统的数据访问瓶颈和热点一目了然，根据这些统计分析数据，你可以自动或手工调整后端存储，将不同的表映射到不同存储引擎上，而整个应用的代码一行也不用改变。 MyCAT中间件原理 Mycat的原理中最重要的一个动词是“拦截”，它拦截了用户发送过来的SQL语句，首先对SQL语句做了一些特定的分析：如分片分析、路由分析、读写分离分析、缓存分析等，然后将此SQL发往后端的真实数据库，并将返回的结果做适当的处理，最终再返回给用户。 Orders表被分为三个分片datanode（简称dn)，这三个分片是分布在两台MySQL Server上(DataHost)，即datanode=database@datahost方式，因此你可以用一台到N台服务器来分片，分片规则为（sharding rule)典型的字符串枚举分片规则，一个规则的定义是分片字段（sharding column)+分片函数(rule function)，这里的分片字段为rov而分片函数为字符串枚举方式。 当Mycat收到一个SQL时，会先解析这个SQL，查找涉及到的表，然后看此表的定义，如果有分片规则，则获取到SQL里分片字段的值，并匹配分片函数，得到该QL对应的分片列表，然后将SQL发往这些分片去执行，最后收集和处理所有分片返回的结果数据，并输出到客户端。 以select * from Orders where prov=?语句为例，查到prov=wuhan，按照分片函数，wuhan返回dn1，于是SQL就发给了MySQL1，去取DB1上的查询结果，并返回给用户。 如果上述SQL改为elect * from Orders where prov in (‘wuhan’,‘beijing’)，那么，SQL就会发给ySQL1与MySQL2去执行，然后结果集合并后输出给用户。 通常业务中我们的SQL会有Order By 以及Limit翻页语法，此时就涉及到结果集在Mycat端的二次处理，这部分的代码也比较复杂，而最复杂的则属两个表的Jion问题，为此，Mycat提出了创新性的ER分片、全局表、HBT（Human Brain Tech)人工智能的Catlet、以及结合Storm/Spark引擎等十八般武艺的解决办法，从而成为目前业界最强大的方案，这就是开源的力量。 MyCAT应用场景 Mycat发展到现在，适用的场景已经很丰富，而且不断有新用户给出新的创新性的方案，以下是几个典型的应用场景： 单纯的读写分离，此时配置最为简单，支持读写分离，主从切换； 分表分库，对于超过1000万的表进行分片，最大支持1000亿的单表分片； 多租户应用，每个应用一个库，但应用程序只连接Mycat,从而不改造程序本身，实现多租户化； 报表系统，借助于Mycat的分表能力，处理大规模报表的统计； 代替Hbase,分析大数据； 作为海量数据实时查询的一种简单有效方案，比如 1〇〇亿条频繁查询的记录需要在3秒内查询出来结果，除了基于主键的查询，还可能存在范围查询或其他属性查询，此时Mycat可能是最简单有效的选择； 单纯的MyCAT读写分离，配置最为简单，支持读写分离，主从切换分表分库，对于超过1000万的表进行分片，最大支持1000亿的单表分片； 多租户应用，每个应用一个库，但应用程序只连接Mycat，从而不改造程序本身，实现多租户化； 报表系统，借助于Mycat的分表能力，处理大规模报表的统计替代Hbase，分析大数据，作为海量数据实时查询的一种简单有效方案，比如100亿条频繁查询的记录需要在3秒内查询出来结果，除了基于主键的查询，还可能存在范围查询或其他属性查询，此时Mycat可能是最简单有效的选择 。 Mycat概念详解Mycat是一个开源的分布式数据库系统，但是由于真正的数据库需要存储引擎，而Mycat并没有存储引擎，所以并不是完全意义的分布式数据库系统。 MyCAT数据库中间件那么Mycat是什么？Mycat是数据库中间件，就是介于数据库与应用之间，进行数据处理与交互的中间服务。对数据进行分片处理之后，从原有的一个库，被切分为多个分片数据库，所有的分片数据库集群构成了整个完整的数据库存储。 数据被分到多个分片数据库后，应用如果需要读取数据，就要需要处理多个数据源的数据。如果没有数据库中间件，那么应用将直接面对分片集群，数据源切换、事务处理、数据聚合都需要应用直接处理，原本该是专注于业务的应用，将会花大量的工作来处理分片后的问题，最重要的是每个应用处理将是完全的重复造轮子。 加入数据库中间件之后，应用只需要集中与业务处理，大量的通用的数据聚合，事务，数据源切换都由中间件来处理，中间件的性能与处理能力将直接决定应用的读写性能，所以一款好的数据库中间件至关重要。 MyCAT逻辑库(schema)通常对实际应用来说，并不需要知道中间件的存在，开发人员只需要知道数据库的概念，所以数据库中间件可以被看做是一个或多个数据库集群构成的逻辑库。 在云计算时代，数据库中间件可以以多租户的形式给一个或多个应用提供服务，每个应用访问的可能是一个独立或者是共享的物理库，常见的如阿里云数据库服务器RDS。 MyCAT逻辑表（Table)MyCAT既然有逻辑库，那么就会有逻辑表，分布式数据库中，对应用来说，读写数据的表就是逻辑表。逻辑表，可 以是数据切分后，分布在一个或多个分片库中，也可以不做数据切分，不分片，只有一个表构成。 MyCAT分片表MyCAT分片表，是指那些原有的很大数据的表，需要切分到多个数据库的表，这样，每个分片都有一部分数据，所有分片构成了完整的数据； 例如在Mycat配置中的t_node就属于分片表，数据按照规则被分到dn1,dn2两个分片节点(dataNode) 上。 MyCAT非分片表如果一个数据库中并不是所有的表都很大，某些表是可以不用进行切分的，非分片是相对分片表来说的，就是那些不需要进行数据切分的表。如下配置中t_node ,只存在于分片节点（dataNode ) dn1上。 MyCAT ER表关系型数据库是基于实体关系模型（Entity-Relationship Model)之上，通过其描述了真实世界中事物与关 系，Mycat中的ER表即是来源于此，根据这一思路，提出了基于E-R关系的数捤分片策略，子表的记录与所关 联的父表记录存放在同一个数据分片上，即子表依赖于父表，通过表分组（Table Group )保证数据Join不会跨库操作。 表分组（Table Group )是解决跨分片数据join的一种很好的思路，也是数据切分规划的重要一条规则。 MyCAT全局表一个真实的业务系统中，往往存在大量的类似字典表的表，这些表基本上很少变动，字典表具有以下几个特性： 变动不频繁； 数据量总体变化不大； 数据规模不大，很少有超过数十万条记录； 分片节点(dataNode)MyCAT数据切分后，一个大表被分到不同的分片数据库上面，每个表分片所在的数据库就是分片节点 (dataNode )。 节点主机(dataHost)MyCAT数据切分后，每个分片节点（dataNode )不一定都会独占一台机器，同一机器上面可以有多个分片数据库， 这样一个或多个分片节点（dataNode )所在的机器就是节点主机（dataHost),为了规避单节点主机并发数限 制，尽量将读写压力高的分片节点（dataNode )均衡的放在不同的节点主机（dataHost )。 分片规则(rule)MyCAT数据切分，1个大表被分成若干个分片表，就需要一定的规则，这样按照某种业务规则把数据分到 某个分片的规则就是分片规则，数据切分选择合适的分片规则非常重要，将极大的避免后续数据处理的难度。 MyCAT多租户多租户技术或称多重租赁技术，是一种软件架构技术，它是在探讨与实现如何于多用户的环境下共用相同的系统或程序组件，并且仍可确保各用户间数据的隔离性。 在云计算时代，多租户技术在共用的数据中心以单一系统架构与服务提供多数客户端相同甚至可定制化的服务，并且仍然可以保障客户的数据隔离。 目前各种各样的云计算服务就是这类技术范畴，例如阿里云数据库服务（RDS )、阿里云服务器(ECS)等等。 数据多租户方案目前互联网多租户在数据存储上存在三种主要的方案，独立数据库、共享数据库及共享数据库共享架构； 独立数据库多租户第一种方案，即一个租户一个数据库，这种方案的用户数据隔离级别最高，安全性最好，但成本也高。 该方案优点： 为不同的租户提供独立的数据库，有助于简化数据模型的扩展设计，满足不同租户的独特需求； 如果出现故障，恢复数据比较简单。- 该方案缺点： 增大了数据库的安装数量； 数据库维护成本和购置成本的增加。 这种方案与传统的一个客户、一套数据、一套部署类似，差别只在于软件统一部署在运营商那里。如果面对的是银行、医院等需要非常高数据隔离级别的租户，可以选择这种模式，提高租用的定价。如果定价较低，产品 走低价路线，这种方案一般对运营商来说是无法承受的。 共享数据库，隔离数据架构多租户第二种方案，即多个或所有租户共享Database，但是每个租户一个Schema。 该方案优点： 为安全性要求较高的租户提供了一定程度的逻辑数据隔离，并不是完全隔离； 每个数据库可以支持更多的租户数量。 该方案缺点： 如果出现故障，数据恢复比较困难，因为恢复数据库将牵扯到其它租户的数据； 如果需要跨租户统计数据，存在一定困难。 共享数据库，共享数据架构多租户第三种方案，即租户共享同一个Database、同一个Schema，但在表中通过TenantID区分租户的数据，这是共享程度最高、隔离级别最低的模式。 该方案优点： 三种方案比较，第三种方案的维护和购置成本最低； 允许每个数据库支持的租户数量最多。 该方案缺点： 隔离级别最低，安全性最低，需要在设计开发时加大对安全的开发量； 数据备份和恢复最困难，需要逐表逐条备份和还原。 如果希望以最少的服务器为最多的租户提供服务，并且租户接受以牺牲隔离级别换取降低成本，这种方案最适合； MyCAT数据切分简单来说，就是指通过某种特定的条件，将我们存放在同一个数据库中的数据分散存放到多个数据库（主 机）上面，以达到分散单台设备负载的效果。数据的切分(Sharding )根据其切分规则的类型，可以分为两种切分模式： 按照不同的表（或者 Schema )来切分到不同的数据库(主机）之上，这种切可以称之为数据的垂直（纵向）切分； 根据表中的数据的逻辑关系，将同一个表中的数据按照某种条件拆分到多台数据库（主机）上面，这种切分称之为数据的水平（横向）切分。 垂直切分的最大特点就是规则简单，实施也更为方便，尤其适合各业务之间的耦合度非常低，相互影响很小，业务逻辑非常清晰的系统。在这种系统中，可以很容易做到将不同业务模块所使用的表分拆到不同的数据库中。根据不同的表来进行拆分，对应用程序的影响也更小，拆分规则也会比较简单清晰。 水平切分于垂直切分相比，相对来说稍微复杂一些。因为要将同一个表中的不同数据拆分到不同的据库中，对于应用程序来说，拆分规则本身就较根据表名来拆分更为复杂，后期的数据维护也会更为复杂一些。 垂直切分数据库由很多表的构成，每个表对应着不同的业务，垂直切分是指按照业务将表进行分类，分布到不同 的数据库上面，这样也就将数据或者说压力分担到不同的库上面， 一个架构设计较好的应用系统，其总体功能肯定是由很多个功能模块所组成的，而每一个功能模块所需要的 数据对应到数据库中就是一个或者多个表。而在架构设计中，各个功能模块相互之间的交互点越统一越少，系统 的耦合度就越低，系统各个模块的维护性以及扩展性也就越好。这样的系统，实现数据的垂直切分也就越容易。 往往系统之有些表难以做到完全的独立，存在这扩库join的情况，对于这类的表，就需要去做平衡，是数据库让步业务，共用一个数据源，还是分成多个库，业务之间通过接口来做调用。在系统初期，数据量比较少，或者资源有限的情况下，会选择共用数据源，但是当数据发展到了一定的规模，负载很大的情况，就需要必须去做分割。 一般来讲业务存在着复杂join的场景是难以切分的，往往业务独立的易于切分。如何切分，切分到何种 程度是考验技术架构的一个难题。 垂直切分的优点： 拆分后业务清晰，拆分规则明确； 系统之间整合或扩展容易； 数据维护简单。 垂直切分的缺点： 部分业务表无法join ,只能通过接口方式解决，提高了系统复杂度； 受每种业务不同的限制存在单库性能瓶颈，不易扩展跟性能提高。 事务处理复杂。由于垂直切分是按照业务的分类将表分散到不同的库，所以有些业务表会过于庞大，存在单库读写与存储瓶颈，所以就需要水平拆分来做解决。 水平切分相对于垂直拆分，水平拆分不是将表做分类，而是按照某个字段的某种规则来分散到多个库之中，每个表中包含一部分数据。简单来说，我们可以将数据的水平切分理解为是按照数据行的切分，就是将表中的某些行切分 到一个数据库，而另外的某些行又切分到其他的数据库中，如图： 拆分数据就需要定义分片规则。关系型数据库是行列的二维模型，拆分的第一原则是找到拆分维度。比如: 从会员的角度来分析，商户订单交易类系统中查询会员某天期某个订单，那么就需要按照会员结合日期来拆分，不同的数据按照会员ID做分组，这样所有的数据查询join都会在单库内解决； 如果从商户的角度来讲，要查询某个商家某天所有的订单数，就需要按照商户ID做拆分；但是如果系统既想按会员拆分，又想按商家数据，则会有一定的困难。如何找到合适的分片规则需要综合考虑衡量。 典型的分片规则 按照用户ID求模，将数据分散到不同的数据库，具有相同数据用户的数据都被分散一个库中； 按照日期，将不同月甚至日的数据分散到不同的库中； 按照某个特定的字段求模，或者根据特定范围段分散到不同的库中。 如图，切分原则都是根据业务找到适合的切分规则分散到不同的库，下面用用户 ID 求模举例： 既然数据做了拆分有优点也就优缺点。 数据库拆分优点： 拆分规则抽象好，join 操作基本可以数据库做； 不存在单库大数据，高并发的性能瓶颈； 应用端改造较少； 提高了系统的稳定性跟负载能力。 数据库拆分缺点： 拆分规则难以抽象； 分片亊务一致性难以解决； 数捤多次扩展难度跟维护量极大； 跨库 join 性能较差。 垂直切分、水平切分共同的缺点： 引入分布式亊务的问题； 跨节点 Join 的问题； 跨节点合并排序分页问题； 多数据源管理问题； 针对数据源管理，目前主要有两种思路： 客户端模式，在每个应用程序模块中配置管理自己需要的一个（或者多个）数据源，直接访问各个数据库，在模块内完成数据的整合； 通过中间代理层来统一管理所有的数据源，后端数据库集群对前端应用程序透明，可能 90%以上的人在面对上面这两种解决思路的时候都会倾向于选择第二种，尤其是系统不断变得庞大复杂的时候。确实，这是一个非常正确的选择，虽然短期内需要付出的成本可能会相对更大一些，但是对整个系统的扩展性来讲，是非常有帮助的数据切分的原则： 数据切分的原则： 能不切分尽量不要切分； 如果要切分一定要选择合适的切分规则，提前规划好； 数据切分尽量通过数据冗余或者表分组（Table Group）来降低跨库 Join 的可能； 由于数据库中间件对数据 Join 实现的优劣难以把握，而且实现高性能难度极大，业务读取尽量少使用多表 Join。 MyCAT安装配置 MyCAT系统安装环境：123192.168.149.128 MyCAT192.168.149.129 MYSQL-MASTER192.168.149.130 MYSQL-SLAVE MyCAT安装之前，需要先安装jdk (Java Development Kit) ，JDK是 Java 语言的软件开发工具包(SDK)），本文安装版本为：jdk1.7.0_75.tar.gz 123tar -xzf jdk1.7.0_75.tar.gzmkdir -p /usr/java/mv jdk1.7.0_75 /usr/java/ 配置java环境变量，vi /etc/profile 添加如下语句： 12345export JAVA\\_HOME=/usr/java/jdk1.7.0\\_75export CLASSPATH=$CLASSPATH:$JAVA\\_HOME/lib:$JAVA\\_HOME/jre/libexport PATH=$JAVA\\_HOME/bin:$JAVA\\_HOME/jre/bin:$PATH:$HOMR/binsource /etc/profile //使环境变量立刻生效。java -version //查看java版本，显示版本为1.7.0_75，证明安装成功。 官网下载MyCAT最新稳定版本1.6：http://www.mycat.io 123wget http://dl.mycat.io/1.6-RELEASE/Mycat-server-1.6-RELEASE-20161028204710-linux.tar.gztar xzf Mycat-server-1.6-RELEASE-20161028204710-linux.tar.gzmv mycat/ /usr/local/ 进入MyCAT主目录，如图所示： MyCAT配置目录详解如下： bin程序目录，存放了 window版本和linux版本启动脚本，除了提供封装服务的版本之外，也提供了 nowrap的 shell脚本命令，方便大家选择和修改，进入到bin目录： Linux 下运行：./mycat console,首先要 chmod +x * mycat 支持的命令{ console | start | stop | restart | status | dump } conf目录下存放配置文件，其中： server.xm 丨Mycat服务器参数调整和用户授权的配置文件； schema.xm丨逻辑库定义和表及分片定义的配置文件； rule.xml |分片规则的配置文件，分片规则的具体一些参数信息单独存放为文件，也在这个目录下，配置文件修改，需要重启Mycat或者通过9066端口 reload； lib目录下主要存放mycat依赖的一些jar文件； 日志存放在logs/mycat.log中，每天一个文件，日志的配置是在conf/log4j.xml中，根据自己的需要，可以调整输出级别为debug , debug级别下； Catlet |支持跨分片复杂SQL实现以及存储过程支持。 本文基于MyCAT实现读写分离，只需要涉及到两个MyCAT配置文件，分别是：server.xml和schema.xml文件：其中Server.xml文件主要配置段内容如下： 123456789&lt;user name=\"jfedu1\"&gt;&lt;property name=\"password\"&gt;jfedu1&lt;/property&gt;&lt;property name=\"schemas\"&gt;testdb&lt;/property&gt;&lt;/user&gt;&lt;user name=\"jfedu2\"&gt;&lt;property name=\"password\"&gt;jfedu2&lt;/property&gt;&lt;property name=\"schemas\"&gt;testdb&lt;/property&gt;&lt;property name=\"readOnly\"&gt;true&lt;/property&gt;&lt;/user&gt; 创建jfedu1、jfedu2两个用户用于连接MyCAT中间件： 用户名jfedu1、密码jfedu1，对逻辑数据库testdb具有增删改查的权限，也即WEB连接MyCAT的用户名和密码； 用户名jfedu2，密码jfedu2，该用户对逻辑数据库testdb只读的权限； 其中Schema.xml文件主要配置内容如下： 12345678910111213&lt;?xml version=\"1.0\"?&gt;&lt;!DOCTYPE mycat:schema SYSTEM \"schema.dtd\"&gt;&lt;mycat:schema xmlns:mycat=\"http://io.mycat/\"&gt;&lt;schema name=\"testdb\" checkSQLschema=\"false\" sqlMaxLimit=\"1000\" dataNode=\"dn1\"&gt;&lt;/schema&gt;&lt;dataNode name=\"dn1\" dataHost=\"localhost1\" database=\"discuz\" /&gt;&lt;dataHost name=\"localhost1\" maxCon=\"2000\" minCon=\"1\" balance=\"0\" writeType=\"1\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\" slaveThreshold=\"100\"&gt;&lt;heartbeat&gt;select user()&lt;/heartbeat&gt;&lt;writeHost host=\"hostM1\" url=\"192.168.149.129:3306\" user=\"root\" password=\"123456\"&gt;&lt;readHost host=\"hostS1\" url=\"192.168.149.130:3306\" user=\"root\" password=\"123456\" /&gt;&lt;/writeHost&gt;&lt;/dataHost&gt;&lt;/mycat:schema&gt; 如上配置逻辑数据库testdb必须和server.xml中的用户指定的testdb数据库名称一致，否则会报错！如下为配置文件详解： 12345678&lt;?xml version=\"1.0\"?&gt;xml文件格式；&lt;!DOCTYPE mycat:schema SYSTEM \"schema.dtd\"&gt;文件标签属性；&lt;mycat:schema xmlns:mycat=\"http://io.mycat/\"&gt;Mycat起始标签&lt;schema name=\"testdb\" checkSQLschema=\"false\" sqlMaxLimit=\"1000\" dataNode=\"dn1\"&gt;&lt;/schema&gt; 配置逻辑库，与server.xml指定库名保持一致，绑定数据节点dn1; 1&lt;dataNode name=\"dn1\" dataHost=\"localhost1\" database=\"discuz\" /&gt; 添加数据节点dn1，设置数据节点host名称，同时设置数据节点真实database为discuz； 1&lt;dataHost name=\"localhost1\" maxCon=\"2000\" minCon=\"1\" balance=\"0\" writeType=\"1\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\" slaveThreshold=\"100\"&gt; 数据节点主机，绑定数据节点，设置连接数及均衡方式、切换方法、驱动程序、连接方法； Balance均衡策略设置： balance=0 不开启读写分离机制，所有读操作都发送到当前可用的writehost； balance=1 全部的readHost与stand by writeHost参与select语句的负载均衡，简单的说，当双主双从模式(M1-&gt;S1，M2-&gt;S2，并且M1与 M2互为主备)，正常情况下，M2,S1,S2都参与select语句的负载均衡。 balance=2 所有读操作都随机的在readhost和writehost上分发； balance=3 所有读请求随机的分发到wiriterHost对应的readhost执行，writerHost不负担读压力。 writeType 写入策略设置 writeType=0， 所有写操作发送到配置的第一个writeHost； writeType=1，所有写操作都随机的发送到配置的writeHost； writeType=2，不执行写操作 switchType 策略设置 switchType=-1，表示不自动切换； switchType=1，默认值，自动切换； switchType=2，基于MySQL 主从同步的状态决定是否切换； switchType=3，基于MySQL galary cluster的切换机制（适合集群）（1.4.1），心跳语句为 show status like ‘wsrep%’。 select user()检测后端MYSQL实例，SQL语句； 123&lt;writeHost host=\"hostM1\" url=\"192.168.149.129:3306\" user=\"root\" password=\"123456\"&gt;&lt;readHost host=\"hostS1\" url=\"192.168.149.130:3306\" user=\"root\" password=\"123456\" /&gt;&lt;/writeHost&gt; 指定读写请求，同时转发至后端MYSQL真实服务器，配置连接后端MYSQL用户名和密码（该用户名和密码为MYSQL数据库用户名和密码）； 数据主机标签； mycat结束标签； MyCAT读写分离测试MyCAT配置完毕，直接启动即可；/usr/local/mycat/bin/mycat start即可，查看8066和9066端口是否启动，其中8066用于WEB连接Mycat，9066用于SA|DBA管理端口； netstat -ntl|grep -E –color “8066|9066” 进入MyCAT命令行界面： mysql -h192.168.149.128 -ujfedu1 -pjfedu1 -P8066 插入数据，以9066端口登录。 MyCAT管理命令 MyCAT 自身有类似其他数据库的管理监控方式，可以通过 Mysql 命令行,登录管理端口(9066)执行相应 的 SQL 进行管理,也可以通过 jdbc 的方式进行远程连接管理,本小节主要讲解命令行的管理操作。 其中8066 数据端口，9066 管理端口，命令行的登陆是通过9066 管理端口来操作，登录方式类似于 mysql 的服务端登陆。 12mysql -h192.168.149.128 -ujfedu1 –pjfedu1 -P8066mysql -h192.168.149.128 -ujfedu1 –pjfedu1 -P9066 -h 后面是主机，即当前 mycat 按照的主机地址； -u Mycat server.xml 中配置的逻辑库用户； -p Mycat server.xml 中配置的逻辑库密码； -P 后面是端口 默认 9066,注意 P 是大写； 数据端口与管理端口的配置端口修改，数据端口默认 8066,管理端口默认 9066 ,如果需要修改需要配置 server.xml，加入如下代码，例如将数据库端口改成3306: 1&lt;property name=\"serverPort\"&gt;3306&lt;/property&gt; &lt;property name=\"managerPort\"&gt;9066&lt;/property&gt; 9066 管理端口登陆后，执行show @@help可以查看到所有命令： 常见管理命令如下：查看当前的库show @@database; +———-+ | DATABASE | +———-+ | testdb | +———-+ 1 row in set (0.00 sec) 查看MyCAT数据节点的列表,dataNode节点： mysql&gt; show @@datanode; 其中,“NAME”表示 dataNode 的名称;“dataHost”表示对应 dataHost 属性的值,即数据主机; “ACTIVE”表示活跃连接数;“IDLE”表示闲置连接数;“SIZE”对应总连接数量。 有1个空闲连接，那我们去主从节点用 netstat -ntp 命令看看建立的连接情况： 查看心跳报告： mysql&gt; show @@heartbeat; 该命令用于报告心跳状态 查看Mycat的前端连接状态，即应用与mycat的连接：mysql&gt; show @@connection\\G从上面获取到的连接 ID 属性，可以手动杀掉某个连接。kill @@connection id,id,id 显示后端连接状态：mysql&gt; show @@backend\\G 显示数据源：mysql&gt; show @@datasource; 可以看到主从信息，同时可以看到读、写的次数； MyCAT状态监控 MyCAT-WEB是基于mycat的一个性能监控工具，可以更有效的使用mycat管理mycat监控Mycat，让Mycat工作更加高效。Mycat-web的运行依赖 zookpeer ，需要提前安装Zookeeper服务，Zookeeper作为配置中心； MyCAT监控 支持如下特点： 支持对Mycat、Mysql性能监控 ； 支持对Mycat的JVM内存提供监控服务 ； 支持对线程的监控 ； 支持对操作系统的CPU、内存、磁盘、网络的监控 ； Zookeeper安装配置： 1234567wget http://apache.opencas.org/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gztar -zxvf zookeeper-3.4.6.tar.gz -C /usr/local/cd /usr/local/zookeeper-3.4.6/cd confcp zoo_sample.cfg zoo.cfgcd /usr/local/zookeeper-3.4.6/bin/./zkServer.sh start 安装配置MyCAT-WEB： 12wget http://dl.mycat.io/mycat-web-1.0/Mycat-web-1.0-SNAPSHOT-20170102153329-linux.tar.gztar -xvf Mycat-web-1.0-SNAPSHOT-20170102153329-linux.tar.gz -C /usr/local/ #修改zookeeper注册中心地址： 123cd /usr/local/mycat-web/mycat-web/WEB-INF/classesvim mycat.propertieszookeeper=127.0.0.1:2181 #启动MyCAT-WEB服务即可： 12cd /usr/local/mycat-web/./start.sh &amp; #通过浏览器访问如图所示: 访问地址是：http://192.168.149.128:8082/mycat/ 连接MyCAT服务器，填写如下配置即可：","tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.dookt.com/tags/数据库/"}]},{"title":"RAID简介","date":"2019-07-26T13:24:45.000Z","path":"post/59899.html","text":"磁盘阵列（Redundant Arrays of Independent Drives，RAID），有“独立磁盘构成的具有冗余能力的阵列”之意。 磁盘阵列是由很多块独立的磁盘，组合成一个容量巨大的磁盘组，利用个别磁盘提供数据所产生加成效果提升整个磁盘系统效能。利用这项技术，将数据切割成许多区段，分别存放在各个硬盘上。 1.RAID 0：称为Stripping条带存储技术（条带），所有磁盘完全地并行读，并行写，是组建磁盘阵列最简单的一种形式，只需要2块以上的硬盘即可，成本低，可以提供整个磁盘的性能和吞吐量，但RAID 0没有提供数据冗余和错误修复功能，因此单块硬盘的损坏会导致所有的数据丢失。（提高读写性能，无备份，成本最低）2.RAID 1：镜像存储，通过把两块磁盘中的一块磁盘的数据镜像到另一块磁盘上， 实现数据冗余，在两块磁盘上产生互为备份的数据，其容量仅等于一块磁盘的容量。当数据在写入一块磁盘时，会在另一块闲置的磁盘上生产镜像，在不影响性能情况下最大限度的保证系统的可靠性和可修复性；当原始数据繁忙时，可直接从镜像拷贝中读取数据（从两块硬盘中较快的一块中读出），提高读取性能。相反的，RAID 1的写入速度较缓慢。RAID 1一般支持“热交换”，即阵列中硬盘的移除或替换可以在系统运行状态下进行，无须中断退出系统。RAID 1是磁盘阵列中硬盘单位成本最高的，但它提供了很高的数据安全性、可靠性和可用性，当一块硬盘失效时，系统可以自动切换到镜像磁盘上读写，而不需要重组失效的数据。（提高读速度，降低写速度，有备份，成本最高）3.RAID 0+1：也被称为RAID 10，实际是将RAID 0和RAID 1结合的形式，在连续地以位或字节为单位分割数据并且并行读/写多个磁盘的同时，为每一块磁盘做镜像进行冗余。通过RAID 0+1的组合形式，数据除分布在多个盘上外，每个盘都有其物理镜像盘，提供冗余能力，允许一个以下磁盘故障，而不影响数据可用性，并且有快速读/写能力。RAID 0+1至少需要4个硬盘在磁盘镜像中建立带区集。RAID 0+1技术在保证数据高可靠性的同时，也保证了数据读/写的高效性。4.RAID 5：是一种存储性能、数据安全和存储成本兼顾的存储解决方案。RAID 5可以理解为是RAID 0和RAID 1的折衷方案，RAID 5至少需要三块硬盘。RAID 5可以为系统提供数据安全保障，但保障程度要比镜像低而磁盘空间利用率要比镜像高。RAID 5具有和RAID 0相近似的数据读取速度，只是多了一个奇偶校验信息，写入数据的速度比对单个磁盘进行写入操作稍慢。同时由于多个数据对应一个奇偶校验信息，RAID 5的磁盘空间利用率要比RAID 1高，存储成本相对较低，是目前运用较多的一种解决方案。","tags":[{"name":"磁盘管理","slug":"磁盘管理","permalink":"http://www.dookt.com/tags/磁盘管理/"}]},{"title":"Linux性能优化企业实战","date":"2019-07-26T12:51:48.000Z","path":"post/44413.html","text":"随着企业网站访问量越来越大，服务器的压力也逐渐增加，主要体现在CPU使用率、内存、硬盘、网卡流量等方面资源占用情况很高。此时需对服务器性能进行调优，尽量在保持服务器的现有数量，然后对其各个环节参数进行优化。 本章向读者介绍Linux企业级性能服务器优化、TCP/IP报文、TCP三次握手及四次断开、Linux内核深入优化、Linux内核故障解决方案及对Linux性能进行评估等。 TCP/IP报文详解TCP/IP 定义了电子设备如何连入因特网，以及数据如何在它们之间传输的标准。协议采用了4层的层级结构，每一层都呼叫它的下一层所提供的协议来完成自己的需求。 TCP负责发现传输的问题，一有问题就发出信号，要求重新传输，直到所有数据安全正确地传输到目的地，而IP是给因特网的每台联网设备规定一个地址。TCP/IP 协议数据封装的过程包括：用户数据经过应用层协议封装后传递给传输层，传输层封装TCP头部，交给网络层，网络层封装IP头部后，再交给数据链路层，数据链路层封装Ethernet帧头和帧尾，交给物理层，物理层以比特流的形式将数据发送到物理线路上。 一般而言，不同的协议层对数据包有不同的称谓，数据包在传输层叫做段（segment），在网络层叫做数据报（datagram），在链路层叫做帧（frame）。数据封装成帧后发到传输介质上，到达目的主机后每层协议再剥掉相应的首部，最后将应用层数据交给应用程序处理，如图15-1所示： 优化Linux服务器，需要了解TCP协议相关信息，例如TCP/IP数据报文的内容及如何传输的。 IP数据包详解如下： Source Port和Destination Port:分别占用16位，表示源端口号和目的端口号；用于区别主机中的不同进程，而IP地址是用来区分不同的主机的，源端口号和目的端口号配合上IP首部中的源IP地址和目的IP地址就能唯一的确定一个TCP连接；Sequence Number:用来标识从TCP发端向TCP收端发送的数据字节流，它表示在这个报文段中的的第一个数据字节在数据流中的序号；主要用来解决网络报乱序的问题；Acknowledgment Number:32位确认序列号包含发送确认的一端所期望收到的下一个序号，因此，确认序号应当是上次已成功收到数据字节序号加1。不过，只有当标志位中的ACK标志（下面介绍）为1时该确认序列号的字段才有效。主要用来解决不丢包的问题；Offset:给出首部中32 bit字的数目，需要这个值是因为任选字段的长度是可变的。这个字段占4bit（最多能表示15个32bit的的字，即4*15=60个字节的首部长度），因此TCP最多有60字节的首部。然而，没有任选字段，正常的长度是20字节；TCP Flags:TCP首部中有6个标志比特，它们中的多个可同时被设置为1，主要是用于操控TCP的状态机的，依次为URG，ACK，PSH，RST，SYN，FIN。每个标志位的意思如下：URG：此标志表示TCP包的紧急指针域（后面马上就要说到）有效，用来保证TCP连接不被中断，并且督促中间层设备要尽快处理这些数据；ACK：此标志表示应答域有效，就是说前面所说的TCP应答号将会包含在TCP数据包中；有两个取值：0和1，为1的时候表示应答域有效，反之为0；PSH：这个标志位表示Push操作。所谓Push操作就是指在数据包到达接收端以后，立即传送给应用程序，而不是在缓冲区中排队；RST：这个标志表示连接复位请求。用来复位那些产生错误的连接，也被用来拒绝错误和非法的数据包；SYN：表示同步序号，用来建立连接。SYN标志位和ACK标志位搭配使用，当连接请求的时候，SYN=1，ACK=0；连接被响应的时候，SYN=1，ACK=1；这个标志的数据包经常被用来进行端口扫描。扫描者发送一个只有SYN的数据包，如果对方主机响应了一个数据包回来 ，就表明这台主机存在这个端口；但是由于这种扫描方式只是进行TCP三次握手的第一次握手，因此这种扫描的成功表示被扫描的机器不很安全，一台安全的主机将会强制要求一个连接严格的进行TCP的三次握手；FIN： 表示发送端已经达到数据末尾，也就是说双方的数据传送完成，没有数据可以传送了，发送FIN标志位的TCP数据包后，连接将被断开。这个标志的数据包也经常被用于进行端口扫描。Window:窗口大小，也就是有名的滑动窗口，用来进行流量控制；TCP三次握手及四次断开TCP是面向连接的，无论哪一方向另一方发送数据之前，都必须先在双方之间建立一条连接。在TCP/IP协议中，TCP协议提供可靠的连接服务，连接是通过三次握手进行初始化的。三次握手的目的是同步连接双方的序列号和确认号并交换TCP窗口大小信息。 TCP三次握手原理：第一次握手：建立连接。客户端发送连接请求报文段，将SYN位置为1，Sequence Number为x；然后客户端进入SYN_SENT状态，等待服务器的确认；第二次握手：服务器收到SYN报文段。服务器收到客户端的SYN报文段，需要对这个SYN报文段进行确认，设置Acknowledgment Number为x+1(Sequence Number+1)；同时，自己自己还要发送SYN请求信息，将SYN位置为1，Sequence Number为y；服务器端将上述所有信息放到一个报文段（即SYN+ACK报文段）中，一并发送给客户端，此时服务器进入SYN_RECV状态；第三次握手：客户端收到服务器的SYN+ACK报文段。然后将Acknowledgment Number设置为y+1，向服务器发送ACK报文段，这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成TCP三次握手。如图15-4所示为基于tcpdump抓取TCP/IP三次握手及数据包传输过程： TCP四次挥手原理：第一次挥手：主机A（可以使客户端，可以是服务器端），设置Sequence Number和Acknowledgment Number，向主机B发送一个FIN报文段；此时，主机A进入FIN_WAIT_1状态；这表示主机A没有数据要发送给主机B；第二次挥手：主机B收到了主机A发送的FIN报文段，向主机A回一个ACK报文段，Acknowledgment Number为Sequence Number加1；主机A进入FIN_WAIT_2状态；主机B告诉主机A，我“同意”你的关闭请求；第三次挥手：主机B向主机A发送FIN报文段，请求关闭连接，同时主机B进入LAST_ACK状态；第四次挥手：主机A收到主机B发送的FIN报文段，向主机B发送ACK报文段，然后主机A进入TIME_WAIT状态；主机B收到主机A的ACK报文段以后，就关闭连接；此时，主机A等待2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，主机A也可以关闭连接。如图15-5所示为基于tcpdump抓取TCP/IP四次挥手及数据包传输过程： 优化Linux文件打开最大数为了防止失控的进程破坏系统的性能，Unix和Linux会跟踪进程使用的大部分资源，并允许用户和系统管理员使用对进程的资源限制，例如控制某个进程打开的系统文件数、对某个用户打开系统进程数进行限制等，一般限制手段包括：软限制和硬限制。软限制（soft limit）是内核实际执行的限制，任何进程都可以将软限制设置为任意小于等于对进程限制的硬限制的值，(noproc)最大线程数和(nofile)文件数；硬限制（hard limit）是可以在任何时候任何进程中设置，但硬限制只能由超级用户修改。Linux系统一切皆文件，对Linux进行各种操作，其实是对文件进行操作，文件可分为：普通文件、目录文件、链接文件和设备文件。而文件描述符（file descriptor）是内核为了高效管理已被打开的文件所创建的索引，其值一个非负整数（通常是小整数），用于指代被打开的文件，所有执行I/O操作的系统调用都通过文件描述符。Linux系统默认已经打开的文件描述符包括：STDIN_FILENO 0表示标准输入、STDOUT_FILENO 1表示标准输出、STDERR_FILENO 2表示标准错误输出，默认打开一个新文件，它的文件描述符为3。每个文件描述符与一个打开文件相对应，不同的文件描述符可以指向同一个文件。相同的文件可以被不同的进程打开，也可以在同一个进程中被多次打开。Linux系统为每个进程维护了一个文件描述符表，该表的值都从0开始的，在不同的进程中你会看到相同的文件描述符，相同文件描述符有可能指向同一个文件，也有可能指向不同的文件。Linux内核对文件操作，维护了3个数据结构概念如下：进程级的文件描述符表；系统级的打开文件描述符表；文件系统的i-node表；其中进程级的描述符表的每一个条目记录了单个文件描述符的相关信息，例如控制文件描述符操作的一组标志及对打开文件句柄的引用。Linux内核对所有打开的文件都维护了一个系统级的描述符表（open file description table）。将描述符表中的记录行称为打开文件句柄（open file handle），一个打开文件句柄存储了与一个打开文件相关的全部信息，详细信息如下：当前文件偏移量；打开文件时所使用的状态标识；文件访问模式；与信号驱动相关的设置；对该文件i-node对象的引用；文件类型和访问权限；指针，指向该文件所持有的锁列表；文件的各种属性。默认Linux内核对每个用户设置了打开文件最大数为1024，对于高并发网站，是远远不够的，需要将默认值调整到更大，调整方法有两种：Linux每个用户打开文件最大数临时设置方法，重启服务器该参数无效，命令行终端执行如下命令：ulimit -n 65535Linux每个用户打开文件最大数永久设置方法，将如下代码加入内核限制文件/etc/security/limits.conf的末尾： 1234* soft noproc 65535* hard noproc 65535* soft nofile 65535* hard nofile 65535 如上设置为对每个用户分别设置nofile、noproc最大数，如果需要对Linux整个系统设置文件最大数限制，需要修改/proc/sys/fs/file-max中的值，该值为Linux总文件打开数，例如设置为：echo 3865161233 &gt;/proc/sys/fs/file-max。 内核参数的优化Linux /proc/sys目录下存放着多数内核的参数，并且可以在系统运行时进行更改，一般重新启动机器就会失效。而/etc/sysctl.conf是一个允许改变正在运行中的Linux系统的接口，它包含一些TCP/IP堆栈和虚拟内存系统的高级选项，修改内核参数永久生效。 /proc/sys下内核文件与配置文件sysctl.conf中变量存在着对应关系，即修改sysct.conf配置文件，其实是修改/proc/sys相关参数，所以对Linux内核优化只需修改/etc/sysctl.conf文件即可。如下为BAT企业生产环境/etc/sysct.conf内核完整参数： 1234567891011121314151617181920212223242526272829303132net.ipv4.ip_forward = 0net.ipv4.conf.default.rp_filter = 1net.ipv4.conf.default.accept_source_route = 0kernel.sysrq = 0kernel.core_uses_pid = 1net.ipv4.tcp_syncookies = 1kernel.msgmnb = 65536kernel.msgmax = 65536kernel.shmmax = 68719476736kernel.shmall = 4294967296net.ipv4.tcp_max_tw_buckets = 10000net.ipv4.tcp_sack = 1net.ipv4.tcp_window_scaling = 1net.ipv4.tcp_rmem = 4096 87380 4194304net.ipv4.tcp_wmem = 4096 16384 4194304net.core.wmem_default = 8388608net.core.rmem_default = 8388608net.core.rmem_max = 16777216net.core.wmem_max = 16777216net.core.netdev_max_backlog = 262144net.core.somaxconn = 262144net.ipv4.tcp_max_orphans = 3276800net.ipv4.tcp_max_syn_backlog = 262144net.ipv4.tcp_timestamps = 0net.ipv4.tcp_synack_retries = 1net.ipv4.tcp_syn_retries = 1net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_mem = 94500000 915000000 927000000net.ipv4.tcp_fin_timeout = 1net.ipv4.tcp_keepalive_time = 30net.ipv4.ip_local_port_range = 1024 65535 Linux内核常见参数详解：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950net.ipv4.tcp_timestamps = 1该参数控制RFC 1323 时间戳与窗口缩放选项；net.ipv4.tcp_sack = 1选择性应答(SACK)是 TCP 的一项可选特性,可以提高某些网络中所有可用带宽的使用效率；net.ipv4.tcp_fack = 1打开FACK(Forward ACK) 拥塞避免和快速重传功能；net.ipv4.tcp_retrans_collapse = 1打开重传重组包功能，为0的时候关闭重传重组包功能；net.ipv4.tcp_syn_retries = 5对于一个新建连接，内核要发送多少个SYN 连接请求才决定放弃；net.ipv4.tcp_synack_retries = 5tcp_synack_retries显示或设定Linux在回应SYN要求时尝试多少次重新发送初始SYN,ACK封包后才决定放弃；net.ipv4.tcp_max_orphans = 131072系统所能处理不属于任何进程的TCP sockets最大数量；net.ipv4.tcp_max_tw_buckets = 5000系统同时保持TIME_WAIT套接字的最大数量，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息；默认为180000，设为较小数值此项参数可以控制TIME_WAIT套接字的最大数量，避免服务器被大量的TIME_WAIT套接字拖死；net.ipv4.tcp_keepalive_time = 30net.ipv4.tcp_keepalive_probes = 3net.ipv4.tcp_keepalive_intvl = 3如果某个TCP连接在空闲30秒后,内核才发起probe(探查)；如果probe 3次(每次3秒既tcp_keepalive_intvl值)不成功,内核才彻底放弃,认为该连接已失效；net.ipv4.tcp_retries1 = 3放弃回应一个TCP 连接请求前﹐需要进行多少次重试；net.ipv4.tcp_retries2 = 15在丢弃激活(已建立通讯状况)的TCP连接之前﹐需要进行多少次重试；net.ipv4.tcp_fin_timeout = 30表示如果套接字由本端要求关闭，这个参数决定了它保持在 FIN-WAIT-2状态的时间；net.ipv4.tcp_tw_recycle = 1表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭；net.ipv4.tcp_max_syn_backlog = 8192表示SYN队列的长度，默认为1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数；net.ipv4.tcp_syncookies = 1TCP建立连接的 3 次握手过程中，当服务端收到最初的 SYN 请求时，会检查应用程序的syn_backlog队列是否已满，启用syncookie，可以解决超高并发时的Can’t Connect` 问题。但是会导致 TIME_WAIT 状态fallback为保持2MSL时间，高峰期时会导致客户端无可复用连接而无法连接服务器；net.ipv4.tcp_orphan_retries = 0关闭TCP连接之前重试多少次；net.ipv4.tcp_mem = 178368 237824 356736net.ipv4.tcp_mem[0]: 低于此值,TCP没有内存压力；net.ipv4.tcp_mem[1]: 在此值下,进入内存压力阶段；net.ipv4.tcp_mem[2]: 高于此值,TCP拒绝分配socket；net.ipv4.tcp_tw_reuse = 1表示开启重用，允许将TIME-WAIT sockets重新用于新的TCP连接；net.ipv4.ip_local_port_range = 1024 65000表示用于向外连接的端口范围；net.ipv4.ip_conntrack_max = 655360在内核内存中netfilter可以同时处理的“任务”（连接跟踪条目）；net.ipv4.icmp_ignore_bogus_error_responses = 1开启恶意icmp错误消息保护；net.ipv4.tcp_syncookies = 1开启SYN洪水攻击保护。 Linux内核报错剖析企业生产环境Linux服务器正常运行，由于某种原因会导致内核报错或者抛出很多信息，根据系统SA可以快速定位Linux服务器故障，Linux内核日志一般存在messages日志中，可以通过命令tail -fn 100 /var/log/messages查看Linux内核日志，如下为Linux内核常见报错日志及生产环境解决报错的方案： Linux内核抛出net.ipv4.tcp_max_tw_buckets错误：123456789Sep 23 04:45:55 localhost kernel: TCP: time wait bucket table overflowSep 23 04:45:55 localhost kernel: TCP: time wait bucket table overflowSep 23 04:45:55 localhost kernel: TCP: time wait bucket table overflowSep 23 04:45:55 localhost kernel: TCP: time wait bucket table overflowSep 23 04:45:55 localhost kernel: TCP: time wait bucket table overflowSep 23 04:45:55 localhost kernel: TCP: time wait bucket table overflowSep 23 04:45:55 localhost kernel: TCP: time wait bucket table overflowSep 23 04:45:55 localhost kernel: TCP: time wait bucket table overflowSep 23 04:45:55 localhost kernel: TCP: time wait bucket table overflow 根据TCP协议定义的3次握手及四次断开连接规定，发起socket主动关闭的一方Socket将进入TIME_WAIT状态，TIME_WAIT状态将持续2个MSL(Max Segment Lifetime)。如果该值设置过小导致，当系统Time wait数量超过默认设置的值，即会抛出如上的警告信息，需要增加net.ipv4.tcp_max_tw_buckets的值，警告信息消除。当然也不能设置过大，对于一个处理大量短连接的服务器，如果是由服务器主动关闭客户端的连接，将导致服务器端存在大量的处于TIME_WAIT状态的Socket，甚至比处于Established状态下的Socket多的多，严重影响服务器的处理能力，甚至耗尽可用的Socket而停止服务，TIME_WAIT是TCP协议用以保证被重新分配的Socket不会受到之前残留的延迟重发报文影响的机制，是TCP传输必要的逻辑保证。 Linux内核抛出Too many open files错误：123456Benchmarking localhost (be patient)socket: Too many open files (24)socket: Too many open files (24)socket: Too many open files (24)socket: Too many open files (24)socket: Too many open files (24) 每个文件描述符与一个打开文件相对应，不同的文件描述符可以指向同一个文件。相同的文件可以被不同的进程打开，也可以在同一个进程中被多次打开。Linux内核对应每个用户打开的文件最大数一般为1024，需要将该值调高满足大并发网站的访问。Linux每个用户打开文件最大数永久设置方法，将如下代码加入内核限制文件/etc/security/limits.conf的末尾，Exit退出终端，重新登录即生效： 12345# cat /etc/security/limits.conf* soft noproc 65535* hard noproc 65535* soft nofile 65535* hard nofile 65535 Linux内核抛出possible SYN flooding on port 80. Sending cookies错误：12345678May 31 14:20:14 localhost kernel: possible SYN flooding on port 80. Sending cookies.May 31 14:21:28 localhost kernel: possible SYN flooding on port 80. Sending cookies.May 31 14:22:44 localhost kernel: possible SYN flooding on port 80. Sending cookies.May 31 14:25:33 localhost kernel: possible SYN flooding on port 80. Sending cookies.May 31 14:27:06 localhost kernel: possible SYN flooding on port 80. Sending cookies.May 31 14:28:44 localhost kernel: possible SYN flooding on port 80. Sending cookies.May 31 14:28:51 localhost kernel: possible SYN flooding on port 80. Sending cookies.May 31 14:31:01 localhost kernel: possible SYN flooding on port 80. Sending cookies. 此问题是由于SYN 队列已满，而触发SYN cookies，一般是由于大量的访问，或者恶意访问导致，也称之为SYN Flooding洪水攻击，与DDOS攻击类似。完整的TCP连接的三次握手，假设一个用户A向服务器发送了SYN报文后突然死机或掉线，那么服务器在发出SYN+ACK应答报文后是无法收到客户端的ACK报文的（第三次握手无法完成），这种情况下服务器端一般会重试（再次发送SYN+ACK给客户端）并等待一段时间后丢弃这个未完成的连接，这段时间的长度我们称为SYN Timeout，一般来说这个时间是分钟的数量级（大约为30秒-2分钟）。一个用户出现异常导致服务器的一个线程等待1分钟并不是什么很大的问题，但如果有一个恶意的攻击者大量模拟这种情况，服务器端将为了维护一个非常大的半连接列表而消耗非常多的资源，数以万计的半连接，即使是简单的保存并遍历也会消耗非常多的CPU时间和内存，何况还要不断对这个列表中的IP进行SYN+ACK的重试。实际上如果服务器的TCP/IP栈不够强大，最后的结果往往是堆栈溢出崩溃，即使服务器端的系统足够强大，服务器端也将忙于处理攻击者伪造的TCP连接请求而无暇理睬客户的正常请求（毕竟客户端的正常请求比率非常之小），此时从正常客户的角度看来，服务器失去响应，服务器拒绝提供服务，服务器受到了DDOS攻击，这里攻击的手段为DDOS中SYN Flood攻击（SYN洪水攻击）。 防护DDOS攻击防护DDOS攻击有两种手段，一是基于硬件专业防火墙、二是基于Linux内核简单防护，如果攻击流量特别大，单纯配置内核参数是无法抵挡的，还得依靠专业级硬件防火墙，如下为Linux内核防护DDOS优化参数，加入如下代码即可： 12345678910net.ipv4.tcp_fin_timeout = 30net.ipv4.tcp_keepalive_time = 1200net.ipv4.tcp_syncookies = 1net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_tw_recycle = 1net.ipv4.ip_local_port_range = 1024 65000net.ipv4.tcp_max_syn_backlog = 8192net.ipv4.tcp_max_tw_buckets = 8000net.ipv4.tcp_synack_retries = 2net.ipv4.tcp_syn_retries = 2 Linux内核抛出ip_conntrack: table full, dropping packet.错误：12345678May 6 11:15:07 localhost kernel: nf_conntrack:table full, dropping packet.May 6 11:19:13 localhost kernel: nf_conntrack:table full, dropping packet.May 6 11:20:34 localhost kernel: nf_conntrack:table full, dropping packet.May 6 11:23:12 localhost kernel: nf_conntrack:table full, dropping packet.May 6 11:24:07 localhost kernel: nf_conntrack:table full, dropping packet.May 6 11:24:13 localhost kernel: nf_conntrack:table full, dropping packet.May 6 11:25:11 localhost kernel: nf_conntrack:table full, dropping packet.May 6 11:26:25 localhost kernel: nf_conntrack:table full, dropping packet. 由于该服务器开启了iptables防火墙，WEB服务器收到了大量的连接，iptables会把所有的连接都做链接跟踪处理，这样iptables就会有一个链接跟踪表，当这个表满的时候，就会出现上面的错误。ip_conntrack是linux NAT的一个跟踪连接条目的模块，ip_conntrack模块会使用一个哈希表记录 tcp 通讯协议的established connection记录。 如果是CentOS6.x系统，需执行：modprobe nf_conntrack命令，然后在内核优化文件中加入如下代码，sysctl –p使其内核文件生效，即可解决该报错： 12net.nf_conntrack_max = 655360net.netfilter.nf_conntrack_tcp_timeout_established = 36000 如果是CentOS5.x系统，需执行：modprobe ip_conntrack命令，然后在内核优化文件中加入如下代码，sysctl –p使其内核文件生效，即可解决该报错： 12net.ipv4.ip_conntrack_max = 655350net.ipv4.netfilter.ip_conntrack_tcp_timeout_established = 10800 影响务器性能因素影响企业生产环境Linux服务器性能的因素有很多，一般分为两大类，分别为操作系统层级和应用程序级别。如下为各级别影响性能的具体项及性能评估的标准： 操作系统级别 内存； CPU； 磁盘I/O； 网络I/O带宽。 应用程序及软件 Nginx； MySQL； Tomcat; PHP； 应用程序代码。 影响性能因素评判标准 好 坏 糟糕 CPU user% + sys%&lt; 70% user% + sys%= 85% user% + sys% &gt;=90% 内存 Swap In（si）＝0 Swap Out（so）＝0 Per CPU with 10 page/s More Swap In &amp; Swap Out 磁盘 iowait % &lt; 20% iowait % =35% iowait % &gt;= 50% Linux系统性能分析工具常用系统性能分析命令: vmstat、sar、iostat、netstat、free、ps、top、iftop等； 常用系统性能组合分析命令； top、uptime 检查系统整体的负载、承受能力； vmstat、sar、iostat 、top 检测是否是CPU瓶颈； free、vmstat 检测是否是内存瓶颈； iostat 检测是否是磁盘I/O瓶颈； netstat、iftop 检测是否是网络带宽瓶颈。 Linux服务器性能评估与优化Linux服务器性能评估与优化是一项长期的工作，需要随时关注网站服务器的运行状态，及时作出相应的调整，如下为Linux服务器性能评估及优化方案： Linux系统整体性能评估uptime命令主要用于查看当前服务器整体性能，例如CPU、负载、内存等值的总览，如下为uptime命令应用案例及详解： 12[root@web1 ~]# uptime13:38:00 up 112 days, 14:01, 5 users, load average: 6.22, 1.02, 0.91 Load average负载有三个值，分别表示：最近1分钟、5分钟、15分钟系统的负载，三个值的大小一般不能大于系统逻辑CPU核数的2倍，例如Linux操作系统有4个逻辑CPU，如果load average的三个值长期大于8时，说明CPU很繁忙，负载很高，可能会影响系统性能，但是偶尔大于8时，可以不用担心，一般不会影响系统性能。如果load average的输出值小于CPU逻辑个数的2倍，则表示CPU还有空闲的时间片，例如案例中CPU负载为6.22，表示CPU或者服务器是比较空闲的。基于此参数不能完全确认服务器的性能瓶颈，需要借助其他工具进一步判断。 CPU性能评估利用vmstat命令监控系统CPU，该命令可以显示关于系统各种资源之间相关性能的简要信息，主要用它来查看CPU负载及队列情况。 Vmstat输出结果详解 r 列表示运行和等待cpu时间片的进程数，这个值如果长期大于系统CPU的个数，说明CPU不足，需要增加CPU； b 列表示在等待资源的进程数，比如正在等待I/O、或者内存交换等； us 列显示了用户进程消耗的CPU 时间百分比。us的值比较高时，说明用户进程消耗的cpu时间多，但是如果长期大于50%，就需要考虑优化程序或算法； sy 列显示了内核进程消耗的CPU时间百分比。Sy的值较高时，说明内核消耗的CPU资源很多；us+sy的参考值为80%，如果us+sy大于80%说明可能存在CPU资源不足。利用sar命令监控系统CPU，sar功能很强大，可以对系统的每个方面进行单独的统计，但是使用sar命令会增加系统开销，不过这些开销是可以评估的，对系统的统计结果不会有很大影响。如图15-7所示，为sar命令对某个系统的CPU统计输出： Sar输出结果详解如下： %user 列显示了用户进程消耗的CPU 时间百分比； %nice 列显示了运行正常进程所消耗的CPU 时间百分比； %system 列显示了系统进程消耗的CPU时间百分比； %iowait 列显示了IO等待所占用的CPU时间百分比； %idle 列显示了CPU处在空闲状态的时间百分比； %steal 列显示了在内存相对紧张的环境下page in强制对不同的页面进行的steal操作。 内存性能评估利用free指令监控内存，free是监控linux内存使用状况最常用的指令。 一般而言，服务器内存可以通过如下方法判断是否空余： 应用程序可用内存/系统物理内存&gt;70%时，表示系统内存资源非常充足，不影响系统性能。 应用程序可用内存/系统物理内存&lt;20%时，表示系统内存资源紧缺，需要增加系统内存，20%&lt;应用程序可用内存/系统物理内存&lt;70%时，表示系统内存资源基本能满足应用需求，暂时不影响系统性能。 磁盘I/O性能评估利用iostat评估磁盘性能，监控磁盘IO读写及带宽。 Iostat输出结果详解如下： Blk_read/s 表示每秒读取的数据块数； Blk_wrtn/s 表示每秒写入的数据块数； Blk_read 表示读取的所有块数； Blk_wrtn 表示写入的所有块数。 可以通过Blk_read/s和Blk_wrtn/s的值对磁盘的读写性能有一个基本的了解，如果Blk_wrtn/s值很大，表示磁盘的写操作很频繁，可以考虑优化磁盘或者优化程序，如果Blk_read/s值很大，表示磁盘直接读取操作很多，可以将读取的数据放入内存中进行操作。 利用sar评估磁盘性能，通过sar -d组合，可以对系统的磁盘IO做一个基本的统计。 Sar输出结果详解如下： await表示平均每次设备I/O操作的等待时间（以毫秒为单位）； svctm表示平均每次设备I/O操作的服务时间（以毫秒为单位）； %util表示一秒中有百分之几的时间用于I/O操作； 磁盘IO性能，评判标准：正常情况下svctm应该是小于await值的，而svctm的大小和磁盘性能有关，CPU、内存的负荷也会对svctm值造成影响，过多的请求也会间接的导致svctm值的增加。await值的大小一般取决与svctm的值和I/O队列长度以及I/O请求模式，如果svctm的值与await很接近，表示几乎没有I/O等待，磁盘性能很好，如果await的值远高于svctm的值，则表示I/O队列等待太长，系统上运行的应用程序将变慢，此时可以通过更换更快的硬盘来解决问题。%util项的值也是衡量磁盘I/O的一个重要指标，如果%util接近100%，表示磁盘产生的I/O请求太多，I/O系统已经满负荷的在工作，该磁盘可能存在瓶颈。长期下去，势必影响系统的性能，可以通过优化程序或者通过更换更高、更快的磁盘来解决此问题。 网络性能评估 通过ping命令检测网络的连通性 通过netstat –i组合检测网络接口状况 通过netstat –r组合检测系统的路由表信息 通过sar -n组合显示系统的网络运行状态 通过iftop -i eth0 查看网卡流量，详细参数如下， &lt;= 客户端流入的流量； =&gt; 服务器端流出的流量； TX 发送流量； RX 接收流量； TOTAL 总流量； Cumm 运行iftop到目前时间的总流量； peak 流量峰值； rates 分别表示过去 2s 10s 40s 的平均流量。","tags":[{"name":"运维基本功","slug":"运维基本功","permalink":"http://www.dookt.com/tags/运维基本功/"}]},{"title":"pyenv安装","date":"2019-07-26T10:07:51.000Z","path":"post/651295d4.html","text":"Pyenv是多版本Python管理器,可以同时管理多个Python版本共存, 区别于virtualenv. 安装1234567git clone git://github.com/yyuu/pyenv.git ~/.pyenvvim ~/.bashrcexport PYENV_ROOT=\"$HOME/.pyenv\"export PATH=\"$PYENV_ROOT/bin:$PATH\"eval \"$(pyenv init -)\"source ~/.bashrc 基本过程是官网下载源码包然后安装, 需要安装gcc, 等库的依赖安装. 查看支持的版本pyenv install –list centos上装python3需要先安装一些依赖包123# yum groupinstall \"Development tools\"# yum install zlib-devel bzip2-devel openssl-devel ncurses-devel \\sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel 开始安装python3.6.41pyenv install -v 3.6.4&lt;/pre&gt; 切换版本1234pyenv global 3.6.4pyenv versions system* 3.6.4 (set by /root/.pyenv/version) 查看当前系统包含的版本。*表示当前正在使用的版本123pyenv versions* system (set by /root/.pyenv/version)3.6.4 相关注意事项因各种原因, 下载速度可能只有几KB, 甚至超时, 可将下载地址替换成国内镜像后在下载. 12345cd ~/.pyenv/plugins/python-build/share/python-build/vim 3.5.2 (如果你下载别的版本, 你就改别的文件)将里面下载地址改成sohu的镜像地址：https://www.python.org/ftp/python/3.5.2/Python-3.5.2.tar.xzhttp://mirrors.sohu.com/python/3.5.2/Python-3.5.2.tar.xz 附搜狐镜像地址：http://mirrors.sohu.com/python/pip安装各种库也经常容易timeout. 1234# cat ~/.pip/pip.conf[global]index-url = http://pypi.douban.com/simpletrusted-host = pypi.douban.com","tags":[{"name":"Python基础","slug":"Python基础","permalink":"http://www.dookt.com/tags/Python基础/"}]},{"title":"Linux硬盘故障修复","date":"2019-07-26T10:04:50.000Z","path":"post/57688.html","text":"企业服务器运维中，经常会发现操作系统的分区变成只读文件系统，错误提示信息为“Read-only filesystem”，出现只读文件系统，会导致只能读取，而无法写入新文件、新数据等操作。 造成该问题的原因包括：磁盘老旧长期大量的读写、文件系统文件被破坏、磁盘碎片文件、异常断电、读写中断等等。 以CentOS 7 Linux为案例，来修复文件系统，步骤如下： 远程备份本地重要数据。出现只读文件系统，需先备份其他重要数据，基于rsync|scp远程备份，/data为源目录，/backup/2018/为目标备份目录。 12rsync -av /data/ root@192.168.21.98:/backup/2017/mount -o remount,rw / 如果重新挂载/系统无法解决问题，则需重启服务器以CD/DVD光盘引导进入Linux Rescue修复模式，如图所示，光标选择“Troubleshooting”,按Enter键，然后选择“Rescue a CentOS system”，按Enter键。 光盘引导进入修复模式， 选择Continue继续进入系统 登录修复模式，执行如下命令，df –h显示原来的文件系统 更改root目录 12chroot /mnt/sysimagedf -h 切换原分区目录对有异常的分区进行检测并修复，根据文件系统类型，执行相应的命令如下： 12umount /dev/sda3fsck.ext4 /dev/sda3 –y 修复完成之后，重启系统即可1reboot","tags":[{"name":"系统管理","slug":"系统管理","permalink":"http://www.dookt.com/tags/系统管理/"}]},{"title":"MYSQL最常见的报错信息","date":"2019-07-26T10:04:05.000Z","path":"post/29811.html","text":"作为一个运维人，MySQL启动不了了，该如何排查呢？ MySQL重启报错12Redirecting to /bin/systemctl restart mariadbJob for mariadb.service failed because the control process exited with error code. See \"systemctl status mariadb.service\" and \"journalctl -xe\" for details. 解决方法： journalctl –xe查看MYSQL错误信息 关闭服务器selinux安全策略，setenforce 0 检查MYSQL|Mariadb通过什么样的方式部署的 检查其配置文件/etc/my.cnf，datadir数据目录是否配置 确认数据库的数据目录mysql用户是否拥有读写权限 检查数据库目录是否初始化，是否包括mysql、test基础库 检查socket文件所在的路径，是否存在socket文件，权限是否正确","tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.dookt.com/tags/数据库/"}]},{"title":"使用expect实现无交互操作远程主机","date":"2019-07-26T10:03:00.000Z","path":"post/38203.html","text":"对于一些需要交互输入的命令可以使用expect。比如ssh ftp scp telnet expect是一款自动化的脚本解释型的工具。expect基于tcl脚本，expect脚本的运行需要tcl的支持。远程登录linux服务器的时候，ssh命令需要手工输入密码，当登录多台机器的时候就会非常繁琐。expect就可以根据设定的规则，自动帮我们输入密码，大大节省了时间。 查看远程主机的负载123456cat mint1.exp #扩展名为exp表示是expect脚本#!/usr/bin/expect #解释器(该命令不能直接再Linux上执行,需要使用expect脚本执行)spawn ssh root@172.17.0.2 uptime #执行ssh命令,开头必须有spawn,否则无法交互 expect \"*password*\" #利用expect获取ssh命令输出字符串是否为*password*,\"*\"为通配符send \"123456\\n\" #当获取到*password*时,发送密码123456给系统,\\n为换行,可以用\\r(回车)expect eof #结束expect 执行过程[root@mint mint]# expect mint1.expspawn ssh root@172.17.0.2 uptimeroot@172.17.0.2‘s password: 09:12:44 up 40 min, 0 users, load average: 0.45, 0.50, 0.46 使用read命令,创造交互式输入read shell脚本12345678cat read_shell.sh#!/bin/bashread -p \"Please input your username:\" nameread -p \"please input your password:\" passread -p \"Please input your email:\" mailecho -n \"your username is $name,\"echo -n \"your password is $pass,\"echo \"your email is $mail.\" read expect脚本1234567#!/usr/bin/expectspawn /bin/bash read_shell.sh #执行上述shell脚本expect &#123; #expect&#123;&#125;相当于多个expect \"username\" &#123;exp_send \"mint\\r\";exp_continue&#125; #获取到的信息是username,则自动输入mint \"*pass*\" &#123;send \"123456\\r\";exp_continue&#125; #获取到的信息是*xinghao*sdfafsfdfsaafsda asfdf aa* \"*mail*\" &#123;exp_send \"1101893634@qq.com\\r\"&#125;&#125; expect eof #执行结果123456expect read_expect.exp&amp;nbsp;spawn /bin/bash read_shell.shPlease input your username:mintplease input your password:123456Please input your email:1101893634@qq.comyour username is mint,your password is 123456,your email is 1101893634@qq.com.","tags":[{"name":"运维基本功","slug":"运维基本功","permalink":"http://www.dookt.com/tags/运维基本功/"}]},{"title":"Centos7网卡名称重命名及root密码重置","date":"2019-07-26T10:02:04.000Z","path":"post/36934.html","text":"CentOS7服务器，默认网卡名为ifcfg-eno16777736，如果我们想改成ifcfg-eth0，使用如下步骤即可： 编辑/etc/sysconfig/grub文件命令为vim /etc/sysconfig/grub，在倒数第二行quiet后加入如下代码，并如图3-14所示： 1net.ifnames=0 biosdevname=0 生成新的grub.cfg文件执行命令grub2-mkconfig -o /boot/grub2/grub.cfg，生成新的grub.cfg文件 1grub2-mkconfig -o /boot/grub2/grub.cfg 重命名网卡名称12mv ifcfg-eno16777736 ifcfg-eth0 sed -i 's/ifcfg-eno16777736/eth0/g' ifcfg-eth0 重启服务器验证网卡名称是否已修改CentOS7服务器忘记密码：修改CentOS7 ROOT密码非常简单，只需登录系统，执行命令passwd回车即可，但是如果忘记ROOT，无法登录系统，该如何去重置ROOT用户的密码呢？如下为重置ROOT用户的密码的方法： Reboot重启系统，系统启动进入欢迎界面，加载内核步骤时，按e，然后选中”CentOS Linux （3.10.0-327.e17.x86_64）7 （Core)” 继续按e进入编辑模式，找到ro crashkernel=auto xxx项，将ro改成rw init=/sysroot/bin/sh，如图3-19所示： 按ctrl+x进入单用户模式 执行命令chroot /sysroot访问系统，并使用passwd修改root密码 更新系统信息，touch /.autorelabel，执行命令touch /.autorelabel，在/目录下创建一个.autorelabel文件，如果该文件存在，系统在重启时就会对整个文件系统进行relabeling重新标记，可以理解为对文件进行底层权限的控制和标记，如果seLinux属于disabled关闭状态则不需要执行这条命令","tags":[{"name":"系统管理","slug":"系统管理","permalink":"http://www.dookt.com/tags/系统管理/"}]},{"title":"解决Nginx报错The plain HTTP request was sent to HTTPS port","date":"2019-07-26T10:01:26.000Z","path":"post/23576.html","text":"从报错的字面意思上来看，是因为HTTP请求被发送到HTTPS端口，这种报错多出现在Nginx既处理HTTP请求又处理HTTPS请求的情况。 修改nginx对应虚拟机的配置文件，找到https段123456server &#123; listen 443; ssl on; server_name localhost; ...&#125; 修改为如下即可实现http和https共存：12345server &#123; listen 443 ssl; server_name localhost; ...&#125;","tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://www.dookt.com/tags/Nginx/"}]},{"title":"Innobackupex——MySQL全备增备及恢复","date":"2019-07-26T10:00:31.000Z","path":"post/40146.html","text":"通常使用逻辑备份工具mysqldump备份mysql数据,但是数据库数据量很大时,使用mysqldump备份耗时太长,故采用物理备份,可使用mysqlhotcopy,可惜他只能备份myisam引擎的数据,Percona XtraBackup 是 Percona 公司开发的一个用于 MySQL 数据库物理热备的备份工具，且是开源项目。XtraBackup 工具下有一个 innobackupex 支持 MyISAM 跟 Innodb 的备份 安装xtraBackup https://www.percona.com/downloads/XtraBackup/1yum -y install https://www.percona.com/downloads/XtraBackup/Percona-XtraBackup-2.4.12/binary/redhat/7/x86_64/percona-xtrabackup-24-2.4.12-1.el7.x86_64.rpm innobackupex全备1innobackupex --user=user --password=passwd --no-timestamp ./`date +%F`.dbname –no-timestamp 如果不加的话会在备份目录下生成一个备份时间的目录，备份数据存在该目录下将整个数据库备份到 ./ 以备份日期加自定义名称的一个目录下虽然可以使用 –stream=tar 加 | gzip &gt; 的方式直接打包并压缩，但是备份速度就下降了，所以我宁愿快速备份，之后再去处理打包、压缩。三、innobackupex全备恢复 12345678910111213141516/etc/init.d/mysql.server stop # 首先关闭数据库cd /data/backup_db # 切换到备份目录mv /usr/local/mysql-5.5.52/data data.old # 将原来的数据目录备份一下tar zxf alldatabase.11.tar.gz # 然后将原来的备份解压缩innobackupex --apply-log alldatabase # 在备份上应用日志，一般没有看到报错且最后显示 OK 就没有问题 ( --use-memory 使用该参数加快速度 ) 12:07:33 completed OK!innobackupex --copy-back alldatabase # 将备份还原到 my.cnf 指定的 datadir 中，不指定 --defaults-file，默认 /etc/my.cnf Error: datadir must be specified. # 报错信息显示，在默认配置文件 /etc/my.cnf 中，没有找到 datadir 配置项vim /etc/my.cnf # 加入 datadir 配置项 datadir = /usr/local/mysql-5.5.52/datainnobackupex --copy-back alldatabase # 再次执行 copy 动作，没有报错且显示 OK 12:17:52 completed OK!ll -d /usr/local/mysql-5.5.52/data drwxr-x--- 6 root root 4096 10月 11 12:17 /usr/local/mysql-5.5.52/datachown -R mysql.mysql /usr/local/mysql-5.5.52/data # 修改数据目录权限/etc/init.d/mysql.server start 注意备份已经恢复!回顾整个恢复过程，发现一个问题：之前数据库里的东西全部没有了,也就是说，innobackupex 只适用于该 MySQL 中除系统库外，只有一个库的备份。虽然有选项 –databases 可以指定备份哪个数据库，但是备出来的结果却是 all databases，且恢复的时候也是全部覆盖。 采用 innobackupex 备份整库，然后恢复到一台新库上，再通过 mysqldump 将需要还原的单库备份一次，之后导入需要恢复的数据库中 ( 要考虑恢复时间 )。 采用 innobackupex 备份只有一个业务库的 MySQL Server，恢复到只有该业务库的 MySQL Server 中。 如果一个 MySQL Server 中有多个数据库，又只想备份某个库，且该库体积比较小的情况下，建议使用 mysqldump 备份。","tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.dookt.com/tags/数据库/"}]},{"title":"vim编辑器常用配置","date":"2019-07-26T09:57:33.000Z","path":"post/53596.html","text":"Vim是一个类似于Vi的著名的功能强大、高度可定制的文本编辑器，在Vi的基础上改进和增加了很多特性。 vim编辑器配置，配置文件如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109#关闭兼容模式set nocompatible#设置历史记录步数set history=100#开启相关插件filetype onfiletype plugin onfiletype indent on#文件被外部修改时，自动更新文件set autoread#激活鼠标使用set mouse=a#开启语法syntax enable#高亮显示当前行set cursorlinehi cursorline guibg=#00ff00hi CursorColumn guibg=#00ff00set nofenset fdl=0#使用空格来替换Tabset expandtab#设置锁头Tab缩进为4set tabstop=4#设定&amp;lt;&amp;lt;和&amp;gt;&amp;gt;命令移动宽度为4set shiftwidth=4set softtabstop=4set smarttab#设置自动缩进=\"set autoindent\"set ai#智能缩进set si#自动换行set wrap#设置软宽度set sw=4#显示行号#set nu#打开wild menuset wildmenu#显示标尺set ruler#设置命令行高度set cmdheight=1#set lz#设置退格set backspace=eol,start,indentset whichwrap+=&amp;lt;,&amp;gt;,h,l#设置魔术set magic#关闭错误是声音提示set noerrorbellsset novisualbell#&#123;[()]&#125;配对set showmatchset mat=2#高亮显示搜索到的内容set hlsearch#忽略大小写,可使用简写set ignorecase#设置编码,文件编码,终端编码set encoding=utf-8set fileencoding=utf-8set termencoding=utf-8#开启新行是智能缩进set smartindentset cin#隐藏工具栏set guioptions-=T#隐藏菜单栏set guioptions-=m#置空错误铃声终端代码set vb t_vb=#显示状态栏,默认为1,不显示set laststatus=2#粘贴不换行的解决方法set pastetoggle=&amp;lt;F9&amp;gt;#开启粘贴模式set paste#设置背景色set background=dark#高亮相关highlight Search ctermbg=black ctermfg=white guifg=white guibg=black#配置自动添加解释器,作者,版权信息autocmd BufNewFile *.py,*.cc,*.sh,*.java exec \":call SetTitle()\"func SetTitle() if expand(\"%:e\") == 'sh' call setline(1, \"#!/bin/bash\") call setline(2, \"#Author:mint\") call setline(3, \"#Blog:www.dookt.com\") call setline(4, \"#Time:\".strftime(\"%F %T\")) call setline(5, \"#Name\".expand(\"%\")) call setline(6, \"#Verson:v1.0\") call setline(6, \"#Info:This is a script.\") endifendfuncfunc SetTitle() if expand(\"%:e\") == 'py' call setline(1, \"#!/usr/bin/python\") call setline(2, \"#Author:mint\") call setline(3, \"#Blog:www.dookt.com\") call setline(4, \"#Time:\".strftime(\"%F %T\")) call setline(5, \"#Name\".expand(\"%\")) call setline(6, \"#Verson:v1.0\") call setline(6, \"#Info:This is a script.\") endifendfunc","tags":[{"name":"系统命令","slug":"系统命令","permalink":"http://www.dookt.com/tags/系统命令/"}]},{"title":"一个完成的HTTP请求过程","date":"2019-07-26T09:56:34.000Z","path":"post/34251.html","text":"LAMP架构主要用于发布WEB网页，发布HTML静态网页+PHP动态网页，Apache默认只能处理HTML静态网页，PHP动态网页交给PHP解释器（PHP模块）；注:DNS解析流程可使用dig命令查看dig +trace www.dookt.com 用户在Chrome浏览器中输入域名：www.dookt.com，按下回车：Chrome浏览器会首先搜索浏览器自身的DNS缓存（缓存时间比较短，大概只有1分钟，且只能容纳1000条缓存），看自身的缓存中是否有www.dookt.com 对应的条目，并且没有过期，如果有且没有过期则解析到此结束。Chrome自身的缓存可以使用 chrome://net-internals/#dns 查看 如果浏览器自身的缓存里面没有找到对应的条目，那么Chrome会搜索操作系统自身的DNS缓存,如果找到且没有过期则停止搜索解析到此结束.Windows系统,可以在命令行下使用 ipconfig /displaydns 来进行查看系统缓存 如果在Windows系统的DNS缓存也没有找到，那么尝试读取hosts文件（位于C:\\Windows\\System32\\drivers\\etc）Linux系统为（/etc/hosts），看看这里面有没有该域名对应的IP地址，如果有则系统会向服务器IP：80端口发起TCP三次握手（建立一个完整的数据传输通道），三次握手建立完毕之后，开始请求和发送HTTP数据请求 如果读取本地hosts文件，没有www.dookt.com对应的IP的记录，将域名查询请求交给本地DNS服务器（网卡配置文件指定的DNS 8.8.8.8），如果本地DNS缓存记录中有该域名+IP对应关系，直接返回IP，此种方式称为递归查询 如果本地DNS服务器缓存记录中没该域名+IP对应关系，将查询请求发往根DNS，根DNS不知道www.dookt.com.的IP地址，根DNS知道.net的DNS服务器，请求一级一级转发，.com DNS服务器也不知道www.dookt.com对应的IP，但是它知道dookt.com的DNS服务器，直到最后返回域名+IP对应关系 由根DNS、迭代DNS最终返回的域名+IP对应关系记录，交给本地DNS，本地DNS将IP信息返回客户端，同时在本地缓存一份，当下一次客户端再发起向该域名 IP请求时，可以直接返回 当Apache服务器接收到用户浏览器发起的请求之后，Apache服务器检测用户请求的网页类型，如果判断到用户请求的网页为HTML静态网页，Apache服务器处理该请求并且返回给用户数据，用户浏览器接收到服务器返回的数据之后，调取本地的软件来解析和渲染该数据，最终得到WEB页面 当Apache服务器判断用户请求的网页类型为PHP动态网页（Apache配置文件中定义一个AddType类型参数），Apache将动态网页请求交给PHP模块，Apache如何知道PHP模块在哪里？Apache+PHP模块共享内存空间，整合在一起，也可以理解为PHP模块是Apache外挂模块（第三方模块） 如果PHP模块接收到Apache发送的PHP动态网页请求，PHP解释器读取PHP网页文件，是否有后端MYSQL数据库信息获取，如果需要从后端获取数据库，PHP解释器基于PHP-MYSQL驱动读取后端MYSQL数据库中内容，最后网页内容+数据信息统一被PHP解释器解析为HTML静态网页 PHP解释器将解析之后的HTML静态网页交给Apache WEB服务器，Apache处理HTML静态网页，最终返回给用户浏览器","tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://www.dookt.com/tags/Nginx/"}]},{"title":"查看dd命令的进度","date":"2019-07-26T09:55:41.000Z","path":"post/22610.html","text":"1234567watch -n 5 pkill -USR1 ^dd$watch -n 5 killall -USR1 ddwhile killall -USR1 dd; do sleep 5; donewhile (ps auxww |grep \" dd \" |grep -v grep |awk '&#123;print $2&#125;' |while read pid; do kill -USR1 $pid; done) ; do sleep 5; done","tags":[{"name":"系统命令","slug":"系统命令","permalink":"http://www.dookt.com/tags/系统命令/"}]},{"title":"shell基础","date":"2019-07-26T09:55:02.000Z","path":"post/52853.html","text":"判断表达式1234if test 表达式为真 if [ 表达式 ]if test !表达式为假 if [ !表达式 ]test 表达式1 –a 表达式2 if [ 表达式1 -a 表达式2 ] 两个表达式都为真test 表达式1 –o 表达式2 if [ 表达式1 -o 表达式2 ] 两个表达式有一个为真 判断字符串1234test –n 字符串 if [ &amp;nbsp;-n 字符串 ] 字符串的长度是否非零test –z 字符串 if [ &amp;nbsp;-z 字符串 ] 字符串的长度是否为零test 字符串1＝字符串2 if [ &amp;nbsp;字符串１=字符串２ ] 字符串是否相等test 字符串1!＝字符串2 if [ &amp;nbsp;字符串１!=字符串２ ] 字符串是否不等 判断整数123456test 整数1 –eq 整数2 if [ 1 -eq 2 ] 整数是否相等test 整数1 –ge 整数2 if [ 1 -ge 2 ] 整数1是否大于等于整数2test 整数1 –gt 整数2 if [ 1 -gt 2 ] 整数1是否大于整数2test 整数1 –le 整数2 整数1小于等于整数2test 整数1 –lt 整数2 整数1是否小于整数2test 整数1 –ne 整数2 整数1是否不等于整数2 判断文件12345678910111213141516171819202122test File1 –ef File2 两个文件具有同样的设备号和i结点号test File1 –nt File2 文件1比文件2 新test File1 –ot File2 文件1比文件2 旧test –b File 文件存在并且是块设备文件test –c File 文件存在并且是字符设备文件test –d File 文件存在并且是目录test –e File 文件存在test –f File 文件存在并且是正规文件test –g File 文件存在并且是设置了组IDtest –G File 文件存在并且属于有效组IDtest –h File 文件存在并且是一个符号链接（同-L）test –k File 文件存在并且设置了sticky位test –b File 文件存在并且是块设备文件test –L File 文件存在并且是一个符号链接（同-h）test –o File 文件存在并且属于有效用户IDtest –p File 文件存在并且是一个命名管道test –r File 文件存在并且可读test –s File 文件存在并且是一个套接字test –t FD 文件描述符是在一个终端打开的test –u File 文件存在并且设置了它的set-user-id位test –w File 文件存在并且可写test –x File 文件存在并且可执行","tags":[{"name":"运维基本功","slug":"运维基本功","permalink":"http://www.dookt.com/tags/运维基本功/"}]},{"title":"使用Linux服务器发送邮件","date":"2019-07-26T09:53:56.000Z","path":"post/40639.html","text":"安装软件1yum -y install mailx 配置第三方SMTPvi /etc/mail.rc在文档末添加如下设置 12345set from=\"1831xxxx@163.com\" # 发信电子邮件地址set smtp=smtp.163.com # 发信服务器地址set smtp-auth=login # 认证方式set smtp-auth-user=1831xxxx@163.com # 发信认证账户set smtp-auth-password=***** # 发信认证账户密码(授权码) 发送邮件12echo \"Text\"|mail -s Subject 1831xxxx.163.commail -s \"This is a test mail\" 18313178130@163.com &amp;lt; /tmp/test.log #后接文本内容,邮件正文","tags":[{"name":"系统管理","slug":"系统管理","permalink":"http://www.dookt.com/tags/系统管理/"}]},{"title":"Fedora安装网易云音乐","date":"2019-07-26T09:46:43.000Z","path":"post/7564.html","text":"1234sudo dnf install --nogpgcheck http://download1.rpmfusion.org/free/fedora/rpmfusion-free-release-24.noarch.rpmsudo config-manager --add-repo=http://repo.fdzh.org/FZUG/FZUG.reposudo dnf install gstreamer-plugins-bad gstreamer-plugins-bad-free-extras gstreamer-plugins-ugly gstreamer-ffmpeg gstreamer1-libav gstreamer1-plugins-bad-free-extras gstreamer1-plugins-bad-freeworld gstreamer-plugins-base-tools gstreamer1-plugins-good-extras gstreamer1-plugins-ugly gstreamer1-plugins-bad-free gstreamer1-plugins-good gstreamer1-plugins-base gstreamer1yum -y install netease-cloud-music-1.0.0-1.x86_64.rpm","tags":[{"name":"系统管理","slug":"系统管理","permalink":"http://www.dookt.com/tags/系统管理/"}]},{"title":"防止linux命令行登录mysql登录密码泄露","date":"2019-07-26T09:45:27.000Z","path":"post/64911.html","text":"使用linux命令行登录mysql，会在history中记录下mysql的登录用户名密码.怎样才能隐藏呢? 可以使用环境变量HISTCONTROL可以使用环境变量HISTCONTROL=ignorespace首先执行该命令,在需要不记录的命令前添加一个空格 1234echo \"export HISTCONTROL=ignorespace\" &gt;&gt; /etc/profile #使HISTCONTROL=ignorespace全局生效 source /etc/profile mysql -uroot -p123456 #最前方有空格,此时history不会记录 history -d 3007 #删除第3007条历史记录 配置用户名、密码在配置文件中带密码的启动、备份脚本使用700权限,修改用户组为root把密码写入my.cnf文件,使用700权限,修改用户组为mysql (在文件[client])断添加user=root password=123456) 当然使用交互式输入密码则无需以上几种操作","tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.dookt.com/tags/数据库/"}]},{"title":"zookeeper单节点-伪集群-集群环境部署","date":"2019-07-26T09:44:38.000Z","path":"post/23319.html","text":"zookeeper部署有三种方式（单机版、伪集群—多实例、集群模式） 单机版zk部署12345wget -c https://mirrors.dookt.com/zookeeper/zookeeper-3.4.10.tar.gztar -xzvf zookeeper-3.4.10.tar.gzmv zookeeper-3.4.10 /usr/local/zookeepergrep \"^[a-z]\" /usr/locl/zookeeper/conf/zoo_sample.cfg &gt;/usr/local/zookeeper/zoo.cfgsed -i 's/dataDir=@/tmp/zookeeper@/usr/local/zookeeper/data@g' usr/local/zookeeper/conf/zoo.cfg tickTime=2000 ##超时配置的基本单位，2000ms，1 tickTime是客户端与zk服务端的心跳时间，20 tickTime是客户端会话的超时时间。initLimit=10 ##initLimit配置follower与leader之间建立连接后进行同步的最长时间syncLimit=5 ##配置follower和leader之间发送消息，请求和应答的最大时间长度dataDir=/usr/local/zookeeper/zk/data ##无默认配置，必须配置，用于配置存储快照文件的目录。如果没有配置dataLogDir，那么事务日志也会存储在此目录clientPort=2181 ##zk服务进程监听的TCP端口，默认情况下，服务端会监听2181端口修改dataDir目录为实际目录 增加dataLogDir 路径 伪集群配置（单台主机172.17.0.1，多实例部署，启用不同端口）实例一配置如下： 123456789tickTime=2000initLimit=10syncLimit=5dataDir=/usr/local/zookeeper01/datadataLogDir=/usr/local/zookeeper01/dataclientPort=2181server.1=172.17.0.1:2888:3888server.2=172.17.0.1:4888:5888server.3=172.17.0.1:6888:7888 实例二配置如下：123456789tickTime=2000initLimit=10syncLimit=5dataDir=/usr/local/zookeeper02/datadataLogDir=/usr/local/zookeeper02/dataclientPort=2182server.1=172.17.0.1:2888:3888server.2=172.17.0.1:4888:5888server.3=172.17.0.1:6888:7888 实例三配置如下：123456789tickTime=2000 initLimit=10 syncLimit=5 dataDir=/usr/local/zookeeper03/data dataLogDir=/usr/local/zookeeper03/data clientPort=2183 server.1=172.17.0.1:2888:3888 server.2=172.17.0.1:4888:5888 server.3=172.17.0.1:6888:7888 配置节点ID（在每个zk实例中添加myid）123echo 1 &gt; /usr/local/zookeeper01/data/myidecho 2 &gt; /usr/local/zookeeper02/data/myidecho 3 &gt; /usr/local/zookeeper03/data/myid 集群版本部署（集群版本需要复制几份，添加myid），各节点配置如下 123456789# cat /usr/local/zookeeper/conf/zoo.cfgtickTime=2000initLimit=10syncLimit=5dataDir=/usr/local/zookeeper/dataclientPort=2181server.1=172.17.0.2:2888:3888server.2=172.17.0.3:2888:3888server.3=172.17.0.4:2888:3888 分别在不同zk节点上执行一下语句123echo 1 &gt; usr/local/zookeeper/data/myidecho 2 &gt; usr/local/zookeeper/data/myidecho 3 &gt; usr/local/zookeeper/data/myid","tags":[{"name":"高可用","slug":"高可用","permalink":"http://www.dookt.com/tags/高可用/"}]},{"title":"Rocketmq双master集群部署","date":"2019-07-26T09:42:58.000Z","path":"post/19268.html","text":"系统环境172.17.0.17 rocketmqnameserver1,broker-a Master1172.17.0.18 rocketmqnameserver2,broker-b Master2 注：两台机器上安装好jdk1.8，并关闭防火墙 配置host文件分别在这两台机器的hosts文件中添加 123456# cat /etc/hosts#rocketmq 172.17.0.17 rocketmq-nameserver1172.17.0.17 rocketmq-master1172.17.0.18 rocketmq-nameserver2172.17.0.18 rocketmq-master2 修改主机名17上执行命令：hostnamectl set-hostname rocketmq-nameserver118上执行命令：hostnamectl set-hostname rocketmq-nameserver2 安装rocketmq/opt/package/rocketmq-all-4.1.0-incubating-bin-release.zip到/opt/app，并命名为rocketmq 12unzip rocketmq-all-4.1.0-incubating-bin-release.zip /opt/appmv /opt/app/rocketmq-all-4.1.0-incubating/ /opt/app/rocketmq 创建rocketmq存储的相关文件及路径12mkdir /opt/data/rocketmqtouch /opt/data/rocketmq/commitlog /opt/data/rocketmq/consumequeue /opt/data/rocketmq/index /opt/data/rocketmq/checkpoint /opt/data/rocketmq/abort 修改broker的配置文件17上 123456789101112131415161718192021# cat /opt/app/rocketmq/conf/2m-noslave/broker-a.propertiesbrokerClusterName=DefaultClusterbrokerName=broker-abrokerId=0deleteWhen=04fileReservedTime=48brokerRole=ASYNC_MASTERflushDiskType=ASYNC_FLUSHnamesrvAddr=mq-nameserver-1:9876;mq-nameserver-2:9876#存储路径storePathRootDir=/opt/data/rocketmq/#commitLog 存储路径storePathCommitLog=/opt/data/rocketmq/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/opt/data/rocketmq/consumequeue#消息索引存储路径storePathIndex=/opt/data/rocketmq/index#checkpoint 文件存储路径storeCheckpoint=/opt/data/rocketmq/checkpoint#abort 文件存储路径abortFile=/opt/data/rocketmq/abort 17上 123456789# cat /opt/app/rocketmq/conf/2m-noslave/broker-b.propertiesbrokerClusterName=DefaultClusterbrokerName=broker-bbrokerId=0deleteWhen=04fileReservedTime=48brokerRole=ASYNC_MASTERflushDiskType=ASYNC_FLUSHnamesrvAddr=mq-nameserver-1:9876;mq-nameserver-2:9876 18上 123456789101112131415161718192021# cat /opt/app/rocketmq/conf/2m-noslave/broker-a.propertiesbrokerClusterName=DefaultClusterbrokerName=broker-abrokerId=0deleteWhen=04fileReservedTime=48brokerRole=ASYNC_MASTERflushDiskType=ASYNC_FLUSHnamesrvAddr=mq-nameserver-1:9876;mq-nameserver-2:9876#存储路径storePathRootDir=/opt/data/rocketmq/#commitLog 存储路径storePathCommitLog=/opt/data/rocketmq/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/opt/data/rocketmq/consumequeue#消息索引存储路径storePathIndex=/opt/data/rocketmq/index#checkpoint 文件存储路径storeCheckpoint=/opt/data/rocketmq/checkpoint#abort 文件存储路径abortFile=/opt/data/rocketmq/abort 18上 123456789# cat /opt/app/rocketmq/conf/2m-noslave/broker-b.propertiesbrokerClusterName=DefaultClusterbrokerName=broker-bbrokerId=0deleteWhen=04fileReservedTime=48brokerRole=ASYNC_MASTERflushDiskType=ASYNC_FLUSHnamesrvAddr=mq-nameserver-1:9876;mq-nameserver-2:9876 修改日志配置文件分别修改两台机器的日志配置文件并且把conf目录下所有xml文件中的${user.home}替换为/opt/app/rocketmq 123mkdir -p /opt/logs/rocketmqcd /opt/app/rocketmq/confsed -i 's#$&#123;user.home&#125;#/opt/app/rocketmq#g' *.xml 分别修改两台机器的rocketmq启动脚本 12# cat /opt/app/rocketmq/bin/runbroker.shJAVA_OPT=\"$&#123;JAVA_OPT&#125; -server -Xms8g -Xmx8g -Xmn4g -XX:PermSize=128m -XX:MaxPermSize=320m\" 12# cat /opt/app/rocketmq/bin/runserver.shJAVA_OPT=\"$&#123;JAVA_OPT&#125; -server -Xms4g -Xmx4g -Xmn2g -XX:PermSize=128m -XX:MaxPermSize=320m\" 注：若配置过低，请记得调整jvm参数，Xms为启动时分配的内存，Xmx为运行过程中分配的最大内存，Xmn为_____,可做如下配置：Xms512m -Xmx512m -Xmn256m 分别启动nameserver启动NameServer（特别注意：在启动 BrokerServer 之前先关闭防火墙） 12cd /opt/app/rocketmq/binnohup sh mqnamesrv &amp;amp; 启动BrokerServerbroker-a: 123456cd /opt/app/rocketmq/bin&lt;br /&gt;nohup sh mqbroker -c /opt/app/rocketmq/conf/2m-noslave/broker-a.properties /dev/null 2netstat -ntlpjpstail -f -n 500 /usr/local/software/rocketmq/logs/rocketmqlogs/broker.logtail -f -n 500 /usr/local/software/rocketmq/logs/rocketmqlogs/namesrv.log broker-b: 123456cd /opt/app/rocketmq/binnohup sh mqbroker -c /opt/app/rocketmq/conf/2m-noslave/broker-b.properties /dev/null 2netstat -ntlpjpstail -f -n 500 /usr/local/software/rocketmq/logs/rocketmqlogs/broker.logtail -f -n 500 /usr/local/software/rocketmq/logs/rocketmqlogs/namesrv.log 停止服务先停止broker 在停止 namesrv&lt; 12cd /opt/app/rocketmq/binsh mqshutdown broker","tags":[{"name":"高可用","slug":"高可用","permalink":"http://www.dookt.com/tags/高可用/"}]},{"title":"Redis主从哨兵集群","date":"2019-07-26T09:41:53.000Z","path":"post/35151.html","text":"单机redis宕机之后，不能正常提供服务，此时就需要部署Redis哨兵集群(一主两从三哨兵)来实现高可用 系统环境(redis-4.0.9，docker_centos6.3) 主机名 IP地址 软件包 redis01 172.17.0.11 master,sentinel01 redis02 172.17.0.11 slave01,sentinel01 redis03 172.17.0.11 slave02,sentinel01 安装部署（每个节点都需安装）123tar -xzvf redis-4.0.9.tar.gz -C /usr/local/mv /usr/local/redis-4.0.9 /usr/local/redismake PREFIX=/usr/local/redis install 配置master（172.17.0.11）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253bind 0.0.0.0protected-mode noport 6379tcp-backlog 511timeout 0tcp-keepalive 300daemonize yessupervised nopidfile \"/var/run/redis_6379.pid\"loglevel noticelogfile \"/var/log/redis_6379.log\"databases 16save 900 1save 300 10save 60 10000stop-writes-on-bgsave-error yesrdbcompression yesrdbchecksum yesdbfilename \"dump.rdb\"dir \"/var/lib/redis/6379\"slave-serve-stale-data yesslave-read-only yesrepl-diskless-sync norepl-diskless-sync-delay 5repl-disable-tcp-nodelay noslave-priority 100appendonly yesappendfilename \"appendonly.aof\"appendfsync everysecno-appendfsync-on-rewrite noauto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mbaof-load-truncated yeslua-time-limit 5000slowlog-log-slower-than 10000slowlog-max-len 128latency-monitor-threshold 0notify-keyspace-events \"\"hash-max-ziplist-entries 512hash-max-ziplist-value 64list-max-ziplist-size -2list-compress-depth 0set-max-intset-entries 512zset-max-ziplist-entries 128zset-max-ziplist-value 64hll-sparse-max-bytes 3000activerehashing yesclient-output-buffer-limit normal 0 0 0client-output-buffer-limit slave 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60hz 10aof-rewrite-incremental-fsync yesslaveof 172.17.0.11 6379 配置slave（172.17.0.12,172.17.0.13）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253bind 0.0.0.0protected-mode noport 6379tcp-backlog 511timeout 0tcp-keepalive 300daemonize yessupervised nopidfile \"/var/run/redis_6379.pid\"loglevel noticelogfile \"/var/log/redis_6379.log\"databases 16save 900 1save 300 10save 60 10000stop-writes-on-bgsave-error yesrdbcompression yesrdbchecksum yesdbfilename \"dump.rdb\"dir \"/var/lib/redis/6379\"slave-serve-stale-data yesslave-read-only yesrepl-diskless-sync norepl-diskless-sync-delay 5repl-disable-tcp-nodelay noslave-priority 100appendonly yesappendfilename \"appendonly.aof\"appendfsync everysecno-appendfsync-on-rewrite noauto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mbaof-load-truncated yeslua-time-limit 5000slowlog-log-slower-than 10000slowlog-max-len 128latency-monitor-threshold 0notify-keyspace-events \"\"hash-max-ziplist-entries 512hash-max-ziplist-value 64list-max-ziplist-size -2list-compress-depth 0set-max-intset-entries 512zset-max-ziplist-entries 128zset-max-ziplist-value 64hll-sparse-max-bytes 3000activerehashing yesclient-output-buffer-limit normal 0 0 0client-output-buffer-limit slave 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60hz 10aof-rewrite-incremental-fsync yesslaveof 172.17.0.11 6379 配置哨兵（172.17.0.11，172.17.0.12,172.17.0.13）123456789101112131415161718port 26379daemonize yes###定义目录存放dir \"/var/lib/redis/sentinel\"###监控mymaster(可自定义-但只能包括A-z 0-9和”._-”)，注意quorum只影响ODOWN的判断，但是不影响failover，发生failover的条件必须是半数sentinel认为老Master已经ODOWN。此参数建议设置为sentinel/2+1的数值，否则可能会产生脑裂。sentinel myid 25370cfd146b4a7302f5c40f3c402f7869d53ce7###mymaster多久不响应认为SDOWN，设置为3100也就是说3次ping失败后认为SDOWNsentinel monitor mymaster 172.17.0.11 6379 2###如果在该时间（ms）内未能完成failover操作，则认为该failover失败sentinel down-after-milliseconds mymaster 3100###在执行故障转移时， 最多可以有多少个从Redis实例在同步新的主实例， 在从Redis实例较多的情况下这个数字越小，同步的时间越长，完成故障转移所需的时间就越长sentinel failover-timeout mymaster 15000###reconfig的时候执行的脚本（选配）###sentinel client-reconfig-script mymaster /redis/script/failover.sh###出现任何sentinel在warning事件时候执行的脚本（选配）###sentinel notification-script mymaster /redis/script/notify.sh####日志位置logfile \"/usr/local/redis/logs/sentinel.log\" 服务启动停止，依次启动master,slave，sentinal1234567891011/usr/local/redis/bin/redis-server redis.confps -ef | grep redistail -f /usr/local/redis/logs/redis.conf/usr/local/redis/bin/redis-server redis.confps -ef | grep redistail -f /usr/local/redis/logs/redis.conf/usr/local/redis/bin/redis-server sentinel.conf --protected-mode no &amp;gt; /usr/local/redis/logs/sentinel.log &amp;amp;ps -ef | grep redistail -f /usr/local/redis/logs/sentinel.conf 当主机宕掉的时候，会由哨兵从备机中推选出一台成为主机，当宕掉的主机再启动的时候就变成了备机。 当应用启动并连上哨兵后，如果哨兵宕掉，应用可以正常运行。但是，如果应用重启依然需要通过哨兵连接redis缓存（主机/备机），则无法正常","tags":[{"name":"高可用","slug":"高可用","permalink":"http://www.dookt.com/tags/高可用/"},{"name":"数据库","slug":"数据库","permalink":"http://www.dookt.com/tags/数据库/"}]},{"title":"Ansible使用小记","date":"2019-07-26T09:38:02.000Z","path":"post/28939.html","text":"ansible执行过程 加载默认配置文件/etc/ansible/ansible.cfg 加载对应的模块文件，如command 通过ansible将模块或命令生成一个python文件，将其临时 拷贝至远程服务器的用户$HOME/.ansible/tmp/ansible-temp-数字-/xxx.py文件，并给文件执行权限（ansible执行原理） 执行并返回结果，删除临时文件，退出 主机清单假如服务器环境分为两类，“生产环境”和“测试环境”，当然生产环境又包括很多模块，所以需要更详细的分组，实例如下： 12345678910111213141516# cat /etc/ansible/hosts[procA]10.3.30.410.3.30.5[procB]10.3.30.610.3.30.7[procC]10.3.30.8[proc:children]procAprocB 1# ansible proc -m ping #查看procA、procB的状态 ansible执行状态 执行成功，并且不需要做改变的操作 黄色：执行成功，但未更改主机操作 红色：执行失败 1host_key_checking = False #连接时不检查新主机，分发公钥是不在需要输入yes ansible-doc #ansible 的帮助手册 ansible-doc帮助手册12# ansible-doc -l #查看ansible支持的模块# ansible-doc -s copy #简单查看copy模块用法 hostsname模块1ansible 172.17.0.2 -m -a 'name=node1' ping模块确认和远程主机之间是否能正常通信，正常则返回”pong” 1ansible all -m ping #检测主机是否在线 setup模块该模块用于收集远程主机信息，setup模块给出的信息十分丰富，可使用filter参数进行过滤 1ansible all -m setup -a \"filter=ansible-fqdn\" #查看所有主机的主机名 command | shell | script模块shell模块支持管道、变量，命令通过shell进程处理,scripts模块将脚本传到远程主机执行,comand模块不支持管道、变量，命令不通过shell处理，ansible默认command模块chdir：运行命令前，先切换至指定目录creates：创建文件，若文件存在则不执行命令removes：删除文件，文件不存在则不执行命令 123ansible all -m command -a \"sh test.sh /chdir=/scripts\" #先进入到/scripts目录下，在执行test.sh脚本ansible all -m shell -a \"ls /script|grep test\" #查找/scripts目录下包含test的文件或目录ansible all -m script -a \"sh test.sh chdir=/scripts\" #先进入到/scripts目录下，在执行test.sh脚本 file模块可完成文件或目录的创建，删除，权限修改path：必选参数，用于指定操作的文件、目录，也可使用name，dest参数兼容低版本state：可使用directory,touch,link,hard,absent值，directort为创建目录，touch为创建文件，link为创建软链接，hard为创建硬链接，absent为删除（目录、文件、链接）src：state=link或hard时，表明是要创建链接，所以必须指定连接的文件，通过src指定链接源force：state=link,可选yes或no，为yes时，若链接文件不存在时，会先创建链接文件，若链接目录中存在与链接文件同名的文件，会覆盖链接文件，若链接目录中存在与链接文件同名的文件，但源文件不存在时，会强制替换同名文件owner：指定创建文件的属主group：指定创建文件的属组recurse：要操作的文件为目录是，recurse=yes,会递归操作 1234ansible all -m file -a \"path=/tmp/test.txt state=touch\" #在/tmp目录下创建test.txt文件ansible all -m file -a \"path=/tmp/test/ state=directory\" #在/tmp目录下创建test目录ansible all -m file -a \"path=/usr/local/mysql/bin/* state=link dest=/usr/bin/ force=yes\" #创建mysql连接到链接到/usr/bin目录下ansible all -m file -a \"path=/tmp/test.txt state=absent\" #删除/tmp目录下的文件test.txt copy模块copy可以拷贝文件至远程服务器，src：指定源文件dest：指定文件拷贝到远程主机的位置content：指定文件内容，与src必须有其一backup：远程主机目标路径存在同名文件，并且与ansible主机文件不同时，对远程主机文件进行备份（添加一个时间戳），可选yes与no，若为yes，则先执行备份，再拷贝文件至远程主机force：远程主机目标路径存在同名文件，并且与ansible主机文件内容不同时是否覆盖，可选yes或no，yes为覆盖，no不执行覆盖操作，文件内容不改变owner：指定文件拷贝至远程主机后的属主，远程主机须有该用户，否则会报错group：指定文件拷贝至远程主机后的属组，远程主机须有该组，否则会报错mode：指定文件拷贝至远程主机后的权限，可使用mode=0644，mode=u+x等 1ansible all -m copy -a \"src=test.txt dest=/tmp/test.txt backup=yes owner=redhat mode=644\" #拷贝test.txt到远程主机的/tmp目录，更改所有者为redhat，权限为644 yum模块用于远程主机上的软件管理name：指定软件名，如nginxstate：指定软件包状态，默认为present，可使用installed、latest、absent、removed等值，installed与present为安装，latest为安装最新版，absent和removed为卸载disable-gpg-check：禁用rpm包的gpg验证，默认为no不禁用验证，再yum源没有开启gpg验证时，需要设置此项为yes，否则报错无法进行安装enablerepo：临时启用yum源disablerepo：临时禁用yum源，可与enablerepo同时使用 1234ansible all -m yum -a \"name=nginx state=installed check-gpg-check=yes\" #开启gpg校验安装nginxansible zookeeper -m yum -a \"name=/opt/package/jdk-8u191-linux-x64.rpm state=present\" #安装jdk这个rpm包ansible all -m yum -a \"name=httpd,redis,php,mysql state=absent\" #卸载httpd,redis,php,mysql包ansible all -m yum -a \"name=dstat upadte_cache=yes\" #清除缓存，再安装dstat service模块用于管理远程主机上的服务，启动、停止、重载、开机启动name：指定服务名称，如nginxstate：指定服务状态，可使用started、stopped、restarted、reloadedenabled：是否开机启动，可使用yes与no，yes表示开机启动 1ansible all -m service -a \"name=nginx state=restarted enabled=yes\" #开启nginx服务，并开机启动 user模块用于管理远程主机系统用户name: 指定用户名comment：注释create_home：是否穿件家目录（yes|no）group：指定所属主组groups：指定所属附加组shell：指定shell的类型home：指定用户家目录remove：用于删除，当state=absent时，相当与userdel -rsystem：指定为系统账号 123ansible all -m user -a 'name=nginx shell=/sbin/nologin system=yes home=/usr/local/nginx groups=root,bin uid=80 comment=Nginx service' #添加系统用户nginx，并指定shell为/sbin/nologin，家目录为/usr/local/nginx，附加组为root、bin组，指定uid为80，注释为Nginx servie ansible all -a \"getent passwd nginx\" #查看nginx用户ansible all -m user -a 'name=nginx state=absent remove=yes' #删除nginx用户及其家目录 group模块gid：指定组IDname：指定组名state：指定删除还是新建组system：指定系统组 123ansible all -m group -a 'name=nginx system=yes gid=80' #创建系统组nginx，指定gid为80ansible all -a 'getent group nginx' #查看nginx组ansible all -m group -a 'name=nginx state=absent' #删除nginx组 template模块template模块与copy模块使用方法以及参数与copy模块一致，但template可以传递变量，以下例子zabbix_agentd.conf配置文件需要传递agent和server的IP地址，各个agent的IP地址不一样，此时IP地址即可作为变量传递。 1ansible all -m template -a \"src=zabbix_agentd.conf dest=/etc/zabbix/zabbix_agentd.conf\" #拷贝带变量的zabbix_agentd.conf 文件到远程主机 使用template模块分发zabbix-agent配置文件， 1234567- hosts: all user: root tasks: - name: Push config file template: src=zabbix_agentd.conf dest=/etc/zabbix_agentd.conf backup=yes - name: Restart zabbix-agent enable boot zabbix-agent service: name=zabbix-agent state=restarted enabled=yes cron模块可以再远程主机上添加计划任务，相当于crontab命令minute：设置分钟，默认值为&#42;，minute=5hour：设置小时，默认值为&#42;，hour=1,凌晨一点day：设置天数，默认为&#42;，month：设置月份weekday：设置周user：设置执行该计划任务的用户，需要远程主机上有该用户jobs：指定计划任务中要执行的命令或脚本name：该计划任务的名字state：设置计划任务的状态，若该计划任务有名字，删除时，可使用state=absentdisabled：使计划任务失效，使用时必须指定名称，jobs以及执行任务的时间，还要保证完全相同，否则在注视任务的同时，任务时间会被修改backup：修改或删除计划任务时，是否备份，可使用yes或no，yes时备份文件至tmp目录，备份文件名称可在返回信息的bakcup_file字段中看到，推荐设置此参数为yes 12345ansible all -m cron -a 'name=\"test ansible cron \" hour=5 minute=10 jobs=\"echo test\"' #每天5:10输出字符串test，该计划任务的名字为test ansible cronansible all -m cron -a 'minute=* weekday=1,3,5 job=\"/usr/bin/wall FBI warning\" name=Warning' #周一周三周五每分钟执行一次广播ansible all -m cron -a 'disabled=true job=\"/usr/bin/wall FBI warning\" name=Warning' #关闭上一步骤的cron, disabled=(true|false|yes|no)ansible all -m cron -a 'disabled=no job=\"/usr/bin/wall FBI warning\" name=Warning' #启用上一步骤的cron, disabled=(true|false|yes|no)ansible all -m cron -a 'job=\"/usr/bin/wall FBI warning\" name=Warning state=absent' #删除上一步骤的cron authorized_key新增公钥内容到服务器家目录.ssh下的authorized_keys文件，没有则创建authorized_keys文件操作=（参数），参数必须-exclusive：是否移除authorized_keys文件中其他非指定key=key：公钥可以是字符串或url-key_options：附加到key中的字符串，该串回家至key的开头，默认没有-path：指定authorized_keys的存放位置，默认的家目录下.ssh/authorized_keysstate：添加移除，可使用present或absentuser：操作远程主机上的哪个用户的authorized_keys ansible-galaxy连接[ansible](https://galaxy.ansible.com ansible网站)网站下载相应的roles 123ansible-galaxy list #列出所有已安装的galaxyanisble-galaxy install geerlingguy.redis #安装galaxyansible-galaxy remove geelingguy.redis #删除galaxy ansible-pull推送命令至远程，效率无限提升 ansible-vault加密playbook文件 12345ansible-vault encrypt hello.yml #加密ansible-vault decrypt hello.yml #解密ansible-vault view hello.yml #查看加密的playbook内容ansible-vault edit hello.yml #编辑加密的ansible-vault rekey hello.yml #修改playbook的加密密码ansible-vault create hello.yml #创建加密的playbook文件 ansible-console可交互式执行命令，支持tab ansible-playbookplaybook是由一个或多个play组成的列表play的主要功能是将事先定义好的主机通过ansible中的task定义好的角色。将多个play组织在一个playbook中，可以联合起来按照事先写好的剧本排演，taks可理解为调用ansible的一个模块playbook通过yaml语言编写 palybook变量变量来源： ansible setup模块中的所有变量都可使用 在/etc/ansible/hosts中定义 在主机组中单独定义，优先级高于公共变量 通过命令行指定变量，优先级最高，ansible-playbook -e varname=value 在playbook中定义 在role中定义 palybook核心元素Hosts：执行远程任务的主机列表Tasks：任务集Varniables：内置变量或自定义变量在playbook中调用Template：模板，可替换模板文件中的变量并实现一些简单逻辑操作的文件Handers和Notify结合使用，由特定的条件触发，满足条件则执行，否则不执行Tag标签：指定某条任务运行时，用于选择运行playbook的部分代码，ansible具有幂等性，因此会跳过没有变化的部分，但是，有些代码未测试其确没有发生变化的时间过长，此时，若确切没有发生变化，就可以通过tags跳过此代码片段 1234ansible-playbook -t tagsname useradd.yml #通过tags跳过此片段ansible-playbook -C file.yml #检测可能发生的改变，不是真正的执行ansible-playbook file.yml --limit 172.17.0.3 #只针对主机列表中的主机执行命令ansible-playbook file.yml --list-tasks #查看任务列表 123456789101112131415- hosts: all remote_user: root gather_facts: False tasks: - name: create user user: name=mint home=/opt/mint groups=wheel - name: create dir file: name=/data/ state=directory - name: create file file: name=/data/test_file.sh mode=755 state=touch owner=mint group=mint - name: install httpd yum: name=httpd state=present - name: startup httpd service service: name=httpd state=started enabled=yes Handers和Notifyhanders是一个触发器，与tasks并列 ，监控其中一个action动作，如果一个action动作执行成功了，会触发handers后面定义的命令，配和Notify使用 1234567891011121314151617- hosts: all remote_user: root gather_facts: False tasks: - name: install httpd yum: name=httpd state=present - name: copy config copy: src=httpd.conf dest=/etc/httpd/conf/httpd.conf backup=yes notify: - restart service - name: startup httpd service service: name=httpd state=started enabled=yes handlers: - name: restart service service: name=httpd state=restarted 可以指定标签执行,多个动作可共用一个标签 1# cat httpd.yml 12345678910111213141516171819- hosts: all remote_user: root gather_facts: False tasks: - name: install httpd yum: name=httpd state=present tags: inshttpd - name: copy config copy: src=httpd.conf dest=/etc/httpd/conf/httpd.conf backup=yes notify: - restart service - name: startup httpd service service: name=httpd state=started enabled=yes tags: rshttpd handlers: - name: restart service service: name=httpd state=restarted 1ansible-playbook -t rshttpd httpd.yml 批量分发ssh公钥的playbook文件123456789101112- hosts: allgather_facts: Falseremote_user: rootbecome: yesbecome_user: roottasks: - name: Push ssh pub key authorized_keys authorized_keys: user: root key: \"&#123;&#123;lookup('file','/root/.ssh/id_rsa.pub')&#125;&#125;\" state: present exclusive: yes 主机清单123456789#cat /etc/ansible/hosts[centos6]172.17.0.2 http_port=81172.17.0.3 http_port=82[centos7]172.17.0.6 http_port=81172.17.0.7 http_port=82[centos7:vars]http_port=80 模板Template*文本文件，嵌套脚本（使用模板编程语言编写）*Jinja2语言，使用字面量（字母数字组合起来的），有如下形式 字符串：使用单、双引号 数字：整数、浮点数 列表：[item1,item2,…] 元组：(item1,item2,…) 字典：{key1:value2,key2:value2,…} 布尔值：true/false 算数运算：+，-，，/，//，%，* 比较操作：= =，!=，&gt;=，&lt;，&lt;= 逻辑运算：and，or，not 流表达式：For，If，When 变量生效优先级：命令行直接定义（-e选项）&gt; playbook &gt; 主机清单中普通变量 &gt; 主机清单中公共变量 When语句条件测试：如果需要根据变量，facts或此前任务的执行结果来作为task执行与否的前提时，要用到条件测试，通过when语句实现，在tasks中使用，jinja2的语法格式在task后添加when子句即可使用条件测试，when语句支持jinja2表达式语法 使用when语法，如果是redhat系统则执行/sbin/shutdown -h now命令 123name: \"shutdown Redhat system\" command: /sbin/shutdown -h now when: ansible_os_family == \"RedHat\" 1cat template.yml 1234567891011121314151617181920- hosts: all remote_user: root vars: - http_port: 88 tasks: - name: Install nginx server yum: name=nginx - name: copy template for 7 template: src=nginx.conf7.j2 dest=/etc/nginx/nginx.conf when: ansible_distribution_major_version == \"7\" #使用When语法，当系统主版本是7，则拷贝nginx.conf7.j2 notify: restart nginx #当nginx配置文件改变时，执行Handers,此处与Handers名字一致 - name: copy template for 6 template: src=nginx.conf6.j2 dest=/etc/nginx/nginx.conf when: ansible_distribution_major_version == \"6\" #使用When语法，当系统主版本是7，则拷贝nginx.conf7.j2 notify: restart nginx #当nginx配置文件改变时，执行Handers,此处与Handers名字一致 - name: start service service: name=nginx state=started enabled=yes handlers: #定义handlers重启nginx服务 - name: restart nginx service: name=nginx state=restarted 1ansible-playbook template.yml 执行结果如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243PLAY [all] ********************************************************************************************TASK [Gathering Facts] ********************************************************************************ok: [172.17.0.6]ok: [172.17.0.7]ok: [172.17.0.2]ok: [172.17.0.3]TASK [Install nginx server] ***************************************************************************ok: [172.17.0.3]ok: [172.17.0.2]ok: [172.17.0.6]ok: [172.17.0.7]TASK [copy template for 7] ****************************************************************************skipping: [172.17.0.2]skipping: [172.17.0.3]changed: [172.17.0.6]changed: [172.17.0.7]TASK [copy template for 6] ****************************************************************************skipping: [172.17.0.6]skipping: [172.17.0.7]changed: [172.17.0.2]changed: [172.17.0.3]TASK [start service] **********************************************************************************ok: [172.17.0.6]ok: [172.17.0.2]ok: [172.17.0.3]ok: [172.17.0.7]RUNNING HANDLER [restart nginx] ***********************************************************************changed: [172.17.0.3]changed: [172.17.0.6]changed: [172.17.0.7]changed: [172.17.0.2]PLAY RECAP ********************************************************************************************172.17.0.2 : ok=5 changed=2 unreachable=0 failed=0172.17.0.3 : ok=5 changed=2 unreachable=0 failed=0172.17.0.6 : ok=5 changed=2 unreachable=0 failed=0172.17.0.7 : ok=5 changed=2 unreachable=0 failed=0 结果分析：第一个skipping表示拷贝centos7的nginx配置文件,跳过centos6，第二个skipping表示拷贝centos6的nginx配置文件，跳过centos7，此时playbook 已经按要求分发nginx配置文件 迭代：with_items()迭代：当有需要重复执行任务时，可以使用迭代机制对迭代项目的引用，固定变量名为”item”要在task中使用with_items 给定要迭代的元素列表列表格式：字符串、字典 1234567891011121314151617- hosts: all remote_user: root tasks: - name: create some file file: name=/opt/&#123;&#123; item &#125;&#125; state=touch when: ansible_distribution_major_version == \"7\" with_items: - file1 - file2 - file3 - name: install some package yum: name=&#123;&#123;item&#125;&#125; when: ansible_distribution_major_version == \"6\" with_items: - hping3 - htop - sl 上述命令执行后，远程主机上会centos7上会创建文件file1、file2、file3，但不会安装hping3、htop、sl，centos6会安装hping3、htop、sl，但不会创建file1、file2、file3。 迭代嵌套子变量123456789101112131415- hosts: all remote_user: root tasks: - name: create some group group: name=&#123;&#123; item &#125;&#125; with_items: - g1 - g2 - g3 - name: create some user user: name=&#123;&#123; item.name &#125;&#125; group=&#123;&#123; item.group &#125;&#125; with_items: - &#123; name: 'u1', group: 'g1' &#125; - &#123; name: 'u2', group: 'g2' &#125; - &#123; name: 'u3', group: 'g3' &#125; 执行该playbook后，会在远程主机上创建三个组g1、g2、g3、三个用户u1、u2、u3，并且u1在g1中，u2在g2中，u3在g3中 1ansible all -m sehll -a \"id u1;id u2;id u3\" #查看创建情况 Playbook中的template for if重复执行一段代码 创建nginx虚拟主机 123&lt;pre&gt;&lt;code class=\"line-numbers\"&gt;&#123;% for vhost in nginx_vhost %&#125;&#123;% endfor %&#125;","tags":[{"name":"运维基本功","slug":"运维基本功","permalink":"http://www.dookt.com/tags/运维基本功/"}]},{"title":"使用ansible部署ELK+Filebeat+kafka+Zookeeper","date":"2019-07-26T09:35:59.000Z","path":"post/22227.html","text":"系统环境 主机名 IP地址 软件环境 elk01 172.17.0.1 zookeeper,kafka elk02 172.17.0.2 zookeeper,kafka elk03 172.17.0.3 zookeeper,kafka elk04 172.17.0.4 elasticsearch，logstash elk05 172.17.0.5 elasticsearch，logstash elk06 172.17.0.6 elasticsearch，logstash elk07 172.17.0.1 elasticsearch，logstash elk08 172.17.0.8 elasticsearch，logstash elk09 172.17.0.9 elasticsearch，logstash elk010 172.17.0.10 elasticsearch，logstash 修改ansible的hosts文件1234567891011121314# cat /etc/ansible/hosts[kafka]172.17.0.1172.17.0.2172.17.0.3[elkl]172.17.0.4172.17.0.5172.17.0.6172.17.0.7172.17.0.8172.17.0.9172.17.0.10 安装elasticsearch1ansible elk -m yum -a \"name=/opt/package/elasticsearch-6.2.4.rpm\" 修改elasticsearch配置文件：1234567891011121314#cat /etc/elasticsearch/elasticsearch.ymlcluster.name: mintnode.name: mint-node-1path.data: /opt/data/elasticsearchpath.logs: /opt/logs/elasticsearchbootstrap.memory_lock: falsenetwork.host: 172.17.0.2http.port: 9200discovery.zen.ping.unicast.hosts: [\"172.17.0.2\"]mkdir /opt/data/elasticsearchmkdir /opt/logs/elasticsearchchow -R elasticsearch. /opt/&#123;data,logs&#125;/elasticsearchservice elasticsearch restart;tail -f /opt/logs/elasticsearch/test.log 安装kibana(只需要在一台机器上安装就行)12345678rpm -ivh kibana-6.2.4.rpm# cat /etc/kibana/kibana.ymlserver.port: 5601server.host: \"0.0.0.0\"elasticsearch.url: \"http://172.17.0.2:9200\"service restart kibana 安装zookeeper集群12345678910111213tar -xvf zookeeper-3.4.10.tar.gz -C /opt/appmv zookeeper-3.4.10 zookeeper# cat /opt/app/zookeeper/conf/zoo.cfgtickTime=2000initLimit=10syncLimit=5dataDir=/opt/data/zookeeperdataLogDir=/opt/logs/zookeeperclientPort=2181server.1=172.17.0.8:2889:3889server.2=172.17.0.9:2889:3889server.3=172.17.0.10:2889:3889 分别在三台服务器上执行以下命令， 1234echo 1 &gt; /opt/data/zookeeper/myid #在8上执行echo 2&gt; /opt/data/zookeeper/myid #在9上执行 echo 3 &gt; /opt/data/zookeeper/myid #在10上执行/opt/app/zookeeper/bin/zkServer.sh start #启动zookeeper节点 安装kafka集群123456789101112131415161718192021222324tar -xvf kafka_2.11-2.0.1.tgz -C /opt/appmv kafka_2.11-2.0.1 kafka#cat /opt/app/kafka/config/server.propertiesbroker.id=1 #集群ID，集群中每台各不一样,需要修改每个节点,保证不一致hostname=172.17.0.5port=9092num.network.threads=3num.io.threads=8socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=/opt/logs/kafka #kafka日志目录num.partitions=3 #单个broker上partations的个数，高并发可多配置。默认为１num.recovery.threads.per.data.dir=1offsets.topic.replication.factor=1transaction.state.log.replication.factor=1transaction.state.log.min.isr=1log.retention.hours=168 #kafka日志保留时间log.segment.bytes=1073741824log.retention.check.interval.ms=300000zookeeper.connect=172.17.0.8:2181,172.17.0.9:2181,172.17.0.10:2181zookeeper.connection.timeout.ms=6000 #连接zookeeper的超时时间group.initial.rebalance.delay.ms=0 1nohup /opt/app/kafka/bin/kafka-server-start.sh /opt/app/kafka/config/server.properties &gt; /opt/logs/kafka/kafka.log &amp;amp; 安装filebeat123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051rpm -ivh filebeat-6.2.4.rpm#cat /etc/filebeat/filebeat.ymlfilebeat.prospectors:- type: log enabled: true paths: - /opt/logs/*.log #exclude_lines: ['^DBG'] #include_lines: ['^ERR', '^WARN'] #exclude_files: ['.gz$'] fields: appname: test-1 multiline.pattern: '^\\d&#123;4&#125;\\-\\d&#123;2&#125;\\-\\d&#123;2&#125;\\s+\\d&#123;2&#125;' multiline.negate: true multiline.match: after#============================= Filebeat modules ===============================filebeat.config.modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: false #reload.period: 10s#==================== Elasticsearch template setting ==========================setup.template.settings: index.number_of_shards: 3 #index.codec: best_compression #_source.enabled: false#================================ General =====================================#tags: [\"service-X\", \"web-tier\"]# output.#fields:# env: staging#============================== Dashboards =====================================#setup.dashboards.enabled: false#setup.dashboards.url:#============================== Kibana =====================================setup.kibana: # Kibana Host # Scheme and port can be left out and will be set to the default (http and 5601) # In case you specify and additional path, the scheme is required: http://localhost:5601/path # IPv6 addresses should always be defined as: https://[2001:db8::1]:5601 #host: \"localhost:5601\"#================================ Outputs =====================================output.kafka: hosts: [\"172.17.0.5:9092\",\"172.17.0.6:9092\",\"172.17.0.7:9092\"] topic: '%&#123;[fields.appname]&#125;' partition.round_robin: reachable_only: false required_acks: 1 compression: gzip max_message_bytes: 1000000 1service filebeat restart 查看kafka中的topic1/opt/app/kafka/bin/kafka-topics.sh --zookeeper 172.17.0.8:2181,172.17.0.9:2181,172.17.0.10:2181 --list #该命令显示kafka中的topic，即为filebeat中定义的appname的值 安装logstash1234567891011121314151617181920rpm -ivh logstash-6.2.4.rpm#cat /etc/logstash/conf.d/test.confinput&#123; kafka &#123; bootstrap_servers = \"172.17.0.5:9092,172.17.0.6:9092,172.17.0.7:9092,\" topics = \"test-1\" #该值为filebeat配置文件中定义的值，可以通过kafka-topic查看 codec = json consumer_threads = 1 decorate_events = false type = \"tdtp-transport\" &#125;&#125;output &#123; elasticsearch &#123; hosts = [\"172.17.0.2:9200\"] index = \"%&#123;type&#125;-%&#123;+YYYY.MM.dd&#125;\" &#125;&#125; 1service logstash restart","tags":[{"name":"运维基本功","slug":"运维基本功","permalink":"http://www.dookt.com/tags/运维基本功/"}]},{"title":"在deepin15.7系统上配置SS客户端","date":"2019-07-26T09:33:53.000Z","path":"post/7348.html","text":"自搭梯子在deepin15.7系统上如何配置SS 客户端，设置web浏览器呢 在deepin15.7系统上配置SS 客户端安装SS123apt -y updateapt -y install python-pippip install shadowsocks 编辑配置文件12345678910111213#cat /etc/shadowsocks/config.json&#123; \"server\":\"my_server_ip\", \"server_port\":8388, \"local_address\": \"127.0.0.1\", \"local_port\":1080, \"password\":\"my_passwd\", \"timeout\":600, \"method\":\"aes-256-cfb\", \"fast_open\": false, \"workers\": 1, \"prefer_ipv6\": false&#125; 启动ss客户端123sslocal -c /etc/shadowsocks/config.json2018-11-15 23:30:18 INFO loading libcrypto from libcrypto.so.1.1&lt;code&gt;2018-11-15 23:30:18 INFO starting local at 127.0.0.1:1080 当然深度商店已提供shadowsocks-Qt5,直接到深度商店安装即可 配置浏览器代理filefox：设置→首选项→高级→网络→链接→设置→手动配置代理→socks主机：127.0.0.1 端口：1080→确定chrome：关闭已经打开的chrome，用终端命令开启chrome、chromium-browser –proxy-server=socks5://127.0.0.1:1080，进入后便可以下载插件，安装SwitchySharp，然后配置此插件： 情景模式→删除原有的情景模式，新建情景模式（原有的情景模式无socks代理）→手动配置→SOCKS代理：127.0.0.1 端口1080→保存 →ok 问题：关闭代理之后，发现百度访问不了了，纳尼，赶紧逛一下深度论坛，还好论坛已有解决方法，因为现在是全局代理，及时访问百度走的也是proxy-server，所以，需要设置pac模式。可以用pac文件实现自动代理。pac文件可以在github找也可以自己生成，安装genpac就可以自己生成了。 配置系统代理pip安装genpac,并是生成pac文件 12pip install genpacgenpac --pac-compress --pac-proxy 'SOCKS5 127.0.0.1:1080' --format pac -o ~/.autoproxy.pac 配置deepin系统代理，在deepin的 [设置]-[网络]-[系统代理]-[自动] 填入pac文件地址file:///home/mint/.autoproxy.pac 注：配置系统代理之后，需要把浏览器代理设置为系统代理 测试断开ss-clicent,访问百度访问成功了,连接ss-client，访问一下Youtube也通了 大功告成！！！","tags":[{"name":"系统管理","slug":"系统管理","permalink":"http://www.dookt.com/tags/系统管理/"}]},{"title":"DRBD+NFS+Keepalived高可用集群搭建","date":"2019-07-26T09:28:44.000Z","path":"post/32014.html","text":"系统环境VIP：10.3.31.103 服务器 主机名 IP地址 主nfs nfs-master 10.3.31.101 从nfs nfs-slave 10.3.31.102 修改hosts文件1echo -e \"10.3.31.101 nfs01.prod\\n10.3.31.102 nfs02.prod\" &gt;&gt;/etc/hosts 配置drbd安装drdb 1234rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.orgrpm -Uvh https://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpmyum install drbd84 kmod-drbd84 -ysystemctl enable drbd 导入drbd模块内核模块需要大于3.10.0-514.6.1.el7.x86_64，否则会报错，如果报错了，先查看系统上的所有可用内核版本： 123awk -F\\' '$1==\"menuentry \" &#123;print i++ \" : \" $2&#125;' /etc/grub2.cfgyum --enablerepo=elrepo-kernel install kernel-ml #升级内核modprobe drbd 添加新硬盘sdb，并初始化123fdisk /dev/sdb #新建一个分区sdb1mkfs.ext4 /dev/sdb1dd if=/dev/zero of=/dev/sdb1 bs=1M count=100 修改配置文件12345678910111213141516171819202122232425262728# cat /etc/drbd.d/global_common.confglobal &#123; usage-count no;&#125;common &#123; protocol C; disk &#123; on-io-error detach; &#125; syncer &#123; rate 100M; ##设置主备节点同步时的网络速率最大值 &#125;&#125;resource data &#123; on nfs01.prod &#123; #主机名称 device /dev/drbd1; #drbd网络磁盘 disk /dev/sdb1; #本地需要挂载的磁盘 address 10.3.31.101:7899; #主ip地址加drbd端口 meta-disk internal; &#125; on nfs02.prod &#123; device /dev/drbd1; disk /dev/sdb1; address 10.3.31.102:7899; meta-disk internal; &#125;&#125; 启动drbd123drbdadm create-md data #创建数据目录systemctl start drbd #启动drbd服务systemctl enable drbd #开机启动 初始化主节点（只在主节点上操作）12drbdadm primary --force datadrbdsetup /dev/drbd1 primary 在master节点挂载drbd112mkfs.ext4 /dev/drbd1mount /dev/drbd1 /opt/ 测试drbd是否可用在master(10.3.31.101)的opt中创建一个文件，然后卸载/opt，将当前主节点降级为次 123mkdir /opt/testumount /optdrbdadm secondary data 将secondary(10.3.31.102)节点升级为主节点，然后挂载/opt，可用看到在10.2.31.51上创建的文件test存在，说明drbd起作用了 12drbdadm primary datamount /dev/drbd1 /opt/ 配置nfs服务端，两个节点都要执行123yum -y install rpcbind nfs-utilsmkdir -p /opt/logs/upload /opt/data/pfxfiles /opt/uploadecho -e \"/opt/logs/itsp-uploadlog 10.3.31.0/24(rw,no_root_squash,sync)\\n/opt/upload 10.3.31.0/24(rw,no_root_squash,sync)\\n/opt/data/pfxfiles 10.3.31.0/24(rw,no_root_squash,sync)\" &amp;gt;&amp;gt; /etc/exports 安装配置keepalived安装keepalived 123yum -y install keepalivedsystemctl enable keepalivedmkdir /et/keepalived/logs #创建日志目录 配置主drbd节点（10.3.31.101）12345678910111213141516171819202122232425262728# cat /etc/keepalived/keepalived.conf! Configuration File for keepadlivedglobal_defs &#123; router_id LVS_DEVEL&#125;vrrp_script chk_nfs &#123; script \"/etc/keepalived/check_nfs.sh\" interval 5&#125;vrrp_instance VI_1 &#123; state BACKUP interface eth0 virtual_router_id 151 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111&#125;track_script &#123; chk_nfs&#125;notify_stop /etc/keepalived/notify_stop.shnotify_master /etc/keepalived/notify_master.shvirtual_ipaddress &#123; 10.3.31.103/24 &#125;&#125; 配置备drbd节点（10.3.31.102）12345678910111213141516171819202122232425262728# cat /etc/keepalived/keepalived.conf! Configuration File for keepadlivedglobal_defs &#123; router_id LVS_DEVEL&#125;vrrp_script chk_nfs &#123; script \"/etc/keepalived/check_nfs.sh\" interval 5&#125;vrrp_instance VI_1 &#123; state BACKUP interface eth0 virtual_router_id 151 priority 90 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111&#125;track_script &#123; chk_nfs&#125;notify_master /etc/keepalived/notify_master.shnotify_backup /etc/keepalived/notify_backup.shvirtual_ipaddress &#123; 10.3.31.103/24 &#125;&#125; 配置文件中用到的脚本123456789101112131415161718# cat /etc/keepalived/check_nfs.sh #给脚本主备服务都需要有#!/bin/sh###检查nfs可用性：进程和是否能够挂载/sbin/service nfs status &amp;amp;&amp;gt;/dev/nullif [ $? -ne 0 ];then ###如果服务状态不正常，先尝试重启服务 systemctl restart nfs systemctl status nfs &amp;amp;&amp;gt;/dev/null if [ $? -ne 0 ];then ###若重启nfs服务后，仍不正常 ###卸载drbd设备 umount /dev/drbd1 ###将drbd主降级为备 drbdadm secondary data #关闭keepalived /sbin/service keepalived stop fifi 12345678# cat /etc/keepalived/notify_master.sh #主备服务器都有，用于设置主drdb#!/bin/bashtime=`date \"+%F %H:%M:%S\"`echo -e \"$time ------notify_master------\\n\" /etc/keepalived/logs/notify_master.log/sbin/drbdadm primary data; /etc/keepalived/logs/notify_master.log/bin/mount /dev/drbd1 /opt; /etc/keepalived/logs/notify_master.log/sbin/service nfs restart; /etc/keepalived/logs/notify_master.logecho -e \"\\n\" /etc/keepalived/logs/notify_master.log 12345678# cat /etc/keepalived/notify_stop.sh #只在主服务器上,用于停止主nfs#!/bin/bashtime=`date \"+%F %H:%M:%S\"`echo -e \"$time ------notify_stop------\\n\"; /etc/keepalived/logs/notify_stop.log/sbin/service nfs stop; /etc/keepalived/logs/notify_stop.log/bin/umount /opt; /etc/keepalived/logs/notify_stop.log/sbin/drbdadm secondary data; /etc/keepalived/logs/notify_stop.logecho -e \"\\n\"; /etc/keepalived/logs/notify_stop.log 1234567891011# cat /etc/keepalived/notify_backup.sh #用于设置主服务为备drbd#!/bin/bashtime=`date \"+%F %H:%M:%S\"`echo -e \"$time ------notify_backup------\\n\" /etc/keepalived/logs/notify_backup.log/sbin/service nfs stop/etc/keepalived/logs/notify_backup.log/bin/umount /dev/drbd1/etc/keepalived/logs/notify_backup.log/sbin/drbdadm secondary data/etc/keepalived/logs/notify_backup.logecho -e \"\\n\" /etc/keepalived/logs/notify_backup.log 自动切换测试关闭主上keepalived，会按照预期流程走。关闭主上nfs—-卸载资源设备—-主drbd降级—-备drdb升级—-备挂载资源设备—-备启动nfs服务。 连续写测试，在客户端创建挂载点，然后挂载nfs,最后写入文件测试 123mkdir testmount -t nfs 10.3.31.103:/opt/upload testfor i in &#123;1..500&#125;;do dd if=/dev/zero of=test/$i.file bs=1M count=1;done 执行循环的过程中在master上关闭keepalived，验证写入过程是否会中断，经验证(不能进入master的opt目录，否则master不能卸载opt)，写入过程没有中断，但中间会有一段时间的延时，在开启原主keepalived，写入过程也没有中断，同样中间有一段时间的延时,将测试文件删除，并卸载 12rm -fr test/*umount test 正式挂载nfs，客户端需要安装rpcbind服务12345ansible nfs -m yum -a 'name=rpcbind,nfs-utils state=present'ansible nfs -m service -a 'name=rpcbind state=restarted enabled=yes'ansible nfs -m file -a 'path=/opt/data state=directory'ansible nfs -m shell -a 'echo -e \"10.3.31.103:/opt/data/\\t /opt/upload\\t\\t\\tnfs\\trw\\t0 0\" /etc/fstab'ansible nfs -m shell -a 'mount -a;mount'","tags":[{"name":"高可用","slug":"高可用","permalink":"http://www.dookt.com/tags/高可用/"}]},{"title":"Centos6.5搭建sftp服务器","date":"2019-07-26T09:26:40.000Z","path":"post/40005.html","text":"SFTP，即 SSH 文件传输协议（ SSH File Transfer Protocol ），或者说是安全文件传输协议（ Secure File Transfer Protocol ）。SFTP 是一个独立的 SSH 封装协议包，通过安全连接以相似的方式工作。它的优势在于可以利用安全的连接传输文件，还能浏览本地和远程系统上的文件系统。在很多情况下，使用SFTP都比FTP更可取，因为它具有最基本的安全特性和能利用 SSH 连接的能力，FTP是一种不安全的协议，只能在有限的情况下或在您信任的网络上使用。服务器 OpenSSH-Server 版本最低4.8p1，因为低版本不支持新配置项 ChrootDirectory ，而此处需要ChrootDirectory来配置权限当然配置时请关闭防火墙和selinux ####系统环境 主机名 服务器 sftp 172.17.0.2 #####安装软件 1yum -y install openssl openssh-server openssh-clients #####配置用户组 12345# groupadd sftp# useradd -g sftp -s /sbin/nologin mysftp# echo mypass | passwd --stdin mysftp# mkdir -p /data/sftp/mysftp# usermod -d /data/sftp/mysftp mysftp #####配置sshd服务，编辑 /etc/ssh/sshd_config 注释此行,在此行下面添加如下内容： 1234567#Subsystem sftp /usr/libexec/openssh/sftp-serverSubsystem sftp internal-sftp # 指定使用sftp服务使用系统自带的internal-sftpMatch Group sftp # 匹配sftp组的用户,若要匹配多个组,可用逗号分开ChrootDirectory /data/sftp/ # 限制用户的根目录ForceCommand internal-sftp # 只能用于sftp登录AllowTcpForwarding no # 禁止用户使用端口转发X11Forwarding no # 禁止用户使用端口转发 #####设定Chroot目录权限及sftp用户登陆后可写入的目录 12345# chown root.sftp /data/sftp/mysftp #文件夹所有者必须是root，用户组可以不是root。# chmod 755 /data/sftp/mysftp #权限不能超过755但不包括755，否则会导致登录报错。# mkdir /data/sftp/mysftp/upload #创建用户上传目录# chown mysftp.sftp /data/sftp/mysftp/upload# chmod 755 /data/sftp/mysftp/upload #####测试sftp服务器能否登录、上传、下载测试登录,若测试结果如下，则sftp服务正常登录 1234sftp -p22 mysftp@172.17.0.2 m1ysftp@172.17.0.2's password: Connected to mysftp@172.17.0.2. sftp&gt; 若出现以下情况： 123sftp -p22 mysftp@172.17.0.2 packet_write_wait: Connection to 172.17.0.2 port 22: Broken pipe Couldn't read packet: Connection reset by peer 出现以上情况的原因是：/data/sftp/mysftp 目录权限分配不当所致，将此目录的所有者更改为root即可，用户组可为root/sftp。 测试上传，登录服务器 123sftp&gt; put vars.yml Uploading vars.yml to /upload/vars.yml vars.yml 测试下载,登录服务器 123sftp&gt; get vars.yml /tmp Fetching /upload/vars.yml to /tmp/vars.yml /upload/vars.yml 测试删除,登录服务器 12sftp&gt; rm vars.yml Removing /upload/vars.yml #####小技巧登录sftp服务器后，可以使用部分shell命令，在shell命令前添加l，可以对本地主机操作。例如ls、lls、pwd、lpwd、cd、lcd等命令","tags":[{"name":"FTP","slug":"FTP","permalink":"http://www.dookt.com/tags/FTP/"}]},{"title":"Centos7.2安装部署KVM虚拟化","date":"2019-07-26T09:25:23.000Z","path":"post/12121.html","text":"Centos7.2安装部署KVM虚拟化检查服务器是否支持虚拟化1cat /proc/cpuinfo | egrep --color \"vmx|smv\" 关闭防火墙和selinux1234systemctl stop firwalldsystemctl disable firwalldsed -i '/SELINUX/s/enforcing/disabled/g' /etc/selinux/configsetenforce 0 #####安装KVM及其虚拟化安装包 1yum -y install qemu-kvm qemu-img virt-manager libvirt libvirt-python python-virtinst libvirt-client virt-install virt-viewer #####配置桥接网络 创建 ifcfg-br0 文件，内容如下：NM_CONTROLLED=no(不实时生效) 123456789# cat ifcfg-br0BOOTPROTO=staticDEVICE=br0TYPE=BridgeNM_CONTROLLED=noIPADDR=192.168.1.95NETMASK=255.255.255.0GATEWAY=192.168.1.1DNS1=114.114.114.114 修改ifcfg-em1文件，内容如下： 123456# cat ifcfg-em1BOOTPROTO=noneDEVICE=em1NM_CONTROLLED=noONBOOT=yesBRIDGE=br0 重启网络服务 1systemctl restart network #####KVM安装虚拟机 创建存储池 12mkdir /kvm/&#123;store,iso&#125; -pvvirt-install -n test-nginx.pord -r 4096 --disk=/kvm/store/nginx.prod.img --network bridge=br0 --os-type=linux --os-variant=el7 --cdrom /kvm/iso/Centos-7-x86_64-DVD-1511.iso --vnc --vncport=5910 --vncclisten=0.0.0.0","tags":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://www.dookt.com/tags/虚拟化/"}]},{"title":"Centos7.2网卡bond","date":"2019-07-26T09:24:01.000Z","path":"post/26042.html","text":"网卡bond是通过多张网卡绑定成一个逻辑网卡实现本地网卡的冗余，带宽扩容和负载平衡，一共有7种模式 Centos7.2网卡bond什么是bond网卡bond是通过多张网卡绑定成一个逻辑网卡，实现本地网卡的冗余，带宽扩容和负载平衡 常用的bond模式mode=0:(balance-rr)负载分担round-robin，轮询方式有高可用 (容错) 和负载均衡的功能, 需要交换机的配置，每块网卡轮询发包 (流量分发比较均衡)。优点：流量提高一倍；缺点：需要接入交换机做端口聚合，否则可能无法使用。mode=1:(active-backup)主备模式，只有高可用 (容错) 功能, 不需要交换机配置, 这种模式只有一块网卡工作, 对外只有一个mac地址。优点：冗余性高；缺点：链路利用率低，两块网卡只有1块在工作。缺点是端口利用率比较低 网卡绑定通过网口bond，可以实现网口冗余，负载均衡，从而达到高可用。物理网卡eno16777736，eno33554960,绑定后的虚拟网口是bond0，服务器IP：172.16.1.199 修改网卡配置文件1234567# cat /etc/sysconfig/network-scripts/ifcfg-eno16777736 TYPE=EthernetBOOTPROTO=noneDEVICE=eno16777736NAME=eno16777736MASTER=bond0SLAVE=yes 1234567# cat /etc/sysconfig/network-scripts/ifcfg-eno33554960 TYPE=EthernetBOOTPROTO=noneDEVICE=eno33554960NAME=eno33554960MASTER=bond0SLAVE=yes 12345678# cat /etc/sysconfig/network-scripts/ifcfg-bond0 TYPE=EthernetBOOTPROTO=noneDEVICE=bond0ONBOOT=yesIPADDR=172.16.1.199NETMASK=255.255.255.0GATEWAY=172.16.1.250 修改并加载模块1.创建bonding模块文件为/etc/modprobe.d/bond.conf 123# cat /etc/modprobe.d/bond.confalias bond0 bondingoptions bond0 mode=1 miimon=200 1234modprobe bonding #加载bonding模块，可直接重启lsmod|grep bonding #查看bonding模块是否加载成功systemctl restart network #重启网络cat /proc/net/bonding/bond0 #查看bond信息 #####查看bond状态 123456789101112131415161718192021222324cat /proc/net/bonding/bond0 Ethernet Channel Bonding Driver: v3.7.1 (April 27, 2011)Bonding Mode: load balancing (round-robin)MII Status: upMII Polling Interval (ms): 0Up Delay (ms): 0Down Delay (ms): 0Slave Interface: eno16777736MII Status: upSpeed: 1000 MbpsDuplex: fullLink Failure Count: 0Permanent HW addr: 00:0c:29:55:9d:bfSlave queue ID: 0Slave Interface: eno33554960MII Status: upSpeed: 1000 MbpsDuplex: fullLink Failure Count: 0Permanent HW addr: 00:0c:29:55:9d:c9Slave queue ID: 0 1ifconfig 可以看出：bond模式为：round-robin激活的网口为：eno33554960eno16777736，eno33554960,bond0三个网卡的物理地址相同，为了避免上层交换机发生混乱 测试在本地主机执行ping 172.16.1.199 -t来检查网络连通性，然后突然在虚拟机硬件配置中随机移除一块网卡设备，能够非常清晰的看到网卡切换的过程（最多有1个数据丢包）。若是在虚拟机环境下测试，秩序断开其中一块网卡 12345678910111213141516171819# ping 172.16.1.199 -t正在 Ping 172.16.1.199 具有 32 字节的数据:来自 172.16.1.199 的回复: 字节=32 时间&amp;lt;1ms TTL=64来自 172.16.1.199 的回复: 字节=32 时间&amp;lt;1ms TTL=64来自 172.16.1.199 的回复: 字节=32 时间&amp;lt;1ms TTL=64来自 172.16.1.199 的回复: 字节=32 时间=1ms TTL=64来自 172.16.1.199 的回复: 字节=32 时间=1ms TTL=64来自 172.16.1.199 的回复: 字节=32 时间&amp;lt;1ms TTL=64来自 172.16.1.199 的回复: 字节=32 时间&amp;lt;1ms TTL=64来自 172.16.1.199 的回复: 字节=32 时间&amp;lt;1ms TTL=64来自 172.16.1.199 的回复: 字节=32 时间&amp;lt;1ms TTL=64来自 172.16.1.199 的回复: 字节=32 时间&amp;lt;1ms TTL=64来自 172.16.1.199 的回复: 字节=32 时间&amp;lt;1ms TTL=64请求超时。来自 172.16.1.199 的回复: 字节=32 时间=1ms TTL=64来自 172.16.1.199 的回复: 字节=32 时间=1ms TTL=64来自 172.16.1.199 的回复: 字节=32 时间=1ms TTL=64来自 172.16.1.199 的回复: 字节=32 时间&amp;lt;1ms TTL=64来自 172.16.1.199 的回复: 字节=32 时间&amp;lt;1ms TTL=64 修改bond模式1234modprobe -r bonding #卸载bonding内核模块lsmod | grep bonding #查看bonding模块sed 's/mode=6/mode=1/g' /etc/modprobe.d/bond.conf #修改bond模式modprobe bonding #重新加载bonding模块 遇到的问题在虚拟机上配置mode=0，ping其他机器会出现 123456789101112131415161718# ping 172.16.1.159PING 172.16.1.159 (172.16.1.159) 56(84) bytes of data.64 bytes from 172.16.1.159: icmp_seq=1 ttl=64 time=0.335 ms64 bytes from 172.16.1.159: icmp_seq=1 ttl=64 time=0.353 ms (DUP!)64 bytes from 172.16.1.159: icmp_seq=2 ttl=64 time=0.399 ms64 bytes from 172.16.1.159: icmp_seq=2 ttl=64 time=0.413 ms (DUP!)64 bytes from 172.16.1.159: icmp_seq=3 ttl=64 time=0.905 ms64 bytes from 172.16.1.159: icmp_seq=3 ttl=64 time=0.931 ms (DUP!)64 bytes from 172.16.1.159: icmp_seq=4 ttl=64 time=1.21 ms64 bytes from 172.16.1.159: icmp_seq=4 ttl=64 time=1.27 ms (DUP!)64 bytes from 172.16.1.159: icmp_seq=5 ttl=64 time=1.48 ms64 bytes from 172.16.1.159: icmp_seq=5 ttl=64 time=1.54 ms (DUP!)64 bytes from 172.16.1.159: icmp_seq=6 ttl=64 time=1.19 ms64 bytes from 172.16.1.159: icmp_seq=6 ttl=64 time=1.24 ms (DUP!)64 bytes from 172.16.1.159: icmp_seq=7 ttl=64 time=1.14 ms64 bytes from 172.16.1.159: icmp_seq=7 ttl=64 time=1.18 ms (DUP!)64 bytes from 172.16.1.159: icmp_seq=8 ttl=64 time=1.42 ms64 bytes from 172.16.1.159: icmp_seq=8 ttl=64 time=1.46 ms (DUP!) 网上搜到的答案是： 应该是重复DUPLICATE，同一个序号的ICMP包却收到了多个回应。一般在PING网段广播地址才会出现这种情况。 改成mode1未出现以上情况个人猜想： 相当于交换机未做端口聚合","tags":[{"name":"系统管理","slug":"系统管理","permalink":"http://www.dookt.com/tags/系统管理/"}]},{"title":"Linux网路命令的妙用","date":"2019-07-26T09:01:43.000Z","path":"post/26598.html","text":"ping命令ping -i:快速测试1000个网络包一般用于主机测试，网络设备可能会丢包 快速10秒测试1000个icmp包 1# ping 111.230.96.65 -i 0.001 -w 10 -c 1000 ping -f：肉眼查看丢包状态是否增多如果不通则点数增多，常常用于切换网络时。 网络不丢包 123# ping 172.16.1.145 -fPING 172.16.1.145 (172.16.1.145) 56(84) bytes of data.. 网络不通 123# ping 172.16.1.15 -fPING 172.16.1.15 (172.16.1.15) 56(84) bytes of data............E............E..........E.... nmap命令nmap 主机该命令可以确定目标主机的在线情况和端口监听状态,如下： 12345678910111213141516# nmap 172.16.1.159Starting Nmap 6.40 ( http://nmap.org ) at 2019-01-10 05:47 CSTNmap scan report for 172.16.1.159Host is up (0.0016s latency).Not shown: 994 closed portsPORT STATE SERVICE22/tcp open ssh80/tcp open http111/tcp open rpcbind3306/tcp open mysql8009/tcp open ajp138080/tcp open http-proxyMAC Address: 00:0C:29:EA:75:0E (VMware)Nmap done: 1 IP address (1 host up) scanned in 0.50 seconds nmap -T4 -A -v 主机-A：用于开启全面扫描，-T4指定扫描过程中使用的时序模板（6个级别：0-5），等级越高，扫描速度越快，但越容易被防火墙或入侵检测设备发现并屏蔽，这里推荐使用”-T4”，-v用于显示详细扫描细节。如下是对主机172.16.1.159进行全面的扫描过程。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081# nmap -T4 -A 172.16.1.159Starting Nmap 6.40 ( http://nmap.org ) at 2019-01-10 05:51 CSTNmap scan report for 172.16.1.159Host is up (0.0010s latency).Not shown: 994 closed portsPORT STATE SERVICE VERSION22/tcp open ssh OpenSSH 6.6.1 (protocol 2.0)| ssh-hostkey: 2048 af:d8:46:f2:18:0b:b2:7e:cf:98:62:b9:c6:3f:52:f8 (RSA)|_256 6b:06:5c:c9:44:82:bc:d5:6d:a5:23:84:de:c1:76:4b (ECDSA)80/tcp open http nginx 1.12.2|_http-methods: No Allow or Public header in OPTIONS response (status code 405)|_http-title: Test Page for the Nginx HTTP Server on Fedora111/tcp open rpcbind 2-4 (RPC #100000)| rpcinfo: | program version port/proto service| 100000 2,3,4 111/tcp rpcbind|_ 100000 2,3,4 111/udp rpcbind3306/tcp open mysql?| mysql-info: MySQL Error detected!| Error Code was: 1130|_Host &apos;172.16.1.145&apos; is not allowed to connect to this MariaDB server8009/tcp open ajp13 Apache Jserv (Protocol v1.3)|_ajp-methods: Failed to get a valid response for the OPTION request8080/tcp open http Apache Tomcat/Coyote JSP engine 1.1|_http-methods: No Allow or Public header in OPTIONS response (status code 404)|_http-title: Site doesn&apos;t have a title.1 service unrecognized despite returning data. If you know the service/version, please submit the following fingerprint at http://www.insecure.org/cgi-bin/servicefp-submit.cgi :SF-Port3306-TCP:V=6.40%I=7%D=1/10%Time=5C366CD1%P=x86_64-redhat-linux-gnu%SF:r(NULL,4B,&quot;G\\0\\0\\0\\xffj\\x04Host\\x20&apos;172\\.16\\.1\\.145&apos;\\x20is\\x20not\\x20alSF:lowed\\x20to\\x20connect\\x20to\\x20this\\x20MariaDB\\x20server&quot;)%r(GenericLiSF:nes,4B,&quot;G\\0\\0\\0\\xffj\\x04Host\\x20&apos;172\\.16\\.1\\.145&apos;\\x20is\\x20not\\x20allowSF:ed\\x20to\\x20connect\\x20to\\x20this\\x20MariaDB\\x20server&quot;)%r(GetRequest,4SF:B,&quot;G\\0\\0\\0\\xffj\\x04Host\\x20&apos;172\\.16\\.1\\.145&apos;\\x20is\\x20not\\x20allowed\\x2SF:0to\\x20connect\\x20to\\x20this\\x20MariaDB\\x20server&quot;)%r(HTTPOptions,4B,&quot;GSF:\\0\\0\\0\\xffj\\x04Host\\x20&apos;172\\.16\\.1\\.145&apos;\\x20is\\x20not\\x20allowed\\x20to\\SF:x20connect\\x20to\\x20this\\x20MariaDB\\x20server&quot;)%r(RTSPRequest,4B,&quot;G\\0\\0SF:\\0\\xffj\\x04Host\\x20&apos;172\\.16\\.1\\.145&apos;\\x20is\\x20not\\x20allowed\\x20to\\x20cSF:onnect\\x20to\\x20this\\x20MariaDB\\x20server&quot;)%r(RPCCheck,4B,&quot;G\\0\\0\\0\\xffjSF:\\x04Host\\x20&apos;172\\.16\\.1\\.145&apos;\\x20is\\x20not\\x20allowed\\x20to\\x20connect\\SF:x20to\\x20this\\x20MariaDB\\x20server&quot;)%r(DNSVersionBindReq,4B,&quot;G\\0\\0\\0\\xfSF:fj\\x04Host\\x20&apos;172\\.16\\.1\\.145&apos;\\x20is\\x20not\\x20allowed\\x20to\\x20connecSF:t\\x20to\\x20this\\x20MariaDB\\x20server&quot;)%r(DNSStatusRequest,4B,&quot;G\\0\\0\\0\\xSF:ffj\\x04Host\\x20&apos;172\\.16\\.1\\.145&apos;\\x20is\\x20not\\x20allowed\\x20to\\x20conneSF:ct\\x20to\\x20this\\x20MariaDB\\x20server&quot;)%r(Help,4B,&quot;G\\0\\0\\0\\xffj\\x04HostSF:\\x20&apos;172\\.16\\.1\\.145&apos;\\x20is\\x20not\\x20allowed\\x20to\\x20connect\\x20to\\x2SF:0this\\x20MariaDB\\x20server&quot;)%r(SSLSessionReq,4B,&quot;G\\0\\0\\0\\xffj\\x04Host\\xSF:20&apos;172\\.16\\.1\\.145&apos;\\x20is\\x20not\\x20allowed\\x20to\\x20connect\\x20to\\x20tSF:his\\x20MariaDB\\x20server&quot;)%r(Kerberos,4B,&quot;G\\0\\0\\0\\xffj\\x04Host\\x20&apos;172\\SF:.16\\.1\\.145&apos;\\x20is\\x20not\\x20allowed\\x20to\\x20connect\\x20to\\x20this\\x20SF:MariaDB\\x20server&quot;)%r(SMBProgNeg,4B,&quot;G\\0\\0\\0\\xffj\\x04Host\\x20&apos;172\\.16\\.SF:1\\.145&apos;\\x20is\\x20not\\x20allowed\\x20to\\x20connect\\x20to\\x20this\\x20MariaSF:DB\\x20server&quot;)%r(X11Probe,4B,&quot;G\\0\\0\\0\\xffj\\x04Host\\x20&apos;172\\.16\\.1\\.145&apos;SF:\\x20is\\x20not\\x20allowed\\x20to\\x20connect\\x20to\\x20this\\x20MariaDB\\x20sSF:erver&quot;)%r(FourOhFourRequest,4B,&quot;G\\0\\0\\0\\xffj\\x04Host\\x20&apos;172\\.16\\.1\\.14SF:5&apos;\\x20is\\x20not\\x20allowed\\x20to\\x20connect\\x20to\\x20this\\x20MariaDB\\x2SF:0server&quot;)%r(LPDString,4B,&quot;G\\0\\0\\0\\xffj\\x04Host\\x20&apos;172\\.16\\.1\\.145&apos;\\x20SF:is\\x20not\\x20allowed\\x20to\\x20connect\\x20to\\x20this\\x20MariaDB\\x20serveSF:r&quot;);MAC Address: 00:0C:29:EA:75:0E (VMware)No exact OS matches for host (If you know what OS is running on it, see http://nmap.org/submit/ ).TCP/IP fingerprint:OS:SCAN(V=6.40%E=4%D=1/10%OT=22%CT=1%CU=40132%PV=Y%DS=1%DC=D%G=Y%M=000C29%TOS:M=5C366CE4%P=x86_64-redhat-linux-gnu)SEQ(SP=FF%GCD=1%ISR=10D%TI=Z%CI=I%IOS:I=I%TS=A)OPS(O1=M5B4ST11NW7%O2=M5B4ST11NW7%O3=M5B4NNT11NW7%O4=M5B4ST11NWOS:7%O5=M5B4ST11NW7%O6=M5B4ST11)WIN(W1=7120%W2=7120%W3=7120%W4=7120%W5=7120OS:%W6=7120)ECN(R=Y%DF=Y%T=40%W=7210%O=M5B4NNSNW7%CC=Y%Q=)T1(R=Y%DF=Y%T=40%OS:S=O%A=S+%F=AS%RD=0%Q=)T2(R=N)T3(R=N)T4(R=Y%DF=Y%T=40%W=0%S=A%A=Z%F=R%O=%OS:RD=0%Q=)T5(R=Y%DF=Y%T=40%W=0%S=Z%A=S+%F=AR%O=%RD=0%Q=)T6(R=Y%DF=Y%T=40%WOS:=0%S=A%A=Z%F=R%O=%RD=0%Q=)T7(R=Y%DF=Y%T=40%W=0%S=Z%A=S+%F=AR%O=%RD=0%Q=)OS:U1(R=Y%DF=N%T=40%IPL=164%UN=0%RIPL=G%RID=G%RIPCK=G%RUCK=G%RUD=G)IE(R=Y%DOS:FI=N%T=40%CD=S)Network Distance: 1 hopTRACEROUTEHOP RTT ADDRESS1 1.04 ms 172.16.1.159OS and Service detection performed. Please report any incorrect results at http://nmap.org/submit/ .Nmap done: 1 IP address (1 host up) scanned in 19.54 seconds 第一部分完成主机是否在线扫描第二部分完成端口扫描，nmap默认扫描1000个最可能开放的端口，由于只识别到22,80,111,3306,8009,8080端口处于打开状态，所以在输出中会有”Not shown: 994 closed ports”的描述，第三部分是对端口上运行的应用程序以及版本号进行统计第四部分显示操作类型和版本最后一部分显示目标主机的路由跟踪信息 mtr命令使用mtr会持续发包，并显示每一跳ping所用的时间。也会显示过程中的任何问题，在下面的示例中，可以看到在第8、9跳分别丢了超过20%、40%的包。 12345678910111213141516171819202122# mtr dookt.comMy traceroute [v0.85]localhost.localdomain (0.0.0.0) Thu Jan 10 07:33:51 2019Keys: Help Display mode Restart statistics Order of fields quit Packets Pings Host Loss% Snt Last Avg Best Wrst StDev 1. 172.16.1.250 0.0% 57 0.5 0.6 0.5 0.9 0.0 2. 192.168.8.1 0.0% 57 2.7 9.2 2.4 99.9 14.2 3. ??? 4. 192.168.20.29 0.0% 57 65.7 90.0 65.7 153.8 18.2 5. 10.242.131.161 0.0% 57 86.0 125.2 62.9 339.1 57.4 6. ??? 7. 218.204.251.17 0.0% 57 98.6 88.2 65.2 148.2 17.9 8. 221.179.15.85 28.6% 57 84.4 103.4 73.3 168.9 21.1 9. 211.136.242.38 43.6% 56 124.9 105.5 76.6 140.9 17.210. 120.241.50.2 0.0% 56 97.4 104.7 77.0 180.6 21.111. 10.196.2.98 0.0% 56 104.9 115.3 80.7 222.7 27.012. 182.254.127.61 0.0% 56 105.9 101.3 79.0 175.2 16.613. ???14. ???15. 111.230.96.65 0.0% 56 124.5 101.1 78.8 166.4 18.1 nc命令在远程主机（172.16.1.159）上开启2398端口监听 1# nc -l 2398 在终端输入一下内容 12# nc 172.16.1.159 &quot;你要说的话&quot; 此时在与远程主机上可以看到刚刚输入的内容","tags":[{"name":"系统命令","slug":"系统命令","permalink":"http://www.dookt.com/tags/系统命令/"}]},{"title":"如何重载haproxy配置文件","date":"2019-07-26T08:58:12.000Z","path":"post/55978.html","text":"怎么在不重新启动haproxy是时候重载haprxoy的配置呢，通过查看进程PID，使用-sf选项即可是实现 ####重载haprxoy的配置 1haproxy -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -sf $(cat /run/haproxy.pid)","tags":[{"name":"运维基本功","slug":"运维基本功","permalink":"http://www.dookt.com/tags/运维基本功/"}]},{"title":"开机rc.local不生效","date":"2019-07-26T08:56:34.000Z","path":"post/58392.html","text":"添加了开机启动任务cron，但是未能成功执行，需要注意一下几点 /etc/rc.local不生效可能的原因 启动脚本中未找到正确的可执行路径，可以使用绝对路径 /etc/rc.local和/etc/rc.d/rc.local没有执行权限 /etc/rc.local是文件，不是链接 #####注：/etc/rc.local是/etc/rc.d/rc.local的软链接，可以直接在该文件中添加启动脚本","tags":[{"name":"系统管理","slug":"系统管理","permalink":"http://www.dookt.com/tags/系统管理/"}]},{"title":"FTP被动模式安装部署","date":"2019-07-26T08:53:04.000Z","path":"post/41762.html","text":"由于生产环境两端都有防火墙，故vsftp需要使用被动模式。 系统环境服务器IP地址：111.230.96.65 安装vsftpd1yum -y install vsftpd 配置vsFTP12345678910111213141516171819202122local_enable=YESwrite_enable=YESlocal_umask=000dirmessage_enable=YESxferlog_enable=YESconnect_from_port_20=YESxferlog_file=/var/log/xferlogxferlog_std_format=YESchroot_local_user=YESchroot_list_enable=YESchroot_list_file=/etc/vsftpd/chroot_listls_recurse_enable=YESlisten=YESlisten_port=6021pasv_enable=YESpasv_min_port=30000pasv_max_port=30001pasv_address=144.120.64.191 #公网IPpasv_promiscuous=YESpam_service_name=vsftpduserlist_enable=YEStcp_wrappers=YES 创建ftp用户并设置目录123mkdir -pv /opt/datauseradd -d /opt/data/ftp -s /sbin/nologin testftpecho testftp | passwd --stdin testftp 遇到的问题 可以登录ftp服务器，却查看不了卡在227 Entering Passive Mode (10,8,181,11,117,48)。后面就报超时，原因很简单。服务器告诉我们,可以去连接10.8.181.11的117*256+48=30000端口以便传输数据,可是2个都不是局域网，肯定无法访问10.8.181.11的30000端口的。故需要开通防火墙上30000及300001及端口的访问权限 可查看连接地址：http://www.voidcn.com/article/p-vhyoixyg-boa.html","tags":[{"name":"FTP","slug":"FTP","permalink":"http://www.dookt.com/tags/FTP/"}]},{"title":"Nginx使用stream模块转发ssh请求","date":"2019-07-26T08:51:40.000Z","path":"post/10505.html","text":"服务器环境nginx服务器IP：192.168.99.113ssh服务器IP：192.168.99.9，端口2222 配置文件如下1234567891011stream &#123; upstream jumpserver2222 &#123; server 192.168.99.9:2222 max_fails=3 fail_timeout=30s; &#125; server &#123; listen 8089; proxy_pass jumpserver2222; proxy_connect_timeout 1h; proxy_timeout 1h; &#125;&#125; 注意事项 stream模块写入配置文件位置与就跟http模块一样，写在最外层 server里面不要使用location / 这种语句，否则报错","tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://www.dookt.com/tags/Nginx/"}]},{"title":"磁盘分区挂载parted及LVM操作","date":"2019-07-26T08:49:22.000Z","path":"post/30018.html","text":"LVM介绍它是Linux环境下对磁盘分区进行管理的一种机制，LVM是建立在硬盘和分区之上的一个逻辑层，来提高磁盘分区管理的灵活性。通过LVM系统管理员可以轻松管理磁盘分区，如：将若干个磁盘分区连接为一个整块的卷组（volume group），形成一个存储池。管理员可以在卷组上随意创建逻辑卷组（logical volumes），并进一步在逻辑卷组上创建文件系统。管理员通过LVM可以方便的调整存储卷组的大小，并且可以对磁盘存储按照组的方式进行命名、管理和分配。当系统添加了新的磁盘，通过LVM管理员就不必将磁盘的文件移动到新的磁盘上以充分利用新的存储空间，而是直接扩展文件系统跨越磁盘即可。 新磁盘设置为LVM123456789101112创建分区：fdisk /dev/sdb ----&gt; /dev/sdb1创建pv：pvcreate /dev/sdb1查看pv：pvdispaly创建vg：vgcreate vg01 /dev/sdb1查看vg：vgdisplay创建LV：lvcreate -L 19G -n lvdata vg01查看lv：lvdisplay格式化为xfs：mkfs.xfs /dev/vg01/lvdata挂载：mount /dev/vg01/lvdata /opt/查看blkid：blkid /dev/vg01/lvdata /dev/vg01/lvdata: UUID=\"dd0cc062-eaff-4e75-a4fe-ea8d7c5de66c\" TYPE=\"xfs\" 开机挂载：把UUID文件xf按格式写入/etc/fatab文件 使用LVM逻辑卷技术挂载新硬盘到LVM分区12345678创建分区：fdisk /dev/sdb ----&gt; /dev/sdb1创建pv：pvcreate /dev/sdb1查看卷组：vgdisplay --&gt; VG Name: centos扩展卷组：vgextend /dev/centos /dev/sdb1在查看卷组大小已经修改扩展逻辑卷：lvextend -L +10G /dev/centos/root重新定义文件系统大小： xfs_growfs /dev/centos/root（xfs文件系统专用，ext文件系统使用resize2fs）查看分区大小：df -h parted结合shell脚本快速分区12345#!/bin/bashparted /dev/$1 mklabel gptparted /dev/$1 printecho \"Ignore\" | parted /dev/$1 \"mkpart primary ext4 0 -1\"mkfs.ext4 /dev/\"$1\"1","tags":[{"name":"磁盘管理","slug":"磁盘管理","permalink":"http://www.dookt.com/tags/磁盘管理/"}]},{"title":"Python列表","date":"2019-07-26T08:47:33.000Z","path":"post/19235.html","text":"一组有序数据做成的序列 数据有先后顺序 数据可以不是一类数据 list的创建 直接创建。用中括号创建，内容直接用英文逗号隔开 使用list创建 列表包含单个字符串的时候是个特例 1234567# 直接赋值创建列表L1 = [1, 2, 3, 4, 5]# list内的数据可以不是一个类型L2 = [1, 2, 3, \"Xiaojing\", \"大拿\"]print(L1)print(L2) [1, 2, 3, 4, 5] [1, 2, 3, &apos;Xiaojing&apos;, &apos;大拿&apos;]1234# 创建列表的第二种方式L3 = list()print(L3)print(type(L3)) [] &lt;class &apos;list&apos;&gt;内置函数的概念 help：帮助函数 type：显示变量的类型 id：显示变量的id print： 1234567891011# list创建的特例演示s = \"Liu Dana\"# 想创建一个只包含s一个字符串的列表L1 = list(s)# 此种情况用 L1 = [s]L2 = [s]print(type(L1))print(L1)print(type(L2))print(L2) &lt;class &apos;list&apos;&gt; [&apos;L&apos;, &apos;i&apos;, &apos;u&apos;, &apos; &apos;, &apos;D&apos;, &apos;a&apos;, &apos;n&apos;, &apos;a&apos;] &lt;class &apos;list&apos;&gt; [&apos;Liu Dana&apos;]列表的常见操作 访问 使用下标操作，也叫索引 列表的元素索引是从0开始的 切片操作 对列表进行任意一段的截取 截取之后创建新的列表 123456L1 = [32,43,22,254,323,4]#使用下标访问print(L1[0])print(L1[5])# 记住IndexError引发的原因print(L1[15]) 32 4 --------------------------------------------------------------------------- IndexError Traceback (most recent call last) &lt;ipython-input-4-ade9bd6fe872&gt; in &lt;module&gt; 4 print(L1[5]) 5 # 记住IndexError引发的原因 ----&gt; 6 print(L1[15]) IndexError: list index out of range12345678910111213141516# 切片操作需要注意取值范围，左包括右边不包括L1 = [10,20,30,40,50,60,70,80,90,100]# 对比打印结果跟下表的值print(L1[1:6])# 下面结果说明切片生成的是一个全新的列表# 通过内置函数id可以判断出切片是后生成了全新的列表# id用来判断两个变量是否是一个变量L2 = L1[0:10]print(id(L1))print(id(L2))# 切片下边可以为空print(L1[:4])print(L1[2:])print(L1[:]) [20, 30, 40, 50, 60] 140401879572168 140401879570504 [10, 20, 30, 40] [30, 40, 50, 60, 70, 80, 90, 100] [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]123# 分片可以控制增长幅度，默认为1print(L1[::1])print(L1[::2]) [10, 20, 30, 40, 50, 60, 70, 80, 90, 100] [10, 30, 50, 70, 90]12# 下标可以超出范围，超出后不再考虑多余下标内容print(L1[:100]) [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]123456789101112# 下标值，增长幅度可以为负数# 下标为负数，表明顺序是从右往左# 规定：数组最后一个数字的下标为-1# 下面例子为空，因为默认是从左向右移动print(L1[-2:-5])# 如果想利用负数下标打印90.80.70，则print(L1[-2:-5:-1])# 如果想利用负数下标打印70.80.90，则print(L1[-4:-1:1]) [] [90, 80, 70] [70, 80, 90]12","tags":[{"name":"Python基础","slug":"Python基础","permalink":"http://www.dookt.com/tags/Python基础/"}]},{"title":"Python字符串","date":"2019-07-26T08:46:25.000Z","path":"post/35224.html","text":"定义：它是一个有序的字符的集合，用于存储和表示基本的文本信息，’’或””或””” “””中间包含的内容称之为字符串 查找类函数 字符串查找类。find、index、islower find：查找字符串中是否包含一个子串 index: 跟fid的唯一区别是index如果没有找到会引发异常 rfind、lfind：向右找或者向左找 1234s = \"Liu Dana kove Wang xiaojing\"s1 = \"xiaojing\"# 返回第一次发现这个字符串的位置s.find(s1) 191234s = \"Liu Dana kove Wang xiaojing\"# 返回-1表示没有找到s2 = \"WanWan\"s.find(s2) -11s.index(s1) 1912#index回报错或者引发异常s.index(s2) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-4-e04416278ca6&gt; in &lt;module&gt; 1 #index回报错或者引发异常 ----&gt; 2 s.index(s2) ValueError: substring not found123456#使用的时候可以使用区间s = \"Liu Dana kove Wang xiaojing and Zhang xiaojing\"s1 = \"xiaojing\"#从下标20开始找，看能否找到s.find(s1, 20) 38判断类函数 此函数的特点是一般都以is开头，比如islower isalpha：判断是否是字母，需要注意以下两点： 此函数默认的前提是字符串至少包含一个字符，如果没有，返回false 汉字被认为alpha，所以此函数不能你作为判断英文字母和汉字的标识，区分中英文，请使用unicode码 注意使用区别，防止被坑 isdigit,isnumric,isdecimal三个判断数字的函数,该三个函数的总结如下： 此类函数不建议使用，在后期爬虫中，判断是否是数字建议使用正则表达式 isdigit: True：Unicode数字，byte数字（单字节），全角数字（双字节），罗马数字 False：汉字数字 Error：无 isdecimal: True：Unicode数字，全角数字（双字节） False：罗马数字，汉字数字 Error：byte（单字节） isnumeric: True：Unicode数字， 全角数字（双字节），罗马数字，汉字数字 False：无 Error：byte（单字节） islower：判断是否是大写还是小写 12345678# 以下三个都不是。因为除了字母还有空格s1 = \"我们对着灯发誓，刘大拿同学是爱着王小静的\"s2 = \"bengberba is friend of baberbeng\"s3 = \"TuLingXueYuan.com is the 1.st\"print(s1.isalpha())print(s2.isalpha())print(s3.isalpha()) False False False12345# 需要注意的是，因为输入法的问题，输入的罗马数字得不到我们想要的结果chin_num = \"一二三四\"print(chin_num.isdigit())print(chin_num.isnumeric())print(chin_num.isdecimal()) False True False内容判断类 startswith/endswith：是否以什么开头或者结尾 监测某个字符串是否以某个子串开头，常用三个参数 suffix：被检测的字符串，必须有 start：检查范围的开始 end：检查范围的结束 islower/isupper：判断字符串是否是大写还是小写 123456dana = \"Liu Dana\"xiaojing = \"Xiao jing\"s = \"Liu Dana really love Wang Xiao jing\"print(s.startswith(dana))print(s.endswith(xiaojing)) True True1234567891011121314s1 = \"Dana love wang xiaojing\"s2 = \"Danalovewangxiaojing\"s3 = \"danalovewangxiaojing\"#s4 包含空格，但空格不影响结果，忽略s4 = \"dana love wangxiaojing\"s5 = \"刘大拿同学是爱过王晓静滴\"print(s1.islower())print(s2.islower())print(s3.islower())print(s4.islower())# 汉字字符串无大小写概念print(s5.islower())print(s5.isupper()) False False True True False False操作类函数 format：格式化用的 strip：去除字符串两方的空格，允许定义删除字符串两边的哪个字符，只不过不指定的话默认为空格。同样还有lstrip和rstrip，分别表示删除字符串左边、右边指定的字符串。默认为空格。注意此处的删除不是删除的一个，而是指从头开始缝合条件的连续字符 strip相似的还有lstrip、rstrip join：拼接字符串。需要一个可迭代的内容分作为参数。功能是把可迭代的字符串拼接再一起，中间使用调用字符串作为分隔符。 12345678910c = \"DDDDana love xiaojing \"# 是否成功删除两边的空格不能观察出来print(c.strip(''))print()print(c.strip(),end=\"-----\")print(\"--------\")print(c.strip('D'))print()print(c.strip(\"D\"),end=\"-----\") DDDDana love xiaojing DDDDana love xiaojing------------- ana love xiaojing ana love xiaojing -----123456789# join的例子。我们需要使用s1,s2,s3作为分隔符，把ss的内容拼接到一起s1 = \"$\"s2 = \"-\"s3 = \" \"ss = [\"Liu Dana\", \"love\", \"Wang\", \"Xiaojing\"]print(s1.join(ss))print(s2.join(ss))print(s3.join(ss)) Liu Dana$love$Wang$Xiaojing Liu Dana-love-Wang-Xiaojing Liu Dana love Wang Xiaojingtulingxueyuan.coding.net","tags":[{"name":"Python基础","slug":"Python基础","permalink":"http://www.dookt.com/tags/Python基础/"}]},{"title":"Python变量","date":"2019-07-26T08:44:01.000Z","path":"post/9630.html","text":"变量就是可以重复使用的一个量，或者一个代号 变量命名规则 变量命名可以包含数字、大小写字母、下划线（不推荐以上三种之外的字符） 数字不能打头 4man，5for 是不合法的变量名 man4，for5 是合法的变量名 一般在python中，以下划线开头的内容有特殊含义，不建议使用 比如_age，_name，理论上是可以的，强烈不推荐，包括但不限于一个下划线和两个下划线开头 大小写不一样，大小写敏感 ForMat跟forMat不是一个变量名称 推荐： 使用具有固定含义的英文单词或缩写，srv=server skt=socket，一般以posix命名规则为主 驼峰命名法： 大驼峰，每个单词首字母大写 在Python中给类命名使用此法 MyFirstLove，IntOne 小驼峰，类似大驼峰，但第一个小写 在Python中一般给普通变量或函数命名 myFirstLove.IntOne posix写法 多个单词用下划线 单词全部小写 my_first_love,int_one 保留字和关键字 变量命名必须避开，不能跟关键字和保留字重复 class，def，break，for 1234# 查看关键字的方法import keyword #引入关键字模块#打印系统全部关键字print(keyword.kwlist) [&apos;False&apos;, &apos;None&apos;, &apos;True&apos;, &apos;and&apos;, &apos;as&apos;, &apos;assert&apos;, &apos;async&apos;, &apos;await&apos;, &apos;break&apos;, &apos;class&apos;, &apos;continue&apos;, &apos;def&apos;, &apos;del&apos;, &apos;elif&apos;, &apos;else&apos;, &apos;except&apos;, &apos;finally&apos;, &apos;for&apos;, &apos;from&apos;, &apos;global&apos;, &apos;if&apos;, &apos;import&apos;, &apos;in&apos;, &apos;is&apos;, &apos;lambda&apos;, &apos;nonlocal&apos;, &apos;not&apos;, &apos;or&apos;, &apos;pass&apos;, &apos;raise&apos;, &apos;return&apos;, &apos;try&apos;, &apos;while&apos;, &apos;with&apos;, &apos;yield&apos;]变量申明 var_name = var_value var1 = var2 = var3 = var_value var1,var2,var3 = v1,v2,v3 12345678910111213141516# 定义变量age。把18放入变量age中age = 18print(age)print(18)# 给age1，age2，age3放入同样的一个内容或值age1 = age2 = age3 = 18print(age1)print(age2)print(age3)# 一行内给多个变量赋值age4, age5, age6 = 12, 21, 45print(age4)print(age5)print(age6) 18 18 18 18 18 12 21 45123456789#申明的三种格式#格式1s1 = \"我爱王晓静\"#格式2s2 = s1 = \"I love wangxiaojing\"#格式3s1, s2, s3 = \"I love wangxiaojing\", \"爱生活爱图灵\", 123 变量类型 严格来讲，python只有一个数据类型 标准数据类型一共六种 数字类型 Number 字符串类型 str 列表 list 元组 tuple 字典 dict 集合 set 数据类型 Number python中的数字没有大小限制常见数字分类整数 没有小数部分 表示正数，负数，0 二进制 只有0，1 以0b开头的01串 例如： 0b110 0b11110 八进制 以0o开的0到7之间的数字串 例如： 0o71 十六进制 以0x组成的由0-9，a-f构成的串 浮点数 科学计数法 复数 12345# 二进制案例a1 = 0b110print(a1)a2 = 0b11110print(a2) 6 30123# 八进制案例a3 = 0o71print(a3) 57123456#十六进制案例a4 = 0xffffprint(a4)a5 = 0x53f2print(a5) 65535 21490浮点数 就是通俗意义上的小数 常见的案例格式 3.14.59 3. 0.4 .4 科学计数法 定义与数学定义一致 写法就是e后面跟整数用来表示10的指数 123456789# 科学计数法height = 184print(184)height = 1.84e2print(height)a = .2print(a) 184 184.0 0.2复数 complex 与数学定义一致 复数的虚部用就j/J表示 例如： 5+4j 4j (4j) 12a = 4jprint(a) 4j布尔值 布尔值就是用来表示真假的值 只有两个值：True/False 在Python中，布尔值可以当数字使用 布尔值如果当数字使用，True=1,False=0 如果数字用来当做布尔值使用，0=False，其余的当做True 12345678910111213# 布尔值当做数字使用age = 18 + Trueprint(age)age = 18 + Falseprint(age)# 判断语句a = -1if a: print(\"负数是True\")else: print(\"负数是False\") 19 18 负数是True字符串 表达文字信息的内容，比如”我爱王晓静” 形式上是引号引起来的一段内容 引号包括 单引号 双引号 三引号，用来表示多行信息 单双引号含义一致，只能引用一行 123456789101112131415# 字符串案例love = \"Ich liebe Wang Xiaojing\"print(love)love2 = \"I love wangxiaojing\"print(love2)# 三引号可以表示多行love3 = '''我爱你呀哈哈哈哈北国风光'''print(love3) Ich liebe Wang Xiaojing I love wangxiaojing 我 爱你呀 哈哈哈哈 北国风光None类型 表示什么都没有。通常用来站位 比如返回，用来表示返回一个空","tags":[{"name":"Python基础","slug":"Python基础","permalink":"http://www.dookt.com/tags/Python基础/"}]},{"title":"Python表达式","date":"2019-07-26T08:43:11.000Z","path":"post/49699.html","text":"由一个或几个数字或者变量或者运算符合成第一行代码 通常返回一个结果运算符 由一个以上的值经过一系列运算得到新值的过程就叫运算 用来操作运算的符号叫做运算符 运算符分类 算数运算符 比较或关系运算符 赋值运算符 逻辑运算符 位运算符 成员运算符 身份运算符 12# 表达式案例a = 1 + 2 算数运算符 用来进行算数运算的符号 通常用来表示加减乘除 Python没有自增自减运算符 12345678910111213141516171819202122232425262728293031323334# 算数运算符案例# 加减乘跟数学基本一致a = 9 - 2 print(a)b= 9 + 2print(b)c = 8 * 2print(c)# Python除法分为普通除法，地板除，取余#正常除法(python2和python3不同)d = 9 / 2print(d)#地板除，取整e = 9 // 2print(e)#取余f = 9 % 2print(f)# 负数取余的结果g = 9 % -4print(g)#两个乘号就是指数a = 7 ** 2print(a) 7 11 16 4.5 4 1 -3 49比较运算符 对两个内容进行比较的运算符 结果一定是布尔值，即True/False 1234567891011121314# 等于 ==a = 3 == 4print(a)# 不等于 != a = 3 != 4print(a)# 其他的符号是# &gt;, &gt;=, &lt;, &lt;=print(3 &gt;= 4)print(\"Wangxiaojing\" &gt; \"liudana\")print(\"Wangxiaojing\" &gt; \"Wangx\") False True False False True赋值运算符 把一个值放到变量里边去 1234567891011121314151617181920# 赋值符号 = a = 9# 复杂赋值a = b = 9a, b = 1, 2# 赋值的缩写z = 100z = z + 3print(z)# 注意下面的符号仅仅是一个缩写z = 100z += 3print(z)# 所有数学运算符都可以缩写# -=, +=, /=, //=, %=, **=。都是缩写形式# Python里面没有 ++, -- 103 103逻辑运算符 对布尔类型变量或者值进行运算的符号 and：逻辑与 or：逻辑或 not：逻辑非 python里面的逻辑运算没有异或 运算规则： and看做乘法，or看做加法 True看做1，False看做0 则逻辑运算就能转换成整数运算 最后结果如果是0则为False，否则为True 逻辑运算的短路问题 逻辑运算时，按照运算顺序计算，一旦能够确定整个式子未来的值，则不再进行计算，直接返回 1234567891011121314151617# 逻辑表达式案例a = Trueb = Truec = Falseaa = a and b #右边表达式可以转换成1*1print(aa)bb =a and cprint(bb)cc = 100 and cprint(cc)# 布尔值跟数字的转换# 数字转换成布尔值的时候， 0 = False，其余的是True# 布尔值转换成数字的时候，True = 1， False = 0 True False False1234567# 短路问题案例1a = Trueb = Truec = Falseaa = a or b and (a and b) #转化成算数 1 + .........print(aa) True12345678910111213141516# 短路问题案例2def a(): print('a') return True def b(): print('b') return Trueaaa = a() and b()print(aaa)# 字符串乘以数字，表示这个字符串重复多少遍print(\"*\" * 20)bbb = a() or b() #短路发生print(bbb) a b True ******************** a True成员运算符 用来检测一个值或者变量是否在某个集合里 in：成员运算符 not in：不再里面的意思 12345678# in 案例L= [1, 2, 3, 4, 5]a = 6aa = a in Lprint(aa)# a没有在L里面aa = a not in Lprint(aa) False True身份运算符 用来确定两个变量是否是同一个变量 is：变量运算符 not is：不是 Python中，对整数N \\in [-5, 256],解释器对他们做了单独处理，放到了固定的内存中，不因每次运行而变化 这里再次记录一些相关的。 不仅对小整数有这样的处理，内建的类（int，staticmamethod，object，TypeError…）也是这样处理的 看一个变量的内存是不是这样处理的，无需运行两次，只需要看id()编号长度就行，他们是10位的，普通变量都是13位。 其实并不是每次运行结果都是一样的，比如重启之后再试试 不同的软件打开同一个python解释器结果也是不同的（最先打开的那个会影响其他的）。比如我电脑上先打开pycharm、cmd、jupyter得到的是不同的结果 电脑不关机的话，软件重复打开关闭的id是一样的 同一电脑上的不同的python解释器结果也肯定不同的，不同电脑更不用说。 12345678910111213141516171819# 身份运算符定义a = 1b = 10999999aa = a is bprint(aa)# a,b仅仅是值一样，并不代表a,b是一个变量 a = 10999999b = 10999999aa = a is bprint(aa)#正确理解下面案例和上面案例的区别# a,b仅仅是值一样，并不代表a,b是一个变量 # 小一点的数字不用重新开辟空间，a = 5b = 5aa = a is bprint(aa) False False True运算符优先级问题 小括号具有最高优先级 ** 指数（最高优先级） ~ + - 按位翻转，一元就加号和减号（最后两个方法名为 +@ 和 -@） * / % // 乘，除，取模和取整除 + - 加减法 &gt;&gt; &lt;&lt; 右移左移运算符 &amp; 位 &apos;AND&apos; ~ | 位运算符 &lt;= &lt; &gt; &gt;= 比较运算符 &lt; &gt; == != 等于运算符 = %= /= //= -= += *= **= 赋值运算符 is not is 身份运算符 in not in 成员运算符","tags":[{"name":"Python基础","slug":"Python基础","permalink":"http://www.dookt.com/tags/Python基础/"}]},{"title":"Python程序结构","date":"2019-07-26T08:41:49.000Z","path":"post/41256.html","text":"程序三种结构 顺序 循环 分支 分支结构 分支机构基本语句 if 条件表达式: 语句1 语句2 语句3 ...... 条件表达式就是计算结果必须为布尔值的表达式 表达式后面的冒号不能少 注意if后面的出现的语句，如果属于if语句块，则必须属于同一个缩进等级 条件表达式结果为True执行if后面的缩进的语句块 双向分支 if …else…表达式 语法结构： if 条件表达式： 语句1 语句2 ... else: 语句1 语句2 ... 123456789101112# if 语句案例# 如果今天不上班，就不用挤地铁了a = \"今天不上班\"# 字符串的真假# 只有空字符串为False，其余全为Trueb = \" \"if a: print(\"今天不用挤地铁啦\") print(\"真tmd舒服呀\")else: print(\"苦逼的工作，还得继续哇\") 今天不用挤地铁啦 真tmd舒服呀12345# if 练习2age = 24if age &gt; 18: print(\"成年啦，喝酒去\")print(\"下次我请你\") 成年啦，喝酒去 下次我请你123456789101112131415# input的作用：# 1.在屏幕上输出括号内的字符串# 2.接收用户在标准输入上的内容返回到程序# 3. input返回的内容一定是字符串# input负责接收用户输入的内容返回给变量gender = input(\"请输入你的性别(man/woman):\")# 打印输入的内容print(gender)if gender == \"man\": print(\"走走走,组对LOL\") print(\"游戏搞起\")else: print(\"你到底是什么呀\") print(\"对不起，我是男滴\") 多路分支 很多分值的情况，叫多路分支 if 条件表达式： 语句1 ... elif 条件表达式： 语句1 ... elif 条件表达式： 语句1 ... elif 条件表达式： 语句1 ... else: 语句1 ... elif可以有很多个，根据实际情况 else可选 多路分支最多只会执行一种情况 if语句可以嵌套，但不推荐 python没有switch语句 123456789101112131415161718192021# 考试成绩判断# 成绩有用户输入# 90分以上：优秀# 80-90分：良# 70-80分：中# 60-70分：平# 60分以下：你又不及格啦# input返回的内容一定是字符串# 输入成绩，需要输入input函数score = int(input(\"请输入你的成绩：\"))if score &gt;= 90: print(\"优\")elif score &gt;= 80 and score &lt; 90: print(\"良\")elif score &gt;= 70 and score &lt; 80: print(\"中\")elif score &gt;= 60 and score &lt; 70: print(\"平\")else: print(\"差\") 请输入你的成绩：99 优循环语句 重复执行某一个固定的动作或者任务 分类 for while for循环 语法 for 变量 in 序列： 语句1 语句2 ... 1234567# for 循环例子# 比如 [1, 2, 3, 4, 5, 6, 7]list_one = [1, 2, 3, 4, 5, 6, 7]for num in list_one: print(num) print(num + 100) for-else语句 for循环结束的时候，有时候需要执行一些收尾工作，此时需要使用else收尾 else语句是可选的 123456789101112# 打印学生列表姓名# 如果是jingjing，那肯定是我最爱呀# 如果是别的学生，那我肯定冷酷的拒绝他stu_list = ['王二牛','李美丽','张二狗','王麻子']for stu in stu_list: if stu == \"张二狗\": print(\"这位是张二狗\") else: print(\"对不起同学，认错人了\")else: print(\"不会再爱了\") break, contiune, pass break：无条件结束整个循环，简称循环猝死 continue：继续，记录结束本轮循环，到下一轮 pass：只是一个占位符,代表这句话啥也不干，没有跳过功能 12345678# 确定一个数组队列中，是否包含某个数字，找到即可，不需要再继续找。所以用breakdig_list = [3,4,6,8,9,7,7,23]for dig in dig_list: if dig == 7: print(\"哈哈哈，终于找到你\") break else: print(dig) 123456789# continue语句案例1# 确定一个数组队列中，是否包含某个数字，找到即可，不需要再继续找。所以用breakdig_list = [3,4,6,8,9,7,7,23]for dig in dig_list: if dig == 7: print(\"哈哈哈，终于找到你\") continue else: print(dig) 123456789101112131415161718# continue语句案例2# 在数字1-10中，寻找所有偶数，找到偶数后打印偶数dig_list = [1,2,3,4,5,6,7,8,9,10]for dig in dig_list: if dig % 2 == 0: print(dig) print(\"哈哈哈，你是一个双的\") else: continuedig_list = [1,2,3,4,5,6,7,8,9,10]for dig in dig_list: if dig % 2 == 1: continue print(dig) print(\"哈哈哈，你是一个双的\") 123456# pass 案例1age = 19if age &gt; 19: passelse: print(\"你还小，啥都干不了\") 12345# pass案例2ages = [2,23,43,54,65,2]for age in ages: pass print(age) range函数 生成有序数列 生成数字序列可以定制 123456789# range案例1#生成一个从1-10的数字序列# range生成的序列左包括右不包括dig_list = range(1,11)for dig in dig_list: print(dig) # 一般在python中，连个表示范围的数字都是左包括右不包括，randint是个特例# range函数再Python2和Python3中有严重区别 1234# range案例3# 打印1到5的数字for i in range(1,6): print(i) 1 2 3 4 5while循环 一个循环语句 表示当条件成立时，就循环，适应于不知道具体的循环次数，但能确定某个条件成立的情况下就循环 while语法 while 条件表达式： 语句块 #另外一种表达式方法 while 条件表达式： 语句块1 else: 语句块2 123456789101112131415161718# 如果年利率是6.7%，本利是每年翻滚，这多少年本钱翻倍benqian = 10000year = 0 #存放需要翻本的年数while benqian &lt; 20000: benqian = benqian * (1+ 0.067) year += 1 # year = year + 1print(year)# 年利率案例2# 本案例中循环题没有被执行，why? ,如何改正？benqian = 10000year =0while benqian &lt; 20000: benqian = benqian * (1+ 0.067) year += 1 # year = year + 1else: print(year) 11 1112","tags":[{"name":"Python基础","slug":"Python基础","permalink":"http://www.dookt.com/tags/Python基础/"}]},{"title":"Python元组","date":"2019-07-26T08:40:23.000Z","path":"post/50225.html","text":"tuple（元组）:可以理解成一个不允许更改的列表 1234567891011# tuple的创建# 1. 直接用小括号ta = ()print(type(ta))# 当用小括号创建一个元素的tuple的时候tb = (100)print(type(tb))tc = (100, )print(type(tc))td = (100, 200, 300)print(type(td)) &lt;class &apos;tuple&apos;&gt; &lt;class &apos;int&apos;&gt; &lt;class &apos;tuple&apos;&gt; &lt;class &apos;tuple&apos;&gt;12345# 2.直接使用逗号ta = 100,print(type(ta))tb = 100, 200, 300, #后便可以跟一个逗号print(type(tb)) &lt;class &apos;tuple&apos;&gt; &lt;class &apos;tuple&apos;&gt;1234567# 3. 使用tuple定义ta = tuple()print(ta)li = [1, 2, 3, 'Ruigege']tb = tuple(li) #可迭代print(tb)print(li) () (1, 2, 3, &apos;Ruigege&apos;) [1, 2, 3, &apos;Ruigege&apos;]tuple其余特征和list基本一致 有序 可以访问不可以修改 元素可以是任意类型 12345# tuple索引操作la = ['I', 'love','Yanggougou']print(la)ta = tuple(la)print(ta[2]) [&apos;I&apos;, &apos;love&apos;, &apos;Yanggougou&apos;] Yanggougou1234# tuple分片操作print(ta[:])print(ta[:2])print(ta[-1::-1]) (&apos;I&apos;, &apos;love&apos;, &apos;Yanggougou&apos;) (&apos;I&apos;, &apos;love&apos;) (&apos;Yanggougou&apos;, &apos;love&apos;, &apos;I&apos;)12345# 元组相加ta = 100, 200, 300tb = ('I', 'Love', 'Yanggougou')tc = ta + tbprint(tc) (100, 200, 300, &apos;I&apos;, &apos;Love&apos;, &apos;Yanggougou&apos;)123# tuple乘法tc = tb * 2print(tc) (&apos;I&apos;, &apos;Love&apos;, &apos;Yanggougou&apos;, &apos;I&apos;, &apos;Love&apos;, &apos;Yanggougou&apos;)1234567# tuple成员检测print(tb)if 'Yanggougou' in tb: print(\"YES\")if 'love' not in tb: print(\"NO\") (&apos;I&apos;, &apos;Love&apos;, &apos;Yanggougou&apos;) YES NO123# tuple遍历for i in tb: print(i) I Love Yanggougou1234567891011121314ta = ((10, 20, 30),('I','Love','Ynaggougou'),(100, 200, 300))# 嵌套元组的访问# 1.双层循环访问for i in ta: print(i) for j in i: print(j) # 2.使用单层循环访问for i,j,k in ta: print(i,j,k)#上面访问有一个规定，几i,j,k要和元组元素个数对应for i,j,k,q in ta: print(i,j,k,q) (10, 20, 30) 10 20 30 (&apos;I&apos;, &apos;Love&apos;, &apos;Ynaggougou&apos;) I Love Ynaggougou (100, 200, 300) 100 200 300 10 20 30 I Love Ynaggougou 100 200 300 --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-43-d64a99607a4b&gt; in &lt;module&gt; 11 print(i,j,k) 12 #上面访问有一个规定，几i,j,k要和元组元素个数对应 ---&gt; 13 for i,j,k,q in ta: 14 print(i,j,k,q) ValueError: not enough values to unpack (expected 4, got 3)123456789# 常用的元组函数ta = (1, 34, 5, 7)# len：取长度print(len(ta))# max：取最大值print(max(ta))tb = (1, 2, 3, \"love\")print(max(tb)) 4 34 --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-50-28c83d67aa92&gt; in &lt;module&gt; 7 8 tb = (1, 2, 3, &quot;love&quot;) ----&gt; 9 print(max(tb)) TypeError: &apos;&gt;&apos; not supported between instances of &apos;str&apos; and &apos;int&apos;12345# count：对某个元素计数ta = (1,2,3,4,5,6,8,23,567,9,123,1,1,1,6,1)print(ta.count(1))# index：某一元素的所在位置print(ta.index(6)) 5 512345678# tuple特殊用法a = 100b = \"Yanggougou\"print(a,b)# 要求对a,b进行互换# 此种用法是Python专用a,b = b,aprint(a,b) 100 Yanggougou Yanggougou 10012","tags":[{"name":"Python基础","slug":"Python基础","permalink":"http://www.dookt.com/tags/Python基础/"}]},{"title":"Python集合","date":"2019-07-26T08:38:46.000Z","path":"post/62246.html","text":"跟数学中的集合概念一致 内容无序 + 内容不重复 123456789101112# 集合的定义# 1.通过set关键字sa = set()print(sa)li = [1,2,3,4,5,6,12,345,4,1,2]sb = set(li)print(sb)# 使用大括号sc = &#123;1,2,3,44,4,4,6,2,3,1,5,6,12,345,4,5,4,6,2,3,1,2&#125;print(sc) set() {1, 2, 3, 4, 5, 6, 12, 345} {1, 2, 3, 4, 5, 6, 44, 12, 345}12345# in 操作if 2 in sc: print(2222222222)if 23 in sc: print(NONONONNO) 22222222221234567# 集合遍历sa = &#123;1,2,3,44,4,4,6,2,3,1,5,6,12,345,4,5,4,6,2,3,1,2&#125;for i in sc: print(i)sb = &#123;(1,2,3),(4,5,6),('I','Love','Yanggougou')&#125;for i,j,k in sb: print(i,j,k) 1 2 3 4 5 6 44 12 345 I Love Yanggougou 4 5 6 1 2 312345678910111213141516# 集合的生成式sa = &#123;1,2,3,4,5,6,7,8,9,10&#125;sb = &#123;i for i in sa&#125;print(sb)sc = &#123;i for i in sa if i % 2 == 0&#125;print(sc)# 双重for循环# 把sa中每一个元素的平方生成一个新的集合# 1.用一个forsd = &#123; i**2 for i in sa&#125;print(sd)# 2.使用两个for循环# 仔细思考，se的长度应该是多少个se = &#123;m*n for m in sa for n in sa&#125;print(se) {1, 2, 3, 4, 5, 6, 7, 8, 9, 10} {2, 4, 6, 8, 10} {64, 1, 4, 36, 100, 9, 16, 49, 81, 25} {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 16, 18, 20, 21, 24, 25, 27, 28, 30, 32, 35, 36, 40, 42, 45, 48, 49, 50, 54, 56, 60, 63, 64, 70, 72, 80, 81, 90, 100}1234567891011# 集合的内置函数# len：长度print(len(se))# max/min：最值# add：向集合中添加元素sa = &#123;1,2,3,4,5,6,5,4,3,2,1&#125;print(sa)# 打印结果不是sa,print(sa.add(7))print(sa)# clear：清空 42 {1, 2, 3, 4, 5, 6} None {1, 2, 3, 4, 5, 6, 7}12345678# 删除操作# remove 和 discard的区别sa = &#123;1,2,3,4,5,6,7&#125;print(sa)sa.remove(5)print(sa)# remove删除的值不存在集合中，报错sa.remove(5) {1, 2, 3, 4, 5, 6, 7} {1, 2, 3, 4, 6, 7} --------------------------------------------------------------------------- KeyError Traceback (most recent call last) &lt;ipython-input-43-eebf097aaad5&gt; in &lt;module&gt; 6 print(sa) 7 # remove删除的值不存在集合中，报错 ----&gt; 8 sa.remove(5) KeyError: 512345sa = &#123;1,2,3,4,5,6,7&#125;print(sa)sa.discard(5)print(sa)sa.discard(5) {1, 2, 3, 4, 5, 6, 7} {1, 2, 3, 4, 6, 7}1234567# pop弹出集合的一个内容# 删除的内容是随机的# 删除的内容没有规律，随机sa = &#123;1,2,3,4,5,6,7&#125;print(sa)sa.pop()print(sa) {1, 2, 3, 4, 5, 6, 7} {2, 3, 4, 5, 6, 7}1234567891011121314151617# 集合的数学操作# intersection：交集sa = &#123;1,2,3,4,5,6&#125;sb = &#123;4,5,6,7,8,9&#125;# sa和sb的交集print(sa.intersection(sb))# difference：差集print(sa.difference(sb))# 差集另一种表示print(sa - sb)# union：并集print(sa.union(sb))print(sb.union(sa))# + 不表示并集print(sa + sb) {4, 5, 6} {1, 2, 3} {1, 2, 3} {1, 2, 3, 4, 5, 6, 7, 8, 9} {1, 2, 3, 4, 5, 6, 7, 8, 9} --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-94-f45a7ca65304&gt; in &lt;module&gt; 15 print(sb.union(sa)) 16 # + 不表示并集 ---&gt; 17 print(sa + sb) TypeError: unsupported operand type(s) for +: &apos;set&apos; and &apos;set&apos;forzenset 冰冻集合 不允许修改的集合 1234# 案例print(sa)sb = frozenset(sa)print(sb) {1, 2, 3, 4, 5, 6} frozenset({1, 2, 3, 4, 5, 6})","tags":[{"name":"Python基础","slug":"Python基础","permalink":"http://www.dookt.com/tags/Python基础/"}]},{"title":"Python递归","date":"2019-07-26T06:49:00.000Z","path":"post/39643.html","text":"递归：函数直接或者间接调用自己 递归分两个过程： 往下回溯。分解的过程 往上回溯，综合的过程 递归需要注意 一定有结束条件 以资源换取编写速度 123456def funca(n): print(\"I am MINT\")def funcb(n): funca(100) print(\"I am Yanggougou\")funcb(100) I am MINT I am Yanggougou12345678910# func_a表示阶乘# 利用数学公式def func_a(n): print(n) # 递归必须有结束条件，否则会死掉 if n == 1: return 1 return n * func_a(n-1)rst = func_a(6)print(\"f(6)=\", rst) 6 5 4 3 2 1 f(6)= 72012345678910# 斐波那切数列# 数学定义自行查找def fib(n): # 结束条件 if n == 1 or n == 2: return 1 return fib(n-1) + fib(n-2)rst = fib(10)print(\"rst = \",rst) rst = 55123456789101112131415161718# 汉诺塔# 把a上的盘子通过移动到c上，注意盘子必须大的在下面a = 'A'b = 'B'c = 'C'def hanot(a,b,c,n): if n ==1: print(\"&#123;&#125;--&gt;&#123;&#125;\".format(a,c)) return None if n == 2: print(\"&#123;&#125;--&gt;&#123;&#125;\".format(a,c)) print(\"&#123;&#125;--&gt;&#123;&#125;\".format(a,b)) print(\"&#123;&#125;--&gt;&#123;&#125;\".format(b,c)) return None # 有n个盘子，把n-1(上面的n-1)个从a借助c，放到b上 hanot(a,c,b,n-1) print(\"&#123;&#125;--&gt;&#123;&#125;\".format(a,c)) hanot(b,a,c,n-1) 12# 一个盘子hanot(a,b,c,1) A--&gt;C12# 两个盘子hanot(a,b,c,2) A--&gt;C A--&gt;B B--&gt;C12# 4个盘子hanot(a,b,c,4) A--&gt;C A--&gt;B B--&gt;C A--&gt;B C--&gt;B C--&gt;A A--&gt;B A--&gt;C B--&gt;A B--&gt;C C--&gt;A B--&gt;C A--&gt;C A--&gt;B B--&gt;C","tags":[{"name":"Python基础","slug":"Python基础","permalink":"http://www.dookt.com/tags/Python基础/"}]},{"title":"Nginx-HTTP模块详解","date":"2019-07-25T14:33:53.000Z","path":"post/60161.html","text":"openresty使用content_by_lua打印出用户浏览器信息1234location /lua &#123; default_type text/html; content_by_lua 'ngx.say(\"User-Agent:\", ngx.req.get_headers()[\"User-Agent\"])';&#125; Nginx HTTP模块详解配置块的嵌套123456789101112131415161718mainhttp &#123; upstream &#123;...&#125; split_clients &#123;...&#125; map &#123;...&#125; geo &#123;...&#125; server &#123; if () &#123;...&#125; location &#123; limit_except &#123;...&#125; &#125; location &#123; location &#123; &#125; &#125; &#125; server &#123;&#125;&#125; 指令的context 指令的能够出现的配置块，配置范围 log_format：http access_log：http,server,location,if in location, limit_except listen：server root：server,location 指令的合并 指令在多个块下同时出现， 并不是所有指令都能合并 合并规则：子配置不存在时，直接使用父配置块；子配置存在时，覆盖父配置 值指令：解析配置时，存储当时配置的值 root access_log gzip 动作指令 rewrite proxy_pass server_rewrite阶段 rewrite阶段 content阶段 需要理解的问题 指令在哪个块下生效？ 指令允许出现在那些块下？ 在server块生效，从http向server合并指令 配置缓存在内存 listen指令12345678listen unix:/var/run/nginx.sock; #监听unix socket地址listen 127.0.0.1:8000; #监听端口加地址listen 127.0.0.1; #只监听IP,默认会监听80端口listen 8000;listen *:8000;listen localhost:8000 bind;listen [::]:8000 ipv6only=on; #只支持IPV6listen [::] Nginx正则表达式 元字符 . ：匹配换行符之外的任意字符 \\w：匹配字母数字或下划线或汉字 \\d：匹配数字 \\s：匹配任意的空白字符 \\b：匹配单词的开始或结束 ^：匹配字符串的开始 $：匹配字符串的结束 重复 *：重复零次或多次 +：重复一次或多次 ?：重复零次或一次 {n}：重复n次 {n，}：重复n次或更多次 {n，m}：重复n到m次 server_name指令块 server_name：可以跟多个域名，第一个是主域名，支持泛域名（仅支持最前和最后），正则表达式（加~前缀） server_name_in_redirect：控制主域名 1234567# 初始配置server &#123; listen 8099; server_name primary.dookt.com.cn second.dookt.com.cn; server_name_in_redirect off; return 302 /redirect; &#125; 使用curl命令查看结果，发现主域名未生效 12345678[root@openresty01 ~]# curl -I http://second.dookt.com.cn:8099/redirectHTTP/1.1 302 Moved TemporarilyServer: openresty/1.13.6.2Date: Thu, 11 Jul 2019 19:20:04 GMTContent-Type: text/htmlContent-Length: 167Location: http://second.dookt.com.cn:8099/redirectConnection: keep-alive 1234567# 开启server_name_in_redirect后的配置server &#123; listen 8099; server_name primary.dookt.com.cn second.dookt.com.cn; server_name_in_redirect on; return 302 /redirect; &#125; 使用curl命令查看结果，发现使用非主域名访问，会自动跳转至主域名 12345678[root@openresty01 ~]# curl -I http://second.dookt.com.cn:8099/redirectHTTP/1.1 302 Moved TemporarilyServer: openresty/1.13.6.2Date: Thu, 11 Jul 2019 19:19:55 GMTContent-Type: text/htmlContent-Length: 167Location: http://primary.dookt.com.cn:8099/redirectConnection: keep-alive 用正则表达式创建变量123456789101112131415# 案例一：位置变量，例如此处取到www.dookt.com,则$2 = 'dookt.com'，即root /site/dookt.com;server &#123; server_name ~^(www\\.)?(.+)$; location / &#123; root /sites/$2; &#125;&#125;#案例二：命名变量server &#123; server_name ~^(www\\.)?(?&lt;domain&gt;.+)$; location / &#123; root /sites/$domain; &#125;&#125; 其他用法 .dookt.com可以匹配dookt.com和*.dookt.com _匹配所有 “”匹配没有传递Host头部 server_name匹配顺序 精确匹配 *在前的泛域名 *在后的泛域名 按文件中的顺序匹配正则表达式域名 default server 第一个 listen指定default HTTP请求的11个阶段除http过滤模块以及只提供变量的nginx模块，所有的http模块必须从nginx定义好的11个阶段进行请求处理 POST_READ：realip #读取到http头部时 SERVER_REWRITE：rewrite FIND_CONFIG：find_config REWRITE：rewrite POST_REWRITE：rewrite #刚刚rewrite之后 PREACCESS：limit_conn, limit_req ACCESS：access, auth_basic, auth_request POST_ACCESS PRECONNECT：try_file, mirrors CONNECT：concat, random_index, index, auto_index, static LOG：log postread阶段—realip模块如何拿到用户的真实IP地址？ TCP连接4元组(src ip, src port, dst ip, dst port) HTTP头部X_Forwarded_for用于传递IP HTTP头部X-Real-IP用于传递用户IP 网络中存在许多反向代理 用户 –&gt; ADSL –&gt; CDN –&gt; 反向代理1 –&gt; Nginx 用户内网IP：172.16.100.x 运营商IP：115.204.33.1 CDN IP地址：1.1.1.1 反向代理IP：2.2.2.2 CDN添加：X-Forward_For：115.204.33.1 X-Real-IP：115.204.33.1 反向代理添加的：X-Forward_For：115.204.33.1，1.1.1.1 X-Real-IP：115.204.33.1 此时Nginx就知道用户地址为：115.204.33.1，远端地址(remote_addr)为：2.2.2.2 拿到用户真实IP地址如何使用?基于变量使用，如：binary_remote_addr，remote_addr。其值为真实的IP,这样做连接限制(limit_conn模块)才有意义。 realip模块的指令123# 默认不带realip模块，编译添加该模块至nginx中./configure --with-http_realip_module --add-module=../tengine-2.2.2/modules/ngx_slab_stat/ gmake &amp;&amp; gmake install set_real_ip_from（是指接受从哪个信任前代理处获得真实用户ip，哪些地址里的x-forwareed-for才替换remote_addr变量） Syntax: set_real_ip_from address | CIDR | unix:; Default: — Context: http, server, location real_ip_header（是指从接收到报文的哪个http首部去获取前代理传送的用户ip） Syntax: real_ip_header field | X-Real-IP | X-Forwarded-For | proxy_protocol; Default: real_ip_header X-Real-IP; Context: http, server, location real_ip_recursive（环回地址，打开时，把x_forwarded_for最后的地址如果和客户端地址相同的话，取下一个地址） Syntax: real_ip_recursive on | off; Default: real_ip_recursive off; Context: http, server, location 12345678910111213# 关闭环回地址real_ip_recursive时server &#123; server_name realip.dookt.com.cn; error_log logs/realip-error.log debug; set_real_ip_from 172.16.100.11; #把本机设置为可信地址 #real_ip_header X-Real-IP; real_ip_recursive off; real_ip_header X-Forwarded-For; location / &#123; return 200 \"Client real ip: $remote_addr\\n\"; &#125;&#125; 使用curl -H在请求中添加head 12[root@openresty01 ~]# curl -H 'X-Forwarded-For: 1.1.1.1, 172.16.100.11' realip.dookt.com.cnClient real ip: 172.16.100.11 12345678910111213#开启环回地址real_ip_recursive时server &#123; server_name realip.dookt.com.cn; error_log logs/realip-error.log debug; set_real_ip_from 172.16.100.11; #real_ip_header X-Real-IP; real_ip_recursive on; real_ip_header X-Forwarded-For; location / &#123; return 200 \"Client real ip: $remote_addr\\n\"; &#125;&#125; 开启环回地址后。这个变量remote_addr（1.1.1.1）就可以用来限速处理了 12[root@openresty01 ~]# curl -H 'X-Forwarded-For: 1.1.1.1, 172.16.100.11' realip.dookt.com.cnClient real ip: 1.1.1.1 Rewrite模块：return指令 Syntax: return code [text];return code URL;return URL; Default: — Context: server, location, if Nginx返回状态码 Nginx自定义 444：Nginx自定义的（Nginx立即关闭连接，不再向用户发送任何信息） HTTP1.0标准 301：http1.0永久重定向 302：临时重定向，禁止被缓存 HTTP1.1标准 303：临时重定向，允许改变方法，禁止被缓存 307：临时重定向，不允许改变方法，禁止被缓存 308：永久重定向，不允许改变方法 Rewrite模块：return指令和error_page Syntax: error_page code … [=[response]] uri; Default: — Context: http, server, location, if in location 12345678910111213#例子1. error_page 404 /404.html;2. error_page 500 502 503 504 /50x/html;3. error_page 404 = 200 /empty.gif;4. error_page 404 = /404.php;5. location / &#123; error_page 404 = @fallback; &#125; location @fallback &#123; proxy_pass http://backend; &#125;6. error_page 403 http://example.com/forbidden,html;7. error_page 404 = 301 http://example.com/notfound.html; return指令和error_page例子Q：server块下与location块下的return指令关系？ A：server块下return与location块下return分别属于server rewrite阶段和rewrite阶段，前者server rewrite先于后者rewrite执行。return是动作类指令，没有合并关系 Q：return与error_page指令的关系？ A： 1234567891011# 使用error_page把404页面重定向到403.htmlserver &#123; listen 8080; server_name return.dookt.com.cn; root html/; error_page 404 /403.html; #return 405; location / &#123; #return 404 &quot;Find nothing!\\n&quot;; &#125;&#125; 使用curl访问测试结果如下，结果为自定义的403.html文件的内容 12[root@openresty01 ~]# curl return.dookt.com.cn:8080/sdfgsag.txt&lt;h1&gt;test 403 Forbirdden&lt;/h1&gt; 1234567891011# location块下return与server块下error_page的关系server &#123; listen 8080; server_name return.dookt.com.cn; root html/; error_page 404 /403.html; #return 405; location / &#123; return 404 \"Find nothing!\\n\"; &#125;&#125; 使用curl访问测试结果如下，结果返回Find nothing！ 12[root@openresty01 ~]# curl return.dookt.com.cn:8080/sdfgsag.txtFind nothing! 1234567891011# server与location块下的return指令关系server &#123; listen 8080; server_name return.dookt.com.cn; root html/; error_page 404 /403.html; return 405; #server rewrite阶段 location / &#123; return 404 \"Find nothing!\\n\"; #rewrite阶段 &#125;&#125; 使用curl访问测试结果如下，返回结果405 12345678[root@openresty01 extra]# curl return.dookt.com.cn:8080/sdfgsag.txt&lt;html&gt;&lt;head&gt;&lt;title&gt;405 Not Allowed&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=\"white\"&gt;&lt;center&gt;&lt;h1&gt;405 Not Allowed&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;openresty/1.13.6.2&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; 结果表明：server阶段的return 先于location阶段的return执行 Rewrite模块：重写URL Syntax: rewrite regex replacement [flag]; Default: — Context: server, location, if rewrite功能 将regex指定的url替换成replacement这个新的URL 可以使用正则表达式及变量提取 当replacement以http://或者https://或者$schema开头，则直接返回302重定向 替换后的url根据flag指定的方式进行处理 last：用replacement这个URL进行新的location匹配 break：break指令停止当前脚本指令的执行，等价于独立的break指令 redirect：返回302重定向 permanent：返回301重定向 123456789# 目录结构如下tree html├── first│ └── 1.txt├── index.html├── second│ └── 2.txt└── third └── 3.txt 12345678910111213141516171819202122#配置文件，未使用breakserver &#123; listen 8057; server_name rewrite.dookt.com.cn; rewrite_log on; error_log logs/rewrite_error.log notice; root html/; location /first &#123; rewrite /first(.*) /second$1 last; return 200 'first!\\n'; &#125; location /second &#123; rewrite /second(.*) /third$1; #此处没有break,执行完之后，执行return 200 'second!\\n'; return 200 'second!\\n'; &#125; location /third &#123; return 200 'third!\\n'; &#125;&#125; 使用curl访问 first/3.txt，此时先匹配location /first，在重定向到location /second.然后返回 second! 12[root@openresty01 ~]# curl rewrite.dookt.com.cn:8057/first/3.txtsecond! 12345678910111213141516171819202122# 此时使用breakserver &#123; listen 8057; server_name rewrite.dookt.com.cn; rewrite_log on; error_log logs/rewrite_error.log notice; root html/; location /first &#123; rewrite /first(.*) /second$1 last; return 200 'first!\\n'; &#125; location /second &#123; rewrite /second(.*) /third$1 break; #此处使用break时，直接跳出location /second，同时也跳出了return 200 'second!\\n' return 200 'second!\\n'; &#125; location /third &#123; return 200 'third!\\n'; &#125;&#125; 使用curl访问 first/3.txt，此时先匹配location /first，在重定向到location /second（使用breakt跳出，未执行return），然后转到location /third。返回 third！ 12[root@openresty01 ~]# curl rewrite.dookt.com.cn:8057/first/3.txttest3 Rewrite模块：条件判断if根据请求中变量的值，判断变量的值是否满足某个条件，在执行if块下的配置指令，根据这些匹配指令在调用相应模块执行请求 Syntax: if (condition) { … } Default: — Context: server, location 如果条件（condition）为真，则执行大括号内的指令，遵循值指令的继承规则 if指令的条件表达式 检查变量为空或值是否为0，直接使用 将变量与字符串做匹配，或者使用 = 或者 != 将变量与正则表达式做匹配 大小写敏感：~ 或者 !~ 大小写不敏感：* 或者 !* 检查文件是否存在，使用 -f 或者 !-f 检查目录是否存在，使用 -d 或者 !-d 检查文件，目录，软链是否存在，使用 -e 或者 !-e 检查是否为可执行文件，使用 -x 或者 !-x 1234567891011121314151617181920# 示例1,如果用户访问代理是IE浏览器就执行以下操作if ($http_user_agent ~ MSIE) &#123; rewrite ^(.*)$ /msie/$1 break; &#125;# 案例2，if ($http_cookie ~* \"id=([^;]+)(?::|$)\") &#123; set $id $1;&#125;# 案例3，post方法返回405if ($request_mothod = POST) &#123; return 405&#125;# 案例4，满足需要是限速10kif ($slow) &#123; limit_rate 10k;&#125;# 案例5,如果是盗链，则返回403if ($invalid_referer) &#123; return 403;&#125; find_config阶段：找到处理请求的location指令块 Syntax: location [ = | ~ | * | ^ ] uri { … }location @name { … } Default: — Context: server, location merge_shashes：可以合并url中的斜杠 Syntax: merge_slashes on | off; Default: merge_slashes on; Context: http, server location匹配规则：仅匹配URI,忽略参数 合并连续的 ‘/‘ 符号 merge_shashes on 前缀字符串 常规（） = ：精确匹配 ^~：匹配上后不再进行正则表达式匹配 用于内部跳转命名的location ：@ 正则表达式 ~ ：大小写敏感的正则匹配 ~* ：忽略大小写的正则匹配 12345678910111213141516171819202122232425262728# 案例server &#123; server_name location.dookt.com.cn; location ~/Test1/$ &#123; return 200 'First regular expresssions match!\\n'; &#125; location ~* /Test1(\\w+)$ &#123; return 200 'Longest regular expresssions match!\\n'; &#125; location ^~/Test1/ &#123; return 200 'Stop regular expresssions match!\\n'; &#125; location /Test1/Test2 &#123; return 200 'Longest prefix string match!\\n'; &#125; location /Test1 &#123; return 200 'Prefix string match!\\n'; &#125; location = /Test1 &#123; return 200 'Exact match!\\n'; &#125;&#125; 使用curl命令测试结果如下： 123456789101112131415161718192021# 访问 /Test1 --- 匹配到5，6，精确匹配[root@openresty01 ~]# curl location.dookt.com.cn/Test1Exact match!# 访问 /Test1/ ---匹配上1，[root@openresty01 ~]# curl location.dookt.com.cn/Test1/Stop regular expresssions match!# 访问 /Test1/Test2 --- 前缀匹配[root@openresty01 ~]# curl location.dookt.com.cn/Test1/Test2Longest regular expresssions match!# 访问 /Test1/Test2/ ---[root@openresty01 ~]# curl location.dookt.com.cn/Test1/Test2/Longest prefix string match!# 访问 /test/Test2 ---[root@openresty01 ~]# curl location.dookt.com.cn/test1/Test2/&lt;html&gt;&lt;head&gt;&lt;title&gt;404 Not Found&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=\"white\"&gt;&lt;center&gt;&lt;h1&gt;404 Not Found&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;openresty/1.13.6.2&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; location匹配顺序 遍历匹配全部前缀字符串location 如果匹配上 “=” 字符串，则使用匹配上的”=”精确匹配location 如果匹配上 “^“ 字符串，则使用匹配上的 “^“ 字符串location 如果没有匹配上，则记住最长匹配的前缀字符串location 按nginx.conf中的顺序依次匹配正则表达式location 如果匹配上，则使用匹配上的正则表达式 如果没有匹配上，则继续按nginx.conf中的顺序依次匹配正则表达式location 如果所有的正则表达式都不匹配，则使用最长匹配的前缀字符串location preaccess阶段：对连接做限制的limit_conn模块 生效阶段：NGX_HTTP_PREACCESS_PHASH阶段 模块：http_limit_conn_module 默认编译进nginx，通过–wthout-http_limit_conn_module禁用该模块 生效范围 全部的worker进程（基于共享内存） 进入preaccess阶段前不生效 限制的有效性取决于key的设计：依赖于postread阶段的realip模块总中取到的真实IP limit_conn指令 定义共享内存（包括大小），以及key关键字 Syntax: limit_conn_zone key zone=name:size; Default: — Context: http 限制并发连接数 Syntax: limit_conn zone number; Default: — Context: http, server, location 限制发生时的日志级别 Syntax: limit_conn_log_level info | notice | warn | error; Default: limit_conn_log_level error; Context: http, server, location 限制发生时向客户端返回的错误码 Syntax: limit_conn_status code; Default: limit_conn_status 503; Context: http, server, location 12345678910111213#配置一个叫addr的共享内存，用来限制客户端访问，还限制访问速率50字节，并给出限制访问客户端返回错误码500limit_conn_zone $binary_remote_addr zone=addr:10M;server &#123; server_name limit.dookt.com.cn; root html; error_log logs/limit-error.log info; location / &#123; limit_conn_status 500; limit_conn_log_level warn; limit_rate 50; limit_conn addr 1; &#125;&#125; 1234567891011# 依次使用curl命令访问limit.dookt.com.cn,可以看出第二个返回了500 [root@openresty01 ~]# curl limit.dookt.com.cntest index[root@openresty01 ~]# curl limit.dookt.com.cn&lt;html&gt;&lt;head&gt;&lt;title&gt;500 Internal Server Error&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=\"white\"&gt;&lt;center&gt;&lt;h1&gt;500 Internal Server Error&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;openresty/1.13.6.2&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; preaccess阶段对连接做限制的limit_req模块 生效阶段：NGX_HTTP_PREACCESS_PHASE阶段 模块：http_limit_req_module 默认编辑进nginx，使用–without-http_limit_req_module禁用该模块 生效算法：leaky bucket算法 生效范围 全部worker进程（基于共享内存） 进入preaccess阶段前不生效 定义共享内存（包括大小），以及key关键字和限制速率， rate单位为r/s或者r/m Syntax: limit_req_zone key zone=name:size rate=rate [sync]; Default: — Context: http 限制并发连接数，burst默认为0，nodelay，对burst请求不再采用延时处理的做法，而是立刻处理 Syntax: limit_req zone=name [burst=number] [nodelay | delay=number]; Default: — Context: http, server, location 限制发生时的日志级别 Syntax: limit_req_log_level info | notice | warn | error; Default: limit_req_log_level error; Context: http, server, location 限制发生时现客户端返回的错误码 Syntax: limit_req_status code; Default: limit_req_status 503; Context: http, server, location Q：limit_req与limit_conn配置同时生效时，哪个有效？ A：limit_req Q：nodelay添加与否，有什么不同？ 123456789101112131415161718#配置一个叫one的共享内存，用来限制客户端访问，未使用brust，默认的限制访问错误码503limit_conn_zone $binary_remote_addr zone=addr:10M;limit_req_zone $binary_remote_addr zone=one:10m rate=2r/m;server &#123; server_name limit.dookt.com.cn; root html; error_log logs/limit-error.log info; location / &#123; limit_conn_status 500; limit_conn_log_level warn; #limit_rate 50; #limit_conn addr 1; #limit_req zone=one burst=3 nodelay; limit_req zone=one; &#125;&#125; 使用curl测试访问，结果如下：访问第二次就不能继续访问了 12345[root@openresty01 ~]# curl limit.dookt.com.cn&lt;h1&gt;Welcome to OpenResty!&lt;/h1&gt;[root@openresty01 ~]# curl limit.dookt.com.cn&lt;h1&gt;503 Service Temporarily Unavailable&lt;/h1&gt; 123456789101112131415161718#配置一个叫one的共享内存，用来限制客户端访问，使用brust，默认的限制访问错误码503limit_conn_zone $binary_remote_addr zone=addr:10M;limit_req_zone $binary_remote_addr zone=one:10m rate=2r/m;server &#123; server_name limit.dookt.com.cn; root html; error_log logs/limit-error.log info; location / &#123; limit_conn_status 500; limit_conn_log_level warn; #limit_rate 50; #limit_conn addr 1; limit_req zone=one burst=3 nodelay; #limit_req zone=one; &#125;&#125; 使用curl测试访问，结果如下：因为使用了burst，会立即处理，所以可以直接访问成功两次 12345678[root@openresty01 ~]# curl limit.dookt.com.cn&lt;h1&gt;Welcome to OpenResty!&lt;/h1&gt;[root@openresty01 ~]# curl limit.dookt.com.cn&lt;h1&gt;Welcome to OpenResty!&lt;/h1&gt;[root@openresty01 ~]# curl limit.dookt.com.cn&lt;h1&gt;503 Service Temporarily Unavailable&lt;/h1&gt; 结果表明使用burst处理会立即处理，不会延时处理 123456789101112131415161718#同时启用限制连接和限制请求（limit_con、limit_req），若返回503则是限制请求生效，若返回500则限制连接生效limit_conn_zone $binary_remote_addr zone=addr:10M;limit_req_zone $binary_remote_addr zone=one:10m rate=2r/m;server &#123; server_name limit.dookt.com.cn; root html; error_log logs/limit-error.log info; location / &#123; limit_conn_status 500; limit_conn_log_level warn; limit_rate 50; limit_conn addr 1; #limit_req zone=one burst=3 nodelay; limit_req zone=one; &#125;&#125; 结论：limit_req在limit_conn之前 access阶段的模块 access模块 auth_basic模块 auth_request模块 其他模块 access阶段：对IP做限制的access模块 生效阶段：NGX_HTTP_ACCESS_PHASH阶段 模块：http_access_module 默认编译进nginx，通过–without-http_access_module禁用功能 生效范围 进入access阶段前不生效 Syntax: allow address | CIDR | unix: | all; Default: — Context: http, server, location, limit_except Syntax: deny address | CIDR | unix: | all; Default: — Context: http, server, location, limit_except 123456#示例 location / &#123; deny 172.16.100.1; allow 172.16.100.0/24; deny all; &#125; access阶段：对用户名和密码做限制的auth_basic模块auth_basic模块的功能 基于HTTP Basic Authutication协议进行用户名密码认证 默认编译进Nginx，通过–without-http_auth_basic_module禁用该模块 auth_basic模块指令 Syntax: auth_basic string | off; #显示的titile Default: auth_basic off; Context: http, server, location, limit_except Syntax: auth_basic_user_file file; Default: — Context: http, server, location, limit_except 生成密码文件 安装依赖包：httpd-tools 生成文件：htpasswd -c file -b user pass 。-c生成一个新文件，不加-c为追加 12345678server &#123; server_name access.dookt.com.cn; location / &#123; satisfy any; auth_basic \"Test auth_basic\"; auth_basic_user_file /usr/local/openresty/nginx/passwd.db; deny all; &#125; 使用elinks或者在浏览器中访问提示输入用户名、密码。必须有输入正确的用户名密码才能访问 access阶段：使用第三方做授权控制的auth_request模块 功能 向上游服务器转发请求，有上游服务返回响应码2xx，则继续执行；若返回401或403，则将响应发给客户端 原理 收到请求后，生成子请求，通过反向代理技术把请求传递给上游服务 默认未编译进nginx，需要使用–with-http_auth_request_module 指令 Syntax: auth_request uri | off; Default: auth_request off; Context: http, server, location Syntax: auth_request_set $variable value; Default: — Context: http, server, location 123456789101112131415161718192021# 172.16.100.11:80server &#123; server_name access.dookt.com.cn; error_log logs/access-error.log debug; location /auth_request &#123; auth_request /test_auth; &#125; location = / &#123; proxy_pass http://127.0.0.1:8090/auth_upstream; proxy_pass_request_body off; proxy_set_header Centenyt-Length \"\"; proxy_set_header X-Original-URI $request_uri; &#125;&#125;# 172.16.100.11:8090 server &#123; listen 8090; location /auth_upstream &#123; return 403 'auth success!\\n'; &#125;&#125; 1234567891011121314151617#此时访问172.16.100.16.11:80[root@openresty01 ~]# curl access.dookt.com.cn -IHTTP/1.1 403 ForbiddenServer: openresty/1.13.6.2Date: Fri, 12 Jul 2019 06:07:47 GMTContent-Type: application/octet-streamContent-Length: 13Connection: keep-alive# 修改172.16.100.11:8090 配置文件中return 200 'auth success!\\n';[root@openresty01 extra]# curl access.dookt.com.cn -IHTTP/1.1 200 OKServer: openresty/1.13.6.2Date: Fri, 12 Jul 2019 06:08:25 GMTContent-Type: application/octet-streamContent-Length: 13Connection: keep-alive access阶段：satisfy指令 Syntax: satisfy all | any; Default: satisfy all; Context: http, server, location 执行顺序 执行一个access模块 如果允许放行，判断satisfy开关 如果时候all，则执行下一个access模块 如果是any，则access阶段放行 如果被拒绝，判断satisfy开关 如果是any，则执行下一个access模块 如果是all，则执行拒绝请求 Q&amp;A环节Q：如果有return指令，access阶段会生效吗？ A：肯定不会，因为return指令在server rewrite或者rewrite阶段，都在access阶段之前 Q：多个access模块的顺序有影响吗？ 查看nginx_module.c &amp;ngx_http_auth_request_module, &amp;ngx_http_auth_basic_module, &amp;ngx_http_access_module, A：肯定是有影响的 Q：输对密码，下面可以访问到文件吗？ 123456location / &#123; satisfy any; auth_basic &quot;test auth_basic&quot; auth_basic_user_file /usr/local/openresty/nginx/passwd.db; deny all;&#125; A：配置satisfy any，只要输对用户名密码就可以访问 Q：如果把deny all提到auth_basic之前呢？ A：还是可以访问的，因为和配置指令的顺序无关 Q：如果改为allow all，有机会输入密码吗？ A：改为allow all，则没有机会输入密码，因为allow all直接同意了 precontent阶段：按序访问资源的try_file模块 Syntax: try_files file…uri; try_files file…=code; Default: — Context: server, location 功能 依次访问多个url对应的文件（由root或者alias指令指定），当文件存在是直接返回文件内容，如果所有文件都不存在，则按最后一个URL结果或者code返回 1234567891011121314151617181920server &#123; server_name tryfiles.dookt.com.cn; error_log logs/tryfiles_error.log info; root html; default_type text/html; location /first &#123; try_files /system/maintenance.html $uri $uri/index.html $uri.html @lasturl; &#125; location @lasturl &#123; return 200 'lasturl!\\n'; &#125; location /second &#123; try_files $uri/index.html $uri.html = 404; &#125;&#125; 使用curl测试访问 /first 和 /second。结果如下与预期一致： 12345678910[root@openresty01 ~]# curl tryfiles.dookt.com.cn/firstlasturl![root@openresty01 ~]# curl tryfiles.dookt.com.cn/second&lt;html&gt;&lt;head&gt;&lt;title&gt;404 Not Found&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=\"white\"&gt;&lt;center&gt;&lt;h1&gt;404 Not Found&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;openresty/1.13.6.2&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; precoppntent阶段：实时拷贝流量的mirror模块处理请求时，生成子请求访问其他服务，对子请求的返回值不作处理 Syntax: mirror uri | off; Default: mirror off; Context: http, server, location Syntax: mirror_request_body on | off; Default: mirror_request_body on; Context: http, server, location content阶段：root和alias指令 Syntax: root path Default: root html; Context: http, server, location, if in location Syntax: alias path; Default: — Context: location alias和root功能及差别： 功能：两者都是将url映射为文件路径，以返回静态文件的内容 差别： root：会将完整的url映射进文件路径中 alias：只会将location后的URL映射到文件路径 1234567891011121314151617181920server &#123; listen 8822; server_name static.dookt.com.cn; location /root &#123; root html; &#125; location /alias &#123; alias html; &#125; location ~ /root/(\\w+\\.txt) &#123; root html/first/$1; &#125; location ~ /alias/(\\w+\\.txt) &#123; alias html/first/$1; &#125; location /RealPath/ &#123; #需要在html目录下做一个软链接，ln -sv first realpath alias html/realpath/; return 200 '$request_filename:$document_root:$realpath_root\\n'; &#125;&#125; 通过curl访问 /root, /root/1.txt, /alias/, /alias/1.txt 1234567891011121314151617181920212223242526272829303132333435363738394041# 访问/root[root@openresty01 ~]# curl alias_root.dookt.com.cn:8822/root&lt;html&gt;&lt;head&gt;&lt;title&gt;404 Not Found&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=\"white\"&gt;&lt;center&gt;&lt;h1&gt;404 Not Found&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;openresty/1.13.6.2&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;# 访问/root/1.txt[root@openresty01 ~]# curl alias_root.dookt.com.cn:8822/root/1.txt&lt;html&gt;&lt;head&gt;&lt;title&gt;404 Not Found&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=\"white\"&gt;&lt;center&gt;&lt;h1&gt;404 Not Found&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;openresty/1.13.6.2&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;curl alias_root.dookt.com.cn:8822/root/&lt;html&gt;&lt;head&gt;&lt;title&gt;404 Not Found&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=\"white\"&gt;&lt;center&gt;&lt;h1&gt;404 Not Found&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;openresty/1.13.6.2&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;# 访问/alias/[root@openresty01 ~]# curl alias_root.dookt.com.cn:8822/alias/&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to OpenResty!&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to OpenResty!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;# 访问/alias/1.txt[root@openresty01 ~]# curl alias_root.dookt.com.cn:8822/alias/1.txttest1 static模块提供的3个变量Q：当我们访问 /RealPath/1.txt时，这三个变量的值各为多少？ request_filename：待访问文件的完整路径 document_root：由URI和root/alias规则生成的文件夹的路径 realpath_root：将document_root中的软连接换成真实路径 123#使用curl访问RealPath/1.txt，其实是访问html/first/1.txt[root@openresty01 ~]# curl static.dookt.com.cn:8822/RealPath/1.txt/usr/local/openresty/nginx/html/realpath/1.txt:/usr/local/openresty/nginx/html/realpath/:/usr/local/openresty/nginx/html/first 静态文件返回的content-type Syntax: types { … } Default: types { text/html html; image/gif gif; image/jpeg jpg; } Context: http, server, location Syntax: default_type mime-type; Default: default_type text/plain;` Context: http, server, location Syntax: types_hash_bucket_size size; Default: types_hash_bucket_size 64; Context: http, server, location Syntax: types_hash_max_size size; Default: types_hash_max_size 1024; Context: http, server, location static模块url不以斜杆结尾却访问目录的做法Q：访问目录时URL最后没有带 / ? static模块实现了root / alias 功能时，发现访问目标是目录，但是URL末尾加上 / 时，会返回301错误 重定向跳转的域名 Syntax: server_name_in_redirect on | off; Default: server_name_in_redirect off; Context: http, server, location | Syntax: | port_in_redirect on | off; || :——- | —————————- || Default: | port_in_redirect on; || Context: | http, server, location | | Syntax: | absolute_redirect on | off; || :——- | —————————– || Default: | absolute_redirect on; || Context: | http, server, location | 123456789101112131415161718192021222324252627282930313233343536#配置1，关闭主域名显示server &#123; server_name return.dookt.com.cn dir.dookt.com.cn; server_name_in_redirect on; #显示重定向域名中的server_name还是host头部的主机名 listen 8081; port_in_redirect on; #打开访问时输入的重定向端口 absolute_redirect on; #打开访问时输入的重定向域名 root html/;&#125;#配置2，关闭端口显示server &#123; server_name return.dookt.com.cn dir.dookt.com.cn; server_name_in_redirect off; listen 8081; port_in_redirect off; #关闭访问时输入的重定向端口 absolute_redirect on; #打开访问时输入的重定向域名 root html/;&#125;#配置3,开启显示重定向域名中的server_name为配置文件中的server_nameserver &#123; server_name return.dookt.com.cn dir.dookt.com.cn; server_name_in_redirect on; listen 8081; port_in_redirect off; absolute_redirect on; root html/;&#125;#配置4，关闭所有显示（域名+端口）server &#123; server_name return.dookt.com.cn dir.dookt.com.cn; server_name_in_redirect on; listen 8081; port_in_redirect on; absolute_redirect off; #关闭绝对重定向 root html/;&#125; 123456789101112131415161718192021222324252627282930313233343536373839#配置1，运行结果[root@openresty01 ~]# curl static.dookt.com.cn:8081/first -IHTTP/1.1 301 Moved PermanentlyServer: openresty/1.13.6.2Date: Fri, 12 Jul 2019 09:48:25 GMTContent-Type: text/htmlContent-Length: 191Location: http://static.dookt.com.cn:8081/first/ #此时访问header头部有域名和端口号Connection: keep-alive#配置2,运行结果[root@openresty01 ~]# curl static.dookt.com.cn:8081/first -IHTTP/1.1 301 Moved PermanentlyServer: openresty/1.13.6.2Date: Fri, 12 Jul 2019 09:51:33 GMTContent-Type: text/htmlContent-Length: 191Location: http://static.dookt.com.cn/first/ #此时访问header头部只有域名，没有端口信息Connection: keep-alive#配置3，运行结果[root@openresty01 ~]# curl static.dookt.com.cn:8081/first -IHTTP/1.1 301 Moved PermanentlyServer: openresty/1.13.6.2Date: Fri, 12 Jul 2019 09:55:02 GMTContent-Type: text/htmlContent-Length: 191Location: http://return.dookt.com.cn/first/ #此时访问header头部修改为配置文件中定义的server_nameConnection: keep-alive#配置4，运行结果[root@openresty01 ~]# curl static.dookt.com.cn:8081/first -IHTTP/1.1 301 Moved PermanentlyServer: openresty/1.13.6.2Date: Fri, 12 Jul 2019 09:57:43 GMTContent-Type: text/htmlContent-Length: 191Connection: keep-aliveLocation: /first/ #此时访问header头部只有/first/，没有域名模和端口 content阶段的：index和autoindex模块 index模块 功能：指定 / 访问时返回index文件的内容 模块：ngx_http_index_module Syntax: index file …; Default: index index.html; Context: http, server, location autoindex模块 功能：当URL以 / 结尾时，尝试以html/xml/json/jsonp等格式返回root/alias中指定目录的目录结构 模块：ngx_http_autoindex_module，默认编译进nginx，使用–without-ngx_http_autoindex_module禁用该模块 autoindex指令 Syntax: autoindex on | off; Default: autoindex off; Context: http, server, location Syntax: autoindex_exact_size on | off; Default: autoindex_exact_size on; Context: http, server, location Syntax: autoindex_format html | xml | json | jsonp; Default: autoindex_format html; Context: http, server, location Syntax: autoindex_localtime on | off; Default: autoindex_localtime off; Context: http, server, location 12345678910111213# 配置autoindexserver &#123; server_name autoindex.dookt.com.cn; listen 8999; location / &#123; alias html/; autoindex on; index a.html; autoindex_exact_size off; autoindex_format json; autoindex_localtime on; &#125;&#125; 12345678910[root@openresty01 ~]# curl autoindex.dookt.com.cn:8999[&#123; \"name\":\"first\", \"type\":\"directory\", \"mtime\":\"Thu, 11 Jul 2019 22:29:53 GMT\" &#125;,&#123; \"name\":\"realpath\", \"type\":\"directory\", \"mtime\":\"Thu, 11 Jul 2019 22:29:53 GMT\" &#125;,&#123; \"name\":\"second\", \"type\":\"directory\", \"mtime\":\"Thu, 11 Jul 2019 22:30:02 GMT\" &#125;,&#123; \"name\":\"third\", \"type\":\"directory\", \"mtime\":\"Thu, 11 Jul 2019 22:30:11 GMT\" &#125;,&#123; \"name\":\"403.html\", \"type\":\"file\", \"mtime\":\"Thu, 11 Jul 2019 21:58:47 GMT\", \"size\":245 &#125;,&#123; \"name\":\"50x.html\", \"type\":\"file\", \"mtime\":\"Thu, 04 Jul 2019 07:43:58 GMT\", \"size\":541 &#125;,&#123; \"name\":\"index.html\", \"type\":\"file\", \"mtime\":\"Thu, 04 Jul 2019 07:43:58 GMT\", \"size\":649 &#125;] content阶段：concat模块 功能：当需要访问多个小文件时，把他们的内容合并到一次http请求中返回，提升性能 模块：ngx_http_concat_module 模块地址（https://github.com/alibaba/nginx-http-concat）: –add-moudle=../nginx-http-concat/ 使用：在URI后加上 ?? ，后通过多个 , 号分隔文件。如果还有参数，则在最后通过 ? 添加参数 12345wget -c https://github.com/alibaba/nginx-http-concat/archive/master.ziptar -xvf master.zipmv nginx-http-concat-master/ nginx-http-concat./configure --add-module=../nginx-http-concat/ gmake &amp;&amp; gmake install concat: on| off Default: concat off Context: http, server, location concat_type: `MIME types Default: concat_types:text/css application/x-javascript Context: http, server, location concat_unique: on| off Default: conca_unique on Context: http, server, location concat_max_files: `numberp Default: conca_max_files 10 Context: http, server, location concat_delimiter: string Default: NONE Context: http, server, location concat_ignore_file_error: on| off Default: off Context: http, server, location 123456789101112131415server &#123; listen 8998; server_name concat.dookt.com.cn; error_log logs/concat_error.log debug; concat on; # 开启concat root html; location /concat &#123; concat_max_files 20; #对多合并多少个文件 concat_types text/plain; #对文本文件进行合并 concat_unique on; #对一种还是多种文件进行分隔 concat_delimiter ':::'; #设置文件内容分隔符 concat_ignore_file_error on; #若文件不存在则返回其他文件的内容 &#125;&#125; 使用curl命令访问，结果如下 1234#结果输出1.txt和2.txt的内容，并以:::分隔文件内容[root@openresty01 ~]# curl concat.dookt.com.cn:8998/concat/??1.txt,2.txtThis is 1.txt content:::This is 2.txt content log阶段：access日志的用法 功能：将HTTP请求信息记录到日志中 模块：nginx_http_log_module，不能禁用该模块 log_format指令 Syntax: log_format name [escape=default|json|none] string …; Default: log_format combined &quot;...&quot;; Context: http 默认的日志格式123log_format combined '$remote_addr - $remote_user [$time_local] ' '\"$request\" $status $body_bytes_sent ' '\"$http_referer\" \"$http_user_agent\"'; 日志文件格式 Syntax: access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]];access_log off; Default: access_log logs/access.log combined; Context: http, server, location, if in location, limit_except path 路径可以包含变量：不打开cache是每记录一条日志都需要打开、关闭日志文件 if 通过变量值控制请求日志是否记录 日志缓存 功能：批量将内存中的日志写入磁盘 写入磁盘的条件 所有待写入磁盘的日志大小超出缓存大小 达到flush指定的过期时间 worker进程执行reopen命令，或者正在关闭 日志压缩 功能：批量压缩内存中的日志，在写入磁盘 buffer大小默认为64KB 压缩级别默认为1（1最快压缩率最低，9压缩最慢压缩率最高） 日志文件名包含变量的优化 Syntax: open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time];open_log_file_cache off; Default: open_log_file_cache off; Context: http, server, location max：缓存内的最大文件句柄数，超出后用LRU算法淘汰 inactive：文件访问完后这段时间内不会关闭。默认10秒 min_uses：在inactive时间内使用次数超过min_uses才会继续存在内存中，默认为1 valid：超出valid时间后，将对缓存的日志文件检查是否存在。默认60秒 off：关闭缓存功能 HTTP过滤模块的调用流程HTTP过滤模块介绍log阶段之前，content阶段之后处理的 copy_filter：复制包体的内容 postpone_filter：处理子请求 header_filter：构造响应头部 write_filter：发送响应 HTTP过滤模块：替换修改响应内容的sub模块 功能：将响应中指定的字符串替换成新的字符串 模块：ngx_http_sub_module模块。默认为编译进nginx，使用 –with-http_sub_module启用该模块 指令： 需要把返回给用户中响应中的匹配上的字符串替换成新的字符串 Syntax: sub_filter string replacement; Default: — Context: http, server, location ​ 是否需要把上次修改字符串的时间显示出来 Syntax: sub_filter_last_modified on | off; Default: sub_filter_last_modified off; Context: http, server, location ​ 是否只修改一次（on），或者全部修改(off) Syntax: sub_filter_once on | off; Default: sub_filter_once on; Context: http, server, location ​ 只是针对什么样的响应才修改，可以设置为*，但是效率太低 Syntax: sub_filter_types mime-type …; Default: sub_filter_types text/html; Context: http, server, location 1234567891011#若不使用sub模块显示的是openresty的默认欢迎主页，此时修改若匹配到openresty.com、openresty.org就替换为主机域名（配置文件中定义的）/nginx，server &#123; server_name sub.dookt.com.cn; error_log logs/sub-error.log info; location / &#123; sub_filter 'openresty.org' '$host/openresty'; sub_filter 'openresty.com' '$host/openresty'; sub_filter_once off; sub_filter_last_modified on; #开启在header头部添加上Last-Modified的时间 &#125;&#125; 1234567891011121314151617181920212223242526#未添加sub配置的效果[root@openresty01 ~]# curl sub.dookt.com.cn &lt;h1&gt;Welcome to OpenResty!&lt;/h1&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href=\"https://openresty.org/\"&gt;openresty.org&lt;/a&gt;.&lt;br/&gt;Commercial support is available at&lt;a href=\"https://openresty.com/\"&gt;openresty.com&lt;/a&gt;.&lt;/p&gt;#添加sub配置的效果[root@openresty01 ~]# curl sub.dookt.com.cn &lt;h1&gt;Welcome to OpenResty!&lt;/h1&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href=\"https://sub.dookt.com.cn/openresty/\"&gt;openresty.org&lt;/a&gt;.&lt;br/&gt;Commercial support is available at&lt;a href=\"https://sub.dookt.com.cn/openresty/\"&gt;openresty.com&lt;/a&gt;.&lt;/p&gt;###可以发现添加sub配置后openresty.org、openresty.com都替换为了sub.dookt.com.cn/openresty[root@openresty01 ~]# curl sub.dookt.com.cn -IHTTP/1.1 200 OKServer: openresty/1.13.6.2Date: Fri, 12 Jul 2019 13:23:15 GMTContent-Type: text/htmlLast-Modified: Thu, 04 Jul 2019 07:43:58 GMT #添加上替换的时间Connection: keep-aliveETag: W/\"5d1dae3e-289\" HTTP过滤模块：在响应前后添加内容的addition模块 功能：在响应前或后正价内容，而增加内容的方式是通过新增子请求的响应完成 模块：ngx_http_addition_module，默认为编译进nginx，使用–with-http_addtion_module启用该模块 指令： 在响应前添加内容，根据uri响应的内容，返回在子请求之前 Syntax: add_before_body uri; Default: — Context: http, server, location ​ 在响应后添加内容，根据uri响应的内容，返回在子请求之后 Syntax: add_after_body uri; Default: — Context: http, server, location ​ 允许添加的响应类型，可以使用*，但是效率太低 Syntax: addition_types mime-type …; Default: addition_types text/html; Context: http, server, location 12345678910111213141516server &#123; server_name addition.dookt.com.cn; error_log logs/addition-error.log info; location / &#123; add_before_body /before_action; #配置add_before_body add_after_body /after_action; #配置add_after_body addition_types *; &#125; location /before_action &#123; return 200 'new content before!\\n'; #访问/before_action，则返回\"new content before!\\n\" &#125; location /after_action &#123; return 200 'new content after!\\n'; #访问/after_action，则返回\"new content after!\\n\" &#125;&#125; 使用curl测试结果 12345678#若没有配置addition（即注释add_before_body、add_after_body两个配置），结果如下：[root@openresty01 ~]# curl addition.dookt.com.cn/a.txtThis is a.txt content! #内容为html/a.txt文件的内容#添加addition配置后结果如下[root@openresty01 ~]# curl addition.dookt.com.cn/a.txtnew content before!This is a.txt content!new content after! Nginx变量Nginx变量的运行原理 变量 提供变量的模块（preconfiguration中定义新变量）—定义规则 变量名 解析出变量的方法 使用变量的模块 解析nginx.conf是定义的变量使用方式 处理请求 性求值：变量值可以时刻变化，其值为使用的那一刻的值 存放变量的哈希表 Syntax: variables_hash_bucket_size size; Default: variables_hash_bucket_size 64; Context: http Syntax: variables_hash_max_size size; Default: variables_hash_max_size 1024; Context: http HTTP框架提供的变量 HTTP请求相关的变量 arg_参数名：URL中某个具体参数的值 query_string：与args变量完全相同 args：全部URL参数 is_args：如果请求URL中有参数则返回？否则返回空 content_length：HTTP请求标识包体长度的centent-length头部的值 content_type：表示请求包体的content_type头部的值 uri：请求的URI（不同于URL，不包括后面的参数） document_uri：与 uri 完全相同 request_uri：请求的URL（包括URI以及完整的参数） scheme：协议名，例如HTTP或者HTTPS request_mothod：请求方法，例如GET或者POST request_length：请求内容的大小，包括请求行、头部、包体等 remote_user：由HTTP Basic Authentication协议传入的用户名 remote_body_file：临时存放请求包体的文件 如果包体非常小则不会存文件 client_body_in_file_only强制所有包体存入文件，且可决定是否删除 request_body：请求的包体，这个变量当且仅当使用反向代理，且设定用内存暂存包体时才有效 request：用户原始的url请求，含有方法与协议版本，例如GET/?a=1&amp;b=22 HTTP/1.1 host：先从请求行中获取，若含有Host头部，则用其值替换掉请求行中的主机名，若前二者都没有，则使用匹配上的server_name http_头部名字： 通用：返回一个具体请求的头部的值（从用户请求的header中取）： 特殊（特殊处理）： http_host http_user_agent http_referer http_via http_x_forwarded_for http_cookie 1234567891011121314151617181920212223242526#变量值server &#123; listen 8098; server_name var.dookt.com.cn; error_log logs/var-error.log info; location / &#123; set $limit 10k; return 200 'arg_a: $arg_a, arg_b: $arg_b, args: $argsconnection: $connection, connection_requests: $connection_requestscookie_a: $cookie_auri: $uri, document_uri: $document_uri, request_uri: $request_urirequest: $requestrequest_id: $request_idserver: $server_addr, $server_name, $server_port, $server_protocoltcpinfo:$tcpinfo_rtt, $tcpinfo_rttvar, $tcpinfo_snd_cwnd, $tcpinfo_rcv_spacelimit_rate: $limit_ratehostname: $hostnamecontent_length: $content_lengthstatus: $statusbody_bytes_sent: $body_bytes_sent, bytes_sent: $bytes_senttime: $request_time. $msec, $time_iso8601, $time_local'; &#125;&#125; 12345678910111213141516[root@openresty01 ~]# curl -H 'Content-Length: 0' -H 'Cookie: a=c1' 'var.dookt.com.cn:8098?a=1&amp;b=23'arg_a: 1, arg_b: 23, args: a=1&amp;b=23connection: 27, connection_requests: 1cookie_a: c1uri: /, document_uri: /, request_uri: /?a=1&amp;b=23request: GET /?a=1&amp;b=23 HTTP/1.1request_id: a3e628a8f23f54c90c1a1481e1814600server: 172.16.100.11, var.dookt.com.cn, 8098, HTTP/1.1tcpinfo:0, 0, 10, 43690limit_rate: 0hostname: openresty01content_length: 0status: 200body_bytes_sent: 0, bytes_sent: 0time: 0.000. 1562944594.627, 2019-07-12T23:16:34+08:00, 12/Jul/2019:23:16:34 +0800 TCP连接相关的变量 binary_remote_addr：客户端地址的整形格式，对于IPV4是4字节，IPv6是16字节 connection：递增的连接序号 connection_reqeuests：当前连接上执行过的请求数，对keepalived连接有意义 remote_addr：客户端地址 remote_port：客户端端口 proxy_protocol_addr：若使用了proxy_protocol协议则返回协议中的地址，否则返回为空 proxy_protocol_port：若使用了proxy_protocol协议则返回协议中的端口，否则返回为空 server_addr：服务器的地址 server_port：服务器的端口 TCP_INFO：tcp内核蹭参数，包括$tcpinfo_rtt, $tcpinfo_rttvar, $tcpinfo_snd_cend, $tcpinfo_rcv_space server_protocol：服务器协议，例如HTTP/1.1 Nginx处理请求过程中产生的变量 request_time：请求处理到现在的耗时，单位是s，精确到ms server_name：匹配请求上的server_name值 https：如果开启了TLS/SSL，则返回no，否则返回空 request_completion：若请求处理完则返回OK，否则返回空 request_id：以16进制输出的请求标识id，该id共含有16个字节，是随机的 request_filename：待访问文件的完整路径 document_root：由URI和root/alias规则生成的文件夹路径 realpath_root：将document_root中的软连接换成真实的路径 limit_rate：返回客户端响应时的速度上限，单位为每秒字节数。可以通过set指令修改 发送HTTP响应时相关的变量 body_bytes_sent：响应中body包体的长度 byte_sent：全部http响应的长度 status：http响应中的返回码 sent_trailer_名字：把响应结尾内容里的值返回 sent_http_头部名字：响应中某个具体头部的值 通用：返回什么头部就取什么头部的值 特殊：需要特殊处理 sent_http_content_type sent_http_content_length sent_http_loction sent_http_last_modified sent_http_connection sent_http_keep_alive sent_http_transfer_encoding sent_http_cache-control sent_http_link Nginx系统变量 time_local：以本地标准输出的当前时间， 例如：12/Jul/2019:23:44:50 +0800 time_iso8601：使用ISO8601标准输出的时间 ，例如：2019-07-12T23:44:50+08:00 nginx_version：Nginx版本号 pid：所属的worker进程id pipe：使用了管道则返回p，否则返回 . hostname：所在服务器的主机名，与hostname命令输出一致 msec：1760年1月1日到现在的时间，单位为秒，小数点后精确到毫秒， 例如：1562946290.424s referer模块 场景：当某个网站通过url引用你的页面，当用户在浏览器上点击url时，http请求的头部会通过referer头部。将该网站当前页面的url带上，告诉服务器本次请求是由这个页面发起的 目的：拒绝非正常的网站访问我们的站点资源 思路：通过referer模块，用invaild_referer变量根据判断referer头部是否合法 refer模块：默认编译进nginx，使用–without-http_referer_module禁用该模块 指令： Syntax: valid_referers none | blocked | server_names | string …; Default: — Context: server, location Syntax: referer_hash_bucket_size size; Default: referer_hash_bucket_size 64; Context: server, location Syntax: referer_hash_max_size size; Default: referer_hash_max_size 2048; Context: server, location valid_referers指令 参数值： none：允许缺失referer头部的请求访问 block：允许referer头部没有对应的值的请求访问 server_names：若referer中站点域名与server_name中本机域名某个匹配，则允许该请求访问 表示域名及URL的字符串，对应域名可在前缀或者后缀中含有*通配符 若referer头部的值匹配字符串后，则允许访问 正则表达式 若referer头部的值匹配正则表达式后，则允许访问 invalid_referers变量 允许访问时变量值为空 不允许访问时的变量值为1 1234567891011121314151617server &#123; server_name referer.dookt.com.cn; error_log logs/referer-error.log debug; root html; location / &#123; valid_referers none blocked server_names *.dookt.com.cn www.dookt.org/nginx/ ~\\.google\\.; if ($invalid_referer) &#123; return 403; &#125; return 200 'valid!\\n'; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334[root@openresty01 ~]# curl -H 'referer: http://www.dookt.org/' referer.dookt.com.cn/&lt;html&gt;&lt;head&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=\"white\"&gt;&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;openresty/1.13.6.2&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;[root@openresty01 ~]# curl -H 'referer: http://www.dookt.org/nginx' referer.dookt.com.cn/&lt;html&gt;&lt;head&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=\"white\"&gt;&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;openresty/1.13.6.2&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;[root@openresty01 ~]# curl -H 'referer: http://www.dookt.org/nginx/' referer.dookt.com.cn/valid![root@openresty01 ~]# curl -H 'referer: ' referer.dookt.com.cn/ valid![root@openresty01 ~]# curl referer.dookt.com.cn/valid![root@openresty01 ~]# curl -H 'referer: http://referer.dookt.com.cn' referer.dookt.com.cn/valid![root@openresty01 ~]# curl -H 'referer: http://images.baidu.com/search/detail' referer.dookt.com.cn/&lt;html&gt;&lt;head&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=\"white\"&gt;&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;openresty/1.13.6.2&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;[root@openresty01 ~]# curl -H 'referer: http://images.google.com/search/detail' referer.dookt.com.cn/valid! 防盗链secure_link模块 功能：通过验证URL中的哈希值的方式防盗链 过程： 由某服务器（可以是nginx）生成加密后的安全链接url，返回给客户端 客户端使用安全url访问nginx，由nginx的secure_link变量判断是否验证通过 变量： sercure_link secure_link_expires 模块：默认没有编译进nginx，需要通过–with-http_secure_link_module添加该模块 原理： 哈希算法是不可逆的 客户端只能拿到执行过哈希算法的URL 仅生成URL的服务器和验证URL是否安全的nginx，才保存执行哈希前的原始字符串 原始字符串通常由以下部分有序组成： 资源位置：例如HTTP中指定资源的URI，防止拿到一个安全的URL后可以访问任意资源 用户信息：例如用户的IP地址，限制其他用户盗用URL 时间戳：使安全URL及时过期 密钥：仅服务器端拥有，增加攻击者猜测出原始字符串的难度 Syntax: secure_link expression; Default: — Context: http, server, location Syntax: secure_link_md5 expression; Default: — Context: http, server, location Syntax: secure_link_secret word; Default: — Context: location 变量 secure_link 值为空：验证不通过 值为0：URL过期 值为1：验证通过 secure_link_rxpires 时间戳的值 变量值带过期时间的配置实例命令行生成安全链接 原请求： /test1.txt?md6=md5生成值&amp;expires=时间戳（如2147483647） 生成md5 echo -n ‘时间戳URL客户端IP密钥’|openssl md5 -binary | openssl base64 | tr +/ - |tr -d = Nginx配置12secure_link $arg_md5,arg_expires;secure_link_mk5 \"$secure_link_expires$uri$remote_addr secret\"; 12345678910111213141516#配置文件server &#123; server_name securelink.dookt.com.cn; error_log logs/secure-error.log info; default_type text/plain; location / &#123; secure_link $arg_md5,$arg_expires; secure_link_md5 \"$secure_link_expires$uri$remote_addr secret\"; if ($secure_link = \"\") &#123; return 403; &#125; if ($secure_link = \"0\" ) &#123; return 410; &#125; return 200 '$secure_link:$secure_link_expires\\n'; &#125; 12345#测试，结果如下 [root@openresty01 ~]# echo -n '2147483647/test1.txt172.16.100.11 secret'|openssl md5 -binary | openssl base64 | tr +/ - |tr -d = #生成md5OpVufjJNnc5LIAT-jJZH7A[root@openresty01 ~]# curl 'securelink.dookt.com.cn/test1.txt?md5=OpVufjJNnc5LIAT-jJZH7A&amp;expires=2147483647' 1:2147483647 仅对URI进行哈希的简单办法 原理： 将请求的URI分为三个部分：/prefix/hash/link hash生成方式 对”link密钥”做md5哈希求值 用secure_link_secret secret; 配置密钥 命令行生成安全链接 原请求： link 生成的安全请求 /prefix/md5/link 生成md5 echo -n ‘linksecret’ | openssl md5 -hex Nginx配置 secure_link_secret secret; 1234[root@openresty01 ~]# echo -n 'test1.txtmysecret2' | openssl md5 -hex (stdin)= c3f9b32bf901b04c052ea9511e29a918[root@openresty01 extra]# curl 'securelink.dookt.com.cn/p/c3f9b32bf901b04c052ea9511e29a918/test1.txt'This is test1.txt content! 为复杂业务生成新的变量：map模块 功能：基于已有变量，使用类似switch {case:… default: …}的语法创建新变量，为其他基于变量值实功能的模块提供更能多可能性 模块：默认编译进nginx，通过–without-http_map_module禁用该模块 map模块的指令 Syntax: map string $variable { … } Default: — Context: http Syntax: map_hash_bucket_size size; Default: map_hash_bucket_size 32|64|128; Context: http Syntax: map_hash_max_size size; Default: map_hash_max_size 2048; Context: http map模块：通过映射新变量提供更多可能性 已有变量 字符串 一个或者多个变量 字符与字符串的组合已有变量： case规则 字符串严格匹配 使用hostname指令，可以对域名使用前缀 * 泛域名匹配 使用hostname指令，可以对域名使用后缀 * 泛域名匹配 ~ 和 ~* 正则表达式匹配，后者忽略大小写 default规则 没有匹配到任何规则时，使用default 缺失default时，返回空字符串给新变量 其他 使用include语法提升可读性 使用volatile禁止变量值缓存 Q &amp; A 环节演示实例Q：对以下配置，当以下请求发生时，name变量值是？ ‘Host: map.dookt.com.cn’ ‘Host: map.dook123.com.cn’ ‘Host: map.dookt.com.cn’ ‘Host: map.dookt.org’ 123456789101112131415161718192021#注意ma指令生效范围httpmap $http_host $name &#123; hostnames; default 0; ~map\\.doo\\w+\\.com.cn 1; *.dookt.com.cn 2; map.dookt.com.cn 3; map.dookt.* 4; &#125; map $http_user_agent $mobile &#123; default 0; \"Opera Mini\" 1; &#125; server &#123; listen 10001; default_type text/plain; location / &#123; return 200 '$name:$mobile\\n'; &#125; &#125; 12345678910[root@openresty01 ~]# curl -H 'Host: www.dookt.com.com' 127.0.0.1:100010:0[root@openresty01 ~]# curl -H 'Host: www.dookt.com.cn' 127.0.0.1:10001 2:0[root@openresty01 ~]# curl -H 'Host: map.dookt.com.cn' 127.0.0.1:10001 3:0[root@openresty01 ~]# curl -H 'Host: map.dook123.com.cn' 127.0.0.1:10001 1:0[root@openresty01 ~]# curl -H 'Host: map.dookt.com' 127.0.0.1:10001 4:0 通过变量指定少量用户实现AB测试：split_client 功能：主要用于实现AB测试，产品不太确定的推出的功能用户是否接受，所以推出多个版本的功能，某个百分比的的用户去尝试某版本的功能，来看反馈，决定使用哪个版本 模块：ngx_http_split_clients_module，默认编译进nginx，通过–without-http_split_clients_module禁用该模块 规则： 已有变量 字符串 一个或多个变量 变量与字符串组合 case规则 xx.xx%，支持小数点后2位，所有项的百分比相加不超过100% *，由它匹配剩余的百分比（100%减去以上项相加的百分比） 基于已有变量创建新变量，为其他AB变量测试提供更能多可能性 对已有变量的值执行MurmurHash2算法得到32位整形哈希数字，记为hash 32位无符号整形的最大数字2^32 -1，记为max 哈希数字与最大数字相除hash/max，可以得到百分比percent 配指令中指示了各项百分比构成的范围，如0-1%，1-5%等，及范围对应的值就当percent落在那个范围里，新变量的值就对应其后的参数 split_client模块的指令 Syntax: split_clients string $variable { … } Default: — Context: http Q：以下配置是否有问题？ 1234567split_clients \"$&#123;http_testcli&#125;AAA\" $variant &#123; 0.51% .one; 20.0% .two; 50.5% .three; 40.0% .four; * \"\";&#125; A：该配置是有问题的，百分比总和超过100% 12345678910111213141516split_clients \"$&#123;http_testcli&#125;\" $variant &#123; #从头部取值，如果用户头部传了testcli，就取http_testcli的值 0.51% .one; 20.0% .two; 50.5% .three; #40% .four; * \"\"; &#125; server &#123; server_name split_client.dookt.com.cn; error_log log/split_client-error.log debug; default_type text/plain; location / &#123; return 200 'ABtestfile$variant\\n'; &#125; &#125; 12345#此处使用curl -H传入testcli到header中，通过修改不同的哈希值，来实现测试[root@openresty01 ~]# curl -H 'testcli:4895768sdfasdgaga907567*&amp;*&amp;*&amp;48546456734579' split_clients.dookt.com.cn:10002/ABtestfile.three[root@openresty01 ~]# curl -H 'testcli:4895768sdfasdgagasdf9sdfsdsf' split_clients.dookt.com.cn:10002/ ABtestfile.two 根据IP地址范围的匹配生成新的变量：geo模块 Syntax: geo [$address] $variable { … } Default: — Context: http 功能：根据IP地址创建新的变量 模块：ngx_http_geo_module，默认编译进nginx，使用–without-http_geo_module禁用该模块 规则： 如果geo指令后不输入$address，那么默认使用$remote_addr变量地址作为IP地址 {} 内指令匹配：优先最长匹配 通过IP地址及子网掩码的方式，定义IP范围，当IP地址在范围内时新变量使用其后的参数值 default指定了当以上范围都未匹配上时。新变量的默认值。 通过proxy指令指定可信地址（realip模块），此时remote_addr为X-Forwarded-For头部值中最后一个IP地址 proxy_recursive允许循环地址搜索 include，优化可读性 delete删除指定网络 Q &amp; A 环节及实例Q：以下命令执行时，变量country的值各为多少（proxy为客户端地址）？ 123curl -H 'X-Forwarded-For: 10.1.0.0, 127.0.0.2' geo.dookt.com.cncurl -H 'X-Forwarded-For: 10.1.0.0, 127.0.0.1' geo.dookt.com.cncurl -H 'X-Forwarded-For: 10.1.0.0, 127.0.0.2,,1.2.3.4' geo.dookt.com.cn 12345678910111213141516#配置文件geo $country &#123; default ZZ; proxy 172.16.100.11; #定义了$address,不使用$remote_addr变量地址作为IP地址 127.0.0.0/24 US; 127.0.0.1/32 RU; 10.1.0.0/16 RU; 172.16.1.0/24 UK; &#125; server &#123; listen 10003; server_name geo.dookt.com.cn; location / &#123; return 200 '$country\\n'; &#125; &#125; 12345678[root@openresty01 ~]# curl -H 'X-Forwarded-For: 10.1.0.0,127.0.0.1,172.16.1.123' geo.dookt.com.cn:10003UK[root@openresty01 ~]# curl -H 'X-Forwarded-For: 10.1.0.0' geo.dookt.com.cn:10003 RU[root@openresty01 ~]# curl -H 'X-Forwarded-For: 10.1.0.0,127.0.0.1' geo.dookt.com.cn:10003RU[root@openresty01 ~]# curl -H 'X-Forwarded-For: 10.1.0.0,127.0.0.1,1.2.3.4' geo.dookt.com.cn:10003ZZ 使用变量获取用户的地理位置：geoip模块基于MaxMind数据库从客户端地址获取变量 功能：根据IP地址创建新变量 模块：ngx_http_geoip_module，默认未编译进nginx，通过–with-http_geoip_module禁用该模块 流程： 安装Maxmind里的geoip的C开发库（https://dev.maxmind.com/geoip/legacy/downloadable/） 编译时nginx要带上–with-http_geoip_module参数 下载geoip_country或者geoip_city指令配置好nginx.conf 运行（升级Nginx） geoip_country指令提供的变量 变量 $geoip_country_code：两个字母的国家代码，如CN或US $geoip_country_code3：三个字母的国家代码。如CHN或USA $geoip_country_name：国家名称，如’China’，’United Stated’ Syntax: geoip_country file; Default: — Context: http Syntax: geoip_proxy address | CIDR; Default: — Context: http geoip_city指令提供的变量 变量 $geoip_latitude：纬度 $geoip_longitide：经度 $geoip_city_continent_code：属于全球哪个州，如EU或AS 与geoip_country指令生成的变量重叠 $geoip_city_country_code：两个字的国家代码，如CN或US $geoip_city_country_code2：三个字的国家代码，如CHN或USA $geoip_city_country_name：两个字的国家代码，如 China或 United States $geoip_region：洲或省的编码。如02 $geoip_region_name：洲或省名称，如Zhejiang或Saint Pertersburg $geoip_city：城市名 $geoip_postal_code：邮编号 Syntax: geoip_city file; Default: — Context: http Nginx对客户端使用keepalived特性提升连接效率 功能：多个HTTP请求通过复用TPC连接实现一下功能： 减少握手次数 减少通过并发连接数减少了服务器资源的消耗 降低TCP拥塞控制的影响 协议： connection头部：取值为close或者keepalive，前者表示请求处理完即关闭连接，后者表示复用连接处理的下一条请求 Keep-Alive头部：其值为timeout=n，后面的数字n单位是秒，告诉客户端连接至少保留n秒 keepalive行为控制的指令 Syntax: keepalive_disable none | browser …; Default: keepalive_disable msie6; Context: http, server, location Syntax: keepalive_requests number; Default: keepalive_requests 100; Context: http, server, location Syntax: keepalive_timeout timeout [header_timeout]; Default: keepalive_timeout 75s; Context: http, server, location","tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://www.dookt.com/tags/Nginx/"}]},{"title":"Nginx-反向代理与负载均衡","date":"2019-07-25T13:38:23.000Z","path":"post/6325.html","text":"Nginx反向代理与负载均衡负载均衡 客户端 Nginx 应用服务器1（正常） 应用服务器2（宕机） 应用服务器3（正常） 应用服务器4（扩容） Nginx在AKF扩展立方体的应用 水平扩展（X轴扩展）：基于Round-Robin或者least-connected算法分发请求，不能解决单台数据量大的问题 纵向扩展（Y轴扩展）：基于URL对功能进行分发，需要一台处理的功能，用两台来处理。需要做重构。能够解决数据量上升的问题 竖向扩展（Z轴扩展）：将用户的IP地址或其他信息映射到某个特定的服务或者集群，如CDN 负载均衡策略：round-robin Syntax: upstream name { … } Default: — Context: http Syntax: server address [parameters]; Default: — Context: upstream 指定上游服务地址的upstream与server指令 功能：指定一组上游服务地址，其中，地址可以是域名、IP地址或者unix socket地址。可以在域名或者IP地址后添加端口，如不添加则默认80端口 通用参数： backup：指定当前server为备份服务，仅当非备份服务不可用时，请求才会到该server down：标识此台服务已下线，不再提供服务 加权Round-Robin负载均衡算法 功能： 使用加权轮训的方式访问server指令指定的上游服务 集成在Nginx的upstream框架中 指令： weight：服务的权重，默认为1 max_conns：server的最大并发连接数，仅作用于单worker进程。默认是0，表示没有限制 max_fails：在fail_timeout时间段内，最大的失败次数。当达到最大失败数时，会在fail_timeout秒内这台server不允许再次被选择 fail_timeout： 单位为秒，默认10s，具有两个功能： 指定一段时间后，最大的失败次数为max_fails 到达max_fails后，该server不能访问的时间 对上游服务使用keepalived长连接 功能：通过复用连接，降低nginx与上游服务器简历、关闭连接的消耗，提升吞吐量的同时降低时延 模块：ngx_http_upstream_keepalive_module，默认编译进nginx，使用–without-http_upstream_keepalive_moduel移除该模块 配置： 对上游连接的http头部设定 12proxy_http_version 1.1;proxy_set_header Connection \"\"; upstream_keepalive的指令 Syntax: keepalive connections; Default: — Context: upstream Syntax: keepalive_requests number; Default: keepalive_requests 100; Context: upstream Syntax: keepalive_timeout timeout; Default: keepalive_timeout 60s; Context: upstream 指定上游服务域名解析的resolver指令 Syntax: resolver address … [valid=time] [ipv6=on|off]; Default: — Context: http, server, location Syntax: resolver_timeout time; Default: resolver_timeout 30s; Context: http, server, location 123456789101112131415161718192021222324252627#roundrobin.conf。配置上游服务9011和9012upstream rrups &#123; server 127.0.0.1:9011 weight=2 max_conns=2 max_fails=2 fail_timeout=5; server 127.0.0.1:9012; keepalive 32;&#125;server &#123; listen 10005; server_name rrup.dookt.com.cn; error_log logs/rrups-error.log info; location / &#123; proxy_pass http://rrups; proxy_http_version 1.1; #上游连接的http头部设定http协议办版本http/1.1 proxy_set_header Connention \"\"; #上游连接的http头部设定 &#125;&#125;#upserver.conf。9011和9012server &#123; listen 9011; default_type text/plain; return 200 '9011 server respomse.\\n';&#125;server &#123; listen 9012; default_type text/plain; return 200 '9012 server respomse.\\n';&#125; 12345678910111213#使用curl验证，可以发现和预期一致，（访问两次9011才访问一次9012）[root@openresty01 ~]# curl rrups.dookt.com.cn:100059011 server respomse.[root@openresty01 ~]# curl rrups.dookt.com.cn:100059011 server respomse.[root@openresty01 ~]# curl rrups.dookt.com.cn:100059012 server respomse.[root@openresty01 ~]# curl rrups.dookt.com.cn:100059011 server respomse.[root@openresty01 ~]# curl rrups.dookt.com.cn:100059011 server respomse.[root@openresty01 ~]# curl rrups.dookt.com.cn:100059012 server respomse. 123456789101112131415161718192021222324252627282930#通过tcpdump抓包分析，[root@openresty01 ~]# curl rrups.dookt.com.cn:10005 #向9011发送报文9011 server respomse.[root@openresty01 ~]# curl rrups.dookt.com.cn:100059012 server respomse.[root@openresty01 ~]# curl rrups.dookt.com.cn:10005 #向9011发送报文9011 server respomse.[root@openresty01 ~]# tcpdump -i lo port 9011 #这几次访问都没有关闭连接tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on lo, link-type EN10MB (Ethernet), capture size 262144 bytes16:10:00.679067 IP localhost.33782 &gt; localhost.9011: Flags [S], seq 1377635386, win 43690, options [mss 65495,sackOK,TS val 25658580 ecr 0,nop,wscale 7], length 019:52:42.147817 IP localhost.9011 &gt; localhost.33782: Flags [S.], seq 1262964724, ack 1377635387, win 43690, options [mss 65495,sackOK,TS val 25658580 ecr 25658580,nop,wscale 7], length 016:10:00.679119 IP localhost.33782 &gt; localhost.9011: Flags [.], ack 1, win 342, options [nop,nop,TS val 25658580 ecr 25658580], length 016:10:00.679164 IP localhost.33782 &gt; localhost.9011: Flags [P.], seq 1:89, ack 1, win 342, options [nop,nop,TS val 25658580 ecr 25658580], length 8816:10:00.679169 IP localhost.9011 &gt; localhost.33782: Flags [.], ack 89, win 342, options [nop,nop,TS val 25658580 ecr 25658580], length 016:10:00.679253 IP localhost.9011 &gt; localhost.33782: Flags [P.], seq 1:172, ack 89, win 342, options [nop,nop,TS val 25658580 ecr 25658580], length 17116:10:00.679256 IP localhost.33782 &gt; localhost.9011: Flags [.], ack 172, win 350, options [nop,nop,TS val 25658580 ecr 25658580], length 016:10:00.680745 IP localhost.9011 &gt; localhost.33782: Flags [F.], seq 172, ack 89, win 342, options [nop,nop,TS val 25658582 ecr 25658580], length 016:10:00.681005 IP localhost.33782 &gt; localhost.9011: Flags [F.], seq 89, ack 173, win 350, options [nop,nop,TS val 25658582 ecr 25658582], length 016:10:00.681019 IP localhost.9011 &gt; localhost.33782: Flags [.], ack 90, win 342, options [nop,nop,TS val 25658582 ecr 25658582], length 016:10:19.678451 IP localhost.33786 &gt; localhost.9011: Flags [S], seq 1105788511, win 43690, options [mss 65495,sackOK,TS val 25677579 ecr 0,nop,wscale 7], length 018:32:42.250471 IP localhost.9011 &gt; localhost.33786: Flags [S.], seq 1019653247, ack 1105788512, win 43690, options [mss 65495,sackOK,TS val 25677579 ecr 25677579,nop,wscale 7], length 016:10:19.678458 IP localhost.33786 &gt; localhost.9011: Flags [.], ack 1, win 342, options [nop,nop,TS val 25677579 ecr 25677579], length 016:10:19.678468 IP localhost.33786 &gt; localhost.9011: Flags [P.], seq 1:89, ack 1, win 342, options [nop,nop,TS val 25677579 ecr 25677579], length 8816:10:19.678470 IP localhost.9011 &gt; localhost.33786: Flags [.], ack 89, win 342, options [nop,nop,TS val 25677579 ecr 25677579], length 016:10:19.678488 IP localhost.9011 &gt; localhost.33786: Flags [P.], seq 1:172, ack 89, win 342, options [nop,nop,TS val 25677579 ecr 25677579], length 17116:10:19.678489 IP localhost.33786 &gt; localhost.9011: Flags [.], ack 172, win 350, options [nop,nop,TS val 25677579 ecr 25677579], length 016:10:19.678512 IP localhost.9011 &gt; localhost.33786: Flags [F.], seq 172, ack 89, win 342, options [nop,nop,TS val 25677579 ecr 25677579], length 016:10:19.678530 IP localhost.33786 &gt; localhost.9011: Flags [F.], seq 89, ack 173, win 350, options [nop,nop,TS val 25677579 ecr 25677579], length 016:10:19.678532 IP localhost.9011 &gt; localhost.33786: Flags [.], ack 90, win 342, options [nop,nop,TS val 25677579 ecr 25677579], length 0 负载均衡算法：ip_hash与hash模块基于客户端IP地址的hash算法实现负载均衡：upstream_ip_hash模块 功能：以客户端IP地址作为hash算法的关键字，映射到特定的上游服务器中 对IPv4地址使用前3个字节作为关键字，对于IPv6则使用完整地址 可以使用realip模块修改用于执行算法的IP地址 模块：ngx_http_upstream_ip_hash_module，默认编译，通过–without-http_upstream_ip_hash_module禁用模块 语法 Syntax: ip_hash; Default: — Context: upstream 基于关键字查找实现hash算法的负载均衡：upstream_hash模块 功能：通过指定关键字作为hash key，基于hash算法映射特定的上游服务器中 关键字可以含有变量字符串 模块：ngx_http_upstream_hash_module，默认编译，通过–without-http_upstream_hash_module禁用模块 语法： Syntax: hash key [consistent]; Default: — Context: upstream 1234567891011121314151617181920upstream iphashups &#123; ip_hash; server 127.0.0.1:9011 weight=2 max_conns=2 max_fails=2 fail_timeout=5; server 127.0.0.1:9012; #此时weight不生效,因为使用了ip_hash，必须根据用户IP地址来确定 #keepalive 32;&#125;server &#123; set_real_ip_from 172.16.100.11; #为了方便测试，使用了realip模块。设置可信地址是本机地址 real_ip_recursive on; real_ip_header X-Forwarded-For; #从X-Forwarded-For的最后一个地址中拿出来作为IP地址即$remote_addr listen 10005; server_name iphash.dookt.com.cn; error_log logs/rrups-error.log info; location / &#123; proxy_pass http://iphashups; proxy_http_version 1.1; proxy_set_header Connention \"\"; &#125;&#125; 使用curl -H 在header头部添加上X-Forwarded-For的值 12345#测试结果如下：通过不同IP地址访问到的后端服务不一样，但是同一个IP访问到的肯定是同一个后端服务[root@openresty01 ~]# curl -H 'X-Forwarded-For: 100.200.20.200' iphash.dookt.com.cn:100059012 server respomse.[root@openresty01 ~]# curl -H 'X-Forwarded-For: 172.15.54.1' iphash.dookt.com.cn:10005 9011 server respomse. 12345678910111213141516171819upstream iphashups &#123; hash user_$arg_username; server 127.0.0.1:9011 weight=2 max_conns=2 max_fails=2 fail_timeout=5; server 127.0.0.1:9012; keepalive 32;&#125;server &#123; set_real_ip_from 172.16.100.11; real_ip_recursive on; real_ip_header X-Forwarded-For; listen 10005; server_name iphash.dookt.com.cn; error_log logs/rrups-error.log info; location / &#123; proxy_pass http://iphashups; proxy_http_version 1.1; proxy_set_header Connention \"\"; &#125;&#125; 12345#以下结果发现，通过访问不同的username到的后端服务不一样，但是同一个username访问过去的肯定是同一个后端服务[root@openresty01 ~]# curl -H 'X-Forwarded-For: 100.200.20.200' iphash.dookt.com.cn:10005?username=389446587asdf9011 server respomse.[root@openresty01 ~]# curl -H 'X-Forwarded-For: 100.200.20.200' iphash.dookt.com.cn:10005?username=2346sfs57asdfgag 9012 server respomse. 一致性hash算法hash算法的问题举例，设置选中上游server的算法为：key % 5 key5 &lt;—&gt; server0 key6 &lt;—&gt; server1 key7 &lt;—&gt; server2 key8 &lt;—&gt; server3 key9 &lt;—&gt; server4 此时如果一台server4宕机。则所有策略都会改变 key5 &lt;—&gt; server1 key6 &lt;—&gt; server2 key7 &lt;—&gt; server3 key8 &lt;—&gt; server0 key9 &lt;—&gt; server1 所以，宕机或者扩容时，hash算法会引发大量的路由变更，可能导致缓存大范围失效 一致性hash算法，缓解hash算法的的扩容或宕机引发的路由变更，导致缓存大范围失效 1234567891011121314151617181920upstream ipchashups &#123; ip_hash consistent; #一致性hash配置只需要在ip_hash上添加consistent即可 server 127.0.0.1:9011 weight=2 max_conns=2 max_fails=2 fail_timeout=5; server 127.0.0.1:9012; #此时weight不生效,因为使用了ip_hash，必须根据用户IP地址来确定 #keepalive 32;&#125;server &#123; set_real_ip_from 172.16.100.11; #为了方便测试，使用了realip模块。设置可信地址是本机地址 real_ip_recursive on; real_ip_header X-Forwarded-For; #从X-Forwarded-For的最后一个地址中拿出来作为IP地址即$remote_addr listen 10005; server_name ipchash.dookt.com.cn; error_log logs/rrups-error.log info; location / &#123; proxy_pass http://ipchashups; proxy_http_version 1.1; proxy_set_header Connention \"\"; &#125;&#125; 最少连接算法以及如何跨worker进程生效优先选择连接最少的上游服务：upstream_least_conn模块 功能：从所有服务器中，找出当前并发连接数最少的一个，将请求转发到它。 如果出现多个最小连接数一样的，使用round-robin算法 模块：ngx_http_upstream_least_conn_module，通过–without-http_upstream_ip_hash_module禁用模块 语法： Syntax: least_conn; Default: — Context: upstream 使用共享内存使负载均衡策略对所有worker进程生效：upstream_zone模块 功能：分配出共享内存，将其他upstream模块定义的负载均衡数据、运行是每个上上游服务的状态数据存放到共享内存上，以对所有nginx的worker进程都生效 模块：ngx_http_upstream_zone_module，默认编译。通过–without-http_upstream_zone_module禁用该模块 语法： Syntax: zone name [size]; Default: — Context: upstream upstream模块提供的变量不含cache的upstream提供的变量 upstream_addr：上游服务的IP地址，格式为可读字符串，例如：127.0.0.1:9011 upstream_connect_time：与上游服务连接消耗的时间，单位为秒，精确到毫秒 upstream_header_time：接收上游服务发回响应中http头部所消耗的时间，单位为秒，精确到毫秒 upstream_response_time：接收完整上游服务响应所消耗的时间，单位为秒吗，精确到毫秒 upstream_http_名称：从上游服务返回的响应头部的值 upstream_bytes_received：从上游服务接收到的响应长度，单位为字节 upstream_response_length：从上游服务返回响应包体的长度，单位为字节 upstream_status：上游服务返回的HTTP响应中的状态码。如果未连接上，该变量值为502 upstream_cookies_名称：从上游服务发回响应头Set-Cookies中取出的cookie的值 upstream_trailer_名称：从上游服务尾部取到的值 12345678910111213141516171819202122upstream varups &#123; server 127.0.0.1:9011 weight=2 max_conns=2 max_fails=2 fail_timeout=5; server 127.0.0.1:9012; keepalive 32;&#125;log_format varups '$upstream_addr $upstream_connect_time $upstream_header_time $upstream_response_time ' '$upstream_response_length $upstream_bytes_received ' '$upstream_status $upstream_http_server $upstream_cache_status';server &#123; set_real_ip_from 172.16.100.11; real_ip_recursive on; real_ip_header X-Forwarded-For; listen 10005; server_name varups.dookt.com.cn; error_log logs/upstream-error.log info; access_log logs/upstream-access.log varups; location / &#123; proxy_pass http://varups; proxy_http_version 1.1; proxy_set_header Connention \"\"; &#125;&#125; proxy模块处理请求的流程对HTTP协议的反向代理：proxy模块 功能：对上游服务使用http/https协议进行反向代理 模块：ngx_http_proxy_module，默认编译，使用–without-http_proxy_module禁用模块 语法： Syntax: proxy_pass URL; Default: — Context: location, if in location, limit_except URL参数规则： URL必须以 http:// 或 https:// 开头，接下来是域名、IP、unix socket地址或者upstream的名字。前两者可以在域名或者IP后加端口。域名和IP后面的URI是可选的。 URL参数中是否携带了URI，会导致发向上游请求的URL不同： 不携带URI，客户端请求中的URL直接转发给上游 location 后使用正则表达式、@名字时，应采用这种方式 携带URI，则对用户请求中的URL做如下操作： 将location参数中匹配上的一段替换为该URL 该URL参数可以携带变量 更复杂的URL替换，可以在location内的配置添加rewrite break语句 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# upserver.conf配置server &#123; listen 9012; default_type text/plain; return 200 '9012 server respomse.uri: $uri\\n';&#125;#配置1，proxy_pass指令没有携带URIupstream proxyups &#123; server 127.0.0.1:9012 weight=1;&#125;server &#123; listen 10006; server_name proxy.dookt.com.cn; error_log logs/proxy-error.log info; access_log logs/proxy-access.log; location /a &#123; proxy_pass http://proxyups; #没有携带URI #proxy_mothod POST; proxy_pass_request_headers off; #proxy_pass_request_body off; proxy_set_body 'hello world!'; proxy_set_header name ''; proxy_http_version 1.1; proxy_set_header Connection \"\"; &#125;&#125;#配置2，proxy_pass指令携带URIupstream proxyups &#123; server 127.0.0.1:9012 weight=1;&#125;server &#123; listen 10006; server_name proxy.dookt.com.cn; error_log logs/proxy-error.log info; access_log logs/proxy-access.log; location /a &#123; proxy_pass http://proxyups/www; #携带URI /www #proxy_mothod POST; proxy_pass_request_headers off; #proxy_pass_request_body off; proxy_set_body 'hello world!'; proxy_set_header name ''; proxy_http_version 1.1; proxy_set_header Connection \"\"; &#125;&#125; 123456789#分别访问配置1 和 2，结果如下：#未携带uri[root@openresty01 ~]# curl proxy.dookt.com.cn:10006/a/b/c9012 server respomse.uri: /a/b/c #proxy_pass未携带URI,客户端请求中的URL（/a/b/c）直接转发给上游#携带uri[root@openresty01 ~]# curl proxy.dookt.com.cn:10006/a/b/c9012 server respomse.uri: /www/b/c #proxy_pass携带URI,将location参数中匹配上的一段替换为该URL 根据指令修改发往上游的请求生成发往上游的请求行 Syntax: proxy_method method; Default: — Context: http, server, location Syntax: proxy_http_version 1.0 | 1.1; Default: proxy_http_version 1.0; Context: http, server, location 生成发往上游的请求头若value的值为空字符串，这整个header都不会向上游发送 Syntax: proxy_set_header field value; Default: proxy_set_header Host $proxy_host;``proxy_set_header Connection close; Context: http, server, location Syntax: proxy_pass_request_headers on | off; Default: proxy_pass_request_headers on; Context: http, server, location Syntax: proxy_pass_request_body on | off; Default: proxy_pass_request_body on; Context: http, server, location Syntax: proxy_set_body value; Default: — Context: http, server, location 1234567891011121314151617181920212223242526272829303132333435363738394041424344#配置1，默认配置，传递header,没有设置header和bodyupstream proxyups &#123; server 127.0.0.1:9012 weight=1;&#125;server &#123; listen 10006; server_name proxy.dookt.com.cn; error_log logs/proxy-error.log info; access_log logs/proxy-access.log; location /a &#123; proxy_pass http://proxyups/www; #proxy_mothod POST; #proxy_pass_request_headers off; #proxy_pass_request_body off; #proxy_set_body 'hello world!'; #proxy_set_header name ''; #proxy_http_version 1.1; proxy_set_header Connection \"\"; &#125;&#125;#配置2，不传递header,修改方法为POST location /a &#123; proxy_pass http://proxyups/www; proxy_method POST; proxy_pass_request_headers off; #proxy_pass_request_body off; #proxy_set_body 'hello world!'; #proxy_set_header name ''; proxy_http_version 1.1; proxy_set_header Connection \"\"; &#125;#配置3，设置body location /a &#123; proxy_pass http://proxyups/www; proxy_method POST; proxy_pass_request_headers off; #proxy_pass_request_body off; proxy_set_body 'hello world!'; proxy_set_header name ''; proxy_http_version 1.1; proxy_set_header Connection \"\"; &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778#配置1，默认开启传递header，所以httpname为myname, 方法为get,协议为1.0[root@openresty01 ~]# curl -H \"name: myname\" proxy.dookt.com.cn:10006/a9012 server respomse.uri: /wwwmethod: GETrequest: GET /www HTTP/1.0httpname: myname#配置2，不传递header，httpname为空，方法为post，协议为1.1[root@openresty01 ~]# curl -H \"name: myname\" proxy.dookt.com.cn:10006/a9012 server respomse.uri: /wwwmethod: POSTrequest: POST /www HTTP/1.1httpname: #配置3，header设置为空，传递过去取到的还是空（httpname: ）[root@openresty01 ~]# tcpdump -i lo port 9012 -A -s 0 #通过抓包查看body已经传入了hello world!tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on lo, link-type EN10MB (Ethernet), capture size 262144 bytes04:51:58.894007 IP localhost.44716 &gt; localhost.9012: Flags [S], seq 2280917651, win 43690, options [mss 65495,sackOK,TS val 71376795 ecr 0,nop,wscale 7], length 0E..&lt;..@.@.'...........#4............0..........A..........11:50:03.167884 IP localhost.9012 &gt; localhost.44716: Flags [S.], seq 1393064595, ack 2280917652, win 43690, options [mss 65495,sackOK,TS val 71376795 ecr 71376795,nop,wscale 7], length 0E..&lt;..@.@.&lt;.........#4..S.z.........0..........A...A......04:51:58.894015 IP localhost.44716 &gt; localhost.9012: Flags [.], ack 1, win 342, options [nop,nop,TS val 71376795 ecr 71376795], length 0E..4. @.@.'...........#4...S.z....V.(......A...A..04:51:58.894024 IP localhost.44716 &gt; localhost.9012: Flags [P.], seq 1:71, ack 1, win 342, options [nop,nop,TS val 71376795 ecr 71376795], length 70E..z.@.@.'r..........#4...S.z....V.n......A...A..POST /www HTTP/1.1Host: proxyupsContent-Length: 12hello world!04:51:58.894026 IP localhost.9012 &gt; localhost.44716: Flags [.], ack 71, win 342, options [nop,nop,TS val 71376795 ecr 71376795], length 0E..4e.@.@...........#4..S.z.......V.(......A...A..04:51:58.894045 IP localhost.9012 &gt; localhost.44716: Flags [P.], seq 1:240, ack 71, win 342, options [nop,nop,TS val 71376795 ecr 71376795], length 239E..#e.@.@...........#4..S.z.......V........A...A..HTTP/1.1 200 OKServer: openresty/1.13.6.2Date: Sun, 14 Jul 2019 20:51:58 GMTContent-Type: text/plainContent-Length: 85Connection: keep-alive9012 server respomse.uri: /wwwmethod: POSTrequest: POST /www HTTP/1.1httpname: 04:51:58.894047 IP localhost.44716 &gt; localhost.9012: Flags [.], ack 240, win 350, options [nop,nop,TS val 71376795 ecr 71376795], length 0E..4..@.@.'...........#4...S.&#123;....^.(......A...A..04:51:58.894082 IP localhost.44716 &gt; localhost.9012: Flags [F.], seq 71, ack 240, win 350, options [nop,nop,TS val 71376795 ecr 71376795], length 0E..4..@.@.'...........#4...S.&#123;....^.(......A...A..04:51:58.894101 IP localhost.9012 &gt; localhost.44716: Flags [F.], seq 240, ack 72, win 342, options [nop,nop,TS val 71376795 ecr 71376795], length 0E..4e.@.@...........#4..S.&#123;.......V.(......A...A..04:51:58.894103 IP localhost.44716 &gt; localhost.9012: Flags [.], ack 241, win 350, options [nop,nop,TS val 71376795 ecr 71376795], length 0E..4..@.@.'...........#4...S.&#123;....^.(......A...A.. 接收用户请求的包体","tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://www.dookt.com/tags/Nginx/"}]},{"title":"Nginx-架构基础","date":"2019-07-25T13:38:23.000Z","path":"post/47516.html","text":"Nginx进程结构为什么使用多进程而不是多线程？实现高可用（master），使用线程的话，其中一个崩溃会导致全部崩溃 单进程 , 不适用于生产环境，用于调试，开发 多进程 master进程，用于管理worker进程，监控以及配置文件重载 子进程 worker进程 cache进程 ，缓存会在多个worker进程之间使用 使用信号管理Nginx的父子进程 master进程 CHILD信号：监控、管理worker进程 TERM，INT信号：立刻停止nginx进程 QUIT信号：优雅停止nginx进程，对用户不要立刻发送tcp的reset复位请求的报文 HUP信号：重载配置文件 USR1信号：重新打开日志文件，做日志文件切割 USR2信号、WINCH信号：只能通过kill命令操作，用作热升级 worker进程 TERM，INT信号： QUIT信号： USR1信号： WINCH信号： nginx命令行（通过nginx.pid文件记录PID） reload：HUP reopen：USR1 stop：TERM quit：QUIT Nginx重载配置文件的真相reload流程 向master进程发送HUP信号（reload命令） master进程校验配置语法是否正确 master进程打开新的监听端口 master进程使用新的配置启动新的worker子进程 master进程向老worker子进程发送QUIT信号 老master进程关闭监听句柄，处理完当前连接后结束进程 热升级的流程 将旧的nginx文件换成新的nginx文件（注意备份） 向master进程发送USR2信号 master进程修改pid文件名，加上后缀.oldbin master进程用新的nginx文件启动新master进程 向老master进程发送QUIT信号，关闭老master进程 回滚：向老master发送HUP，向新master发送QUIT信号 优雅的关闭worker进程（针对http请求） 设置定时器worker_shutdown_timeout 关闭监听句柄 关闭空闲连接 在循环中等待全部连接关闭 退出进程 Nginx连接池worker_connections（高并发配置项） Syntax: worker_connections number; Default: worker_connections 512; Context: events client_header_timeout Syntax: client_header_timeout time; Default: client_header_timeout 60s; Context: http, server $byte_sent（发送的字节数）number of bytes sent to a client (1.3.8, 1.2.5) 123log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status [$request_length:$bytes_sent] \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\" \"$upstream_cache_status\"'; connection_pool_size（连接内存池大小） Syntax: connection_pool_size size; Default: connection_pool_size 256|512; Context: http, server request_pool_size（请求内存池大小） Syntax: request_pool_size size; Default: request_pool_size 4k; Context: http, server 共享内存—-Nginx跨worker进程通信的有效手段使用共享内存的官方模块 Ngx_http_lua_api rbtree Ngx_stream_limit_conn_module Ngx_http_limit_conn_module Ngx_stream_limit_req_module：流量控制 http cache Ngx_http_file_cache Ngx_http_proxy_module Ngx_http_scgi_module Ngx_http_uwsgi_module Ngx_http_fastcgi_module ssl Ngx_http_ssl_module Ngx_mail_ssl_module Ngx_stream_ssl_module 单链表 Ngx_http_upstream_zone_module Ngx_stream_upstream_zone_module slab内存分配管理器 下载Tengine中的slab_stat模块编译进openresty中 12345wget -c http://tengine.taobao.org/download/tengine-2.2.2.tar.gztar -xvf tengine-2.2.2.tar.gzcd ~/openresty-1.13.6.2./configure --add-module=../tengine-2.2.2/modules/ngx_slab_stat/gmake &amp;&amp; gmake install 共享内存示例1234567891011121314151617181920212223 http &#123; lua_shared_dict dogs 10m; server &#123; location = /slab_stat &#123; slab_stat; &#125; location /set &#123; content_by_lua_block &#123; local dogs = ngx.shared.dogs dogs:set(\"Jim\", 8) ngx.say(\"STORED\") &#125; &#125; location /get &#123; content_by_lua_block &#123; local dogs = ngx.shared.dogs ngx.say(dogs:get(\"Jim\")) &#125; &#125; &#125;&#125; 使用共享内存及slab_stat 1234567891011121314151617[root@openresty01 ~]# curl 172.16.100.11/setSTORED[root@openresty01 ~]# curl 172.16.100.11/get8[root@openresty01 ~]# curl 172.16.100.11/slab_stat* shared memory: dogstotal: 10240(KB) free: 10168(KB) size: 4(KB)pages: 10168(KB) start:00007F1C8B47F000 end:00007F1C8BE6F000slot: 8(Bytes) total: 0 used: 0 reqs: 0 fails: 0slot: 16(Bytes) total: 0 used: 0 reqs: 0 fails: 0slot: 32(Bytes) total: 127 used: 1 reqs: 1 fails: 0slot: 64(Bytes) total: 0 used: 0 reqs: 0 fails: 0slot: 128(Bytes) total: 32 used: 2 reqs: 2 fails: 0slot: 256(Bytes) total: 0 used: 0 reqs: 0 fails: 0slot: 512(Bytes) total: 0 used: 0 reqs: 0 fails: 0slot: 1024(Bytes) total: 0 used: 0 reqs: 0 fails: 0slot: 2048(Bytes) total: 0 used: 0 reqs: 0 fails: 0 Nginx的容器 数组 链表 队列 哈希表 红黑树：自平衡查找二叉树，高度差不大 高度不会超过2倍log(n) 增删改查算法复杂度O(log(n)) 遍历复杂度O(n) 基数树 Nginx最常用的容器—–红黑树使用红黑树的常见模块 ngx_conf_module #config_dump_rbtree ngx_event_timer_rbtree #管理计时器的红黑树 Ngx_http_file_cache Ngx_http_geo_module Ngx_http_limit_conn_module Ngx_http_limit_req_module Ngx_http_lua_shdict:ngx.shared.DICT #LRU链表性质 resolver #ngx_resolver_t Ngx_stream_geo_module Ngx_stream_limit_conn_module Nginx动态模块动态模块编译步骤 Configure加入动态模块 编译进binary 启动初始化模块数组 读取load_module配置 打开动态库加入模块数组 基于模块数组开始初始化 查看哪些模块可以作为动态模块12345678[root@openresty01 ~]# ./configure --help | grep =dynamic --with-http_xslt_module=dynamic enable dynamic ngx_http_xslt_module --with-http_image_filter_module=dynamic --with-http_geoip_module=dynamic enable dynamic ngx_http_geoip_module --with-http_perl_module=dynamic enable dynamic ngx_http_perl_module --with-mail=dynamic enable dynamic POP3/IMAP4/SMTP proxy module --with-stream=dynamic enable dynamic TCP/UDP proxy module --with-stream_geoip_module=dynamic enable dynamic ngx_stream_geoip_module http_image_filter_module模块使用http_image_filter_module123[root@openresty01 ~]# yum -y install gd gd-devel[root@openresty01 ~]# ./configure --prefix=/tmp/nginx122 --with-http_image_filter_module=dynamic[root@openresty01 ~]# make &amp;&amp; make install 修改配置文件123456# 未使用模块配置文件 server &#123; listen 8080; location / &#123; root test; #该目录下有一个ubunt.jgp的图片 &#125; 12345678# 使用模块配置文件load_module modules/ngx_http_image_filter_module.so; #引入动态库文件 server &#123; listen 8080; location / &#123; root test; #该目录下有一个ubunt.jgp的图片 image_filter resize 15 10; #设置图片为15x10大小 &#125; 测试验证 使用浏览器访问两次即可发现图片发生改变","tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://www.dookt.com/tags/Nginx/"}]}]